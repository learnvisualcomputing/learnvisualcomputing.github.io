<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Color Vision – Foundations of Visual Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./hvs-colorimetry.html" rel="next">
<link href="./hvs-receptor.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./hvs.html">Human Visual System</a></li><li class="breadcrumb-item"><a href="./hvs-color.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Color Vision</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Foundations of Visual Computing</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Foundations-of-Visual-Computing.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">An Invitation to Visual Computing</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./hvs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Human Visual System</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">From Light to Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-receptor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Photoreceptors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-color.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Color Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-colorimetry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Colorimetry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Visual Adaptations and Constancy</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./rendering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rendering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-radiometry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Radiometry and Photometry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-lightfield.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Light Field</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-re.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Rendering Surface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-surface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Modeling Material Surface</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-sss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Volume and Subsurface Scattering Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-rte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Rendering Volume and Subsurface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-nflux.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">The N-Flux Theory</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./imaging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Imaging</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Imaging Optics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-sensor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Image Sensor Architecture</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-noise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-isp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Image Signal Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./display.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Display</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Optical Mechanisms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-electronics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Driving Circuits and Processing Pipeline</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-chpt-hvs-color-receptor" id="toc-sec-chpt-hvs-color-receptor" class="nav-link active" data-scroll-target="#sec-chpt-hvs-color-receptor"><span class="header-section-number">4.1</span> Color Encoding at Photoreceptors</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-hvs-color-receptor-cones" id="toc-sec-chpt-hvs-color-receptor-cones" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-receptor-cones"><span class="header-section-number">4.1.1</span> From Light Spectrum to Cone Responses</a></li>
  <li><a href="#sec-chpt-hvs-color-receptor-conespace" id="toc-sec-chpt-hvs-color-receptor-conespace" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-receptor-conespace"><span class="header-section-number">4.1.2</span> Cone Excitation Space, Spectral Locus, and HVS Gamut</a></li>
  </ul></li>
  <li><a href="#sec-chpt-hvs-color-cme" id="toc-sec-chpt-hvs-color-cme" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-cme"><span class="header-section-number">4.2</span> Trichromatic Color Matching</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-hvs-color-cme-cmf" id="toc-sec-chpt-hvs-color-cme-cmf" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-cme-cmf"><span class="header-section-number">4.2.1</span> Color Matching Experiments and Color Matching Functions</a></li>
  <li><a href="#sec-chpt-hvs-color-cme-cone" id="toc-sec-chpt-hvs-color-cme-cone" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-cme-cone"><span class="header-section-number">4.2.2</span> Connecting CMFs and Cone Fundamentals</a></li>
  </ul></li>
  <li><a href="#sec-chpt-hvs-color-oppo" id="toc-sec-chpt-hvs-color-oppo" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-oppo"><span class="header-section-number">4.3</span> Post-Receptoral Color Encoding: Opponent Processes</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-hvs-color-oppo-hue" id="toc-sec-chpt-hvs-color-oppo-hue" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-oppo-hue"><span class="header-section-number">4.3.1</span> Hue Cancellation Experiment</a></li>
  <li><a href="#sec-chpt-hvs-color-oppo-light" id="toc-sec-chpt-hvs-color-oppo-light" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-oppo-light"><span class="header-section-number">4.3.2</span> Light-Dark Mechanism and Luminous Efficiency Function</a></li>
  </ul></li>
  <li><a href="#sec-chpt-hvs-color-oppobasis" id="toc-sec-chpt-hvs-color-oppobasis" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-oppobasis"><span class="header-section-number">4.4</span> Neural and Physiological Basis of Opponent Processes</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-hvs-color-oppobasis:neurons" id="toc-sec-chpt-hvs-color-oppobasis:neurons" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-oppobasis\:neurons"><span class="header-section-number">4.4.1</span> Spectrally-Opponent and Non-Opponent Neurons</a></li>
  <li><a href="#sec-chpt-hvs-color-oppobasis-cir" id="toc-sec-chpt-hvs-color-oppobasis-cir" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-oppobasis-cir"><span class="header-section-number">4.4.2</span> Potential Neural Circuitries</a></li>
  <li><a href="#sec-chpt-hvs-color-oppobasis-model" id="toc-sec-chpt-hvs-color-oppobasis-model" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-oppobasis-model"><span class="header-section-number">4.4.3</span> A Cone-Opponent Model for Color-Opponent Mechanisms</a></li>
  <li><a href="#sec-chpt-hvs-color-oppobasis-truth" id="toc-sec-chpt-hvs-color-oppobasis-truth" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-oppobasis-truth"><span class="header-section-number">4.4.4</span> There are Many Inconvenient Truths</a></li>
  </ul></li>
  <li><a href="#sec-chpt-hvs-color-evo" id="toc-sec-chpt-hvs-color-evo" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-evo"><span class="header-section-number">4.5</span> Evolution of Color Vision</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-hvs-color-evo-tri" id="toc-sec-chpt-hvs-color-evo-tri" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-evo-tri"><span class="header-section-number">4.5.1</span> The Rise of Trichromacy</a></li>
  <li><a href="#sec-chpt-hvs-color-evo-duplex" id="toc-sec-chpt-hvs-color-evo-duplex" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-evo-duplex"><span class="header-section-number">4.5.2</span> The Rise of Scotopic vs.&nbsp;Photopic Vision</a></li>
  </ul></li>
  <li><a href="#sec-chpt-hvs-color-cvd" id="toc-sec-chpt-hvs-color-cvd" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-cvd"><span class="header-section-number">4.6</span> Color Vision Deficiencies</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-hvs-color-cvd-model" id="toc-sec-chpt-hvs-color-cvd-model" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-cvd-model"><span class="header-section-number">4.6.1</span> Models of Deficient Color Vision</a></li>
  <li><a href="#cvd-assistive-technologies" id="toc-cvd-assistive-technologies" class="nav-link" data-scroll-target="#cvd-assistive-technologies"><span class="header-section-number">4.6.2</span> CVD Assistive Technologies</a></li>
  <li><a href="#sec-chpt-hvs-color-cvd-gene" id="toc-sec-chpt-hvs-color-cvd-gene" class="nav-link" data-scroll-target="#sec-chpt-hvs-color-cvd-gene"><span class="header-section-number">4.6.3</span> Genetic Basis of CVD</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./hvs.html">Human Visual System</a></li><li class="breadcrumb-item"><a href="./hvs-color.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Color Vision</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-chpt-hvs-color" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Color Vision</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This chapter studies color vision. We will review two main retinal stages responsible for color vision: wavelength encoding by the photoreceptors and the opponent processes that take place post-receptorally. We discuss both the behavioral phenomena as well as the potential neural and physiological basis. That this chapter almost exclusively focuses on the retinal mechanisms should in no way be taken to downplay the significance of cortical mechanisms to color vision <span class="citation" data-cites="gegenfurtner2003cortical">(<a href="references.html#ref-gegenfurtner2003cortical" role="doc-biblioref">Gegenfurtner 2003</a>)</span>. We take this approach because: 1) the retinal mechanisms are much better understood and 2) many real-world applications such as color reproduction and detecting colored patterns could be adequately modeled by retinal mechanisms. This chapter concludes by briefly reviewing the evolution of color vision and deficient color vision.</p>
<section id="sec-chpt-hvs-color-receptor" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-chpt-hvs-color-receptor"><span class="header-section-number">4.1</span> Color Encoding at Photoreceptors</h2>
<p>Newton presumably did the famous experiment where he showed that a beam of white light is really a mixture of photons at different wavelengths, and each wavelength gives a different color percept. Color is very much our subjective sensation. What is the physical reality is the spectral power distribution of light. In Newton’s words: “<em>rays of Light in falling upon the bottom of the eye excite vibrations in the retina. Which vibrations, being propagated along the solid fibres of the optick Nerves into the Brain, cause the sense of seeing.</em>” <span class="citation" data-cites="newton1952opticks">(<a href="references.html#ref-newton1952opticks" role="doc-biblioref">Newton 1704</a>)</span>.</p>
<section id="sec-chpt-hvs-color-receptor-cones" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="sec-chpt-hvs-color-receptor-cones"><span class="header-section-number">4.1.1</span> From Light Spectrum to Cone Responses</h3>
<p>As we have seen before, there are three classes of cones, each with a different spectral sensitivity function or a cone fundamental. We will now see how the cone fundamentals encode wavelength information that eventually gives rise to color vision.</p>
<p>The cone fundamentals we have seen in <a href="hvs-receptor.html#fig-cone_fundamentals" class="quarto-xref">Figure&nbsp;<span>3.4</span></a> tell us the absolute spectral sensitivities of photoreceptors. It is customary to normalize the cone fundamentals to peak at unity. This normalization eliminates the differences at peak across photoreceptor types, but retains the relative spectral sensitivity within a particular type. Thus, this normalization is useful when we care only about comparing the sensitivity of different wavelengths of a particular type of photoreceptor, but not across different types of photoreceptor.</p>
<p>In addition, the cone fundamentals in <a href="hvs-receptor.html#fig-cone_fundamentals" class="quarto-xref">Figure&nbsp;<span>3.4</span></a> are defined on an “equal-quantal” basis: the sensitivities at different wavelengths are given assuming each wavelength has the same amount of photons. Sometimes, especially in CIE standards, the cone fundamentals (and other functions related to cone fundamentals, such as luminous efficiency function and color matching functions, both of which we will discuss later) are defined based on “equal-energy”, assuming each wavelength has the same energy/power, not the same amount of photons. As we will see shortly, the equal-energy definition is practically useful since the spectrum of a light is defined as power/energy distribution, rather than quantal distribution, over wavelength.</p>
<div id="fig-normalized_cone_fundamentals" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-normalized_cone_fundamentals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/normalized_cone_fundamentals_new.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-normalized_cone_fundamentals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Physiological measurements give us absolute spectral sensitivities on an equal-quantal basis (left), but in color science each cone fundamental function is usually normalized to peak at unity and then converted to an equal-energy form (right).
</figcaption>
</figure>
</div>
<p><a href="#fig-normalized_cone_fundamentals" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> compares the absolute, equal-quantal cone fundamentals with the normalized, equal-energy cone fundamentals. A normalized, equal-energy sensitivity function tells us the relative amount of photon absorption given a unit power at each wavelength. For instance, the normalized L cone response is 1 at 570 <span class="math inline">\(\text{nm}\)</span> and 0.4 at 630 <span class="math inline">\(\text{nm}\)</span>. This means that given two lights that have the same power/energy, one with photons only at 570 <span class="math inline">\(\text{nm}\)</span> and the other with photons only at 630 <span class="math inline">\(\text{nm}\)</span>, the fraction of photons absorbed in the 630 <span class="math inline">\(\text{nm}\)</span> light is about 40% of that in the 570 <span class="math inline">\(\text{nm}\)</span> light.</p>
<p>Critically, this also means if we have a 570 <span class="math inline">\(\text{nm}\)</span> light at 1 <span class="math inline">\(\text{W}\)</span> and a 630 <span class="math inline">\(\text{nm}\)</span> light at 2.5 W, the two lights would cause the same amount of pigment excitations in L cones. If we had only L cones, these two lights would be seen as the exact same light, because the HVS will receive the exact amount of electrical responses — according to the Principle of Univariance. This explains why we could not see colors at night, when only rods are functioning.</p>
<p>In reality, of course, most humans have three classes of cones, so what <em>is</em> the signal we receive? Given the Spectral Power Distribution (SPD) of a light <span class="math inline">\(\Phi(\lambda)\)</span>, we can calculate the total number of photon absorptions for each cone type, given by:</p>
<p><span id="eq-spd2cones_int"><span class="math display">\[
\begin{aligned}
  L &amp;= \int_\lambda L(\lambda) \Phi(\lambda) d\lambda \\
  M &amp;= \int_\lambda M(\lambda) \Phi(\lambda) d\lambda \\
  S &amp;= \int_\lambda S(\lambda) \Phi(\lambda) d\lambda
\end{aligned}
\tag{4.1}\]</span></span></p>
<p>where <span class="math inline">\(L(\lambda)\)</span>, <span class="math inline">\(M(\lambda)\)</span> and <span class="math inline">\(S(\lambda)\)</span> represent the cone sensitivity functions. The fact that we can directly multiply <span class="math inline">\(\Phi(\lambda)\)</span> with, say, <span class="math inline">\(L(\lambda)\)</span> is a result of defining <span class="math inline">\(L(\lambda)\)</span> on an equal-energy/power basis. The L/M/S values we calculate represent the total number of photon absorptions given an incident light. You would know why we care about photon absorption: it is equivalent to pigment excitation up to a constant scaling factor, and pigment excitations produce electrical signals that our brain actually receives. We sometimes simply call the L/M/S value the <strong>cone responses</strong> or <strong>tristimulus values</strong> of a light, but you should know that they do not represent the actual magnitude of the electrical responses of the cones, since the magnitude is not linearly proportional to absorption as we have discussed before.</p>
<p>In actual computation we discretize the spectra and perform summation rather than integration. We also limit the summation to within the [380 <span class="math inline">\(\text{nm}\)</span>, 780 <span class="math inline">\(\text{nm}\)</span>] range, since the cone fundamentals are practically 0 beyond that range. Assuming that we are quantizing the spectra at a 1-<span class="math inline">\(\text{nm}\)</span> interval, the cone responses are linearly related to the light spectrum by:</p>
<p><span id="eq-spd2cones"><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
L(380), L(381), \cdots, L(780)\\
M(380), M(381), \cdots, M(780)\\
S(380), S(381), \cdots, S(780)\\
\end{bmatrix}
\times
\begin{bmatrix}
\Phi(380)\\
\Phi(381)\\
\vdots \\
\Phi(780)\\
\end{bmatrix}
=
\begin{bmatrix}
L\\
M\\
S\\
\end{bmatrix}
\end{aligned}
\tag{4.2}\]</span></span></p>
<p>We can see that this is a huge dimensionality reduction. That is, our brain receives only the three-dimensional cone responses, not the actual spectrum of the light, which is of a much higher dimension. This is the basis of the <strong>trichromatic theory</strong> of color vision: color is a three-dimensional system. The theory was first proposed by <span class="citation" data-cites="young1802ii">Young (<a href="references.html#ref-young1802ii" role="doc-biblioref">1802</a>)</span>, who conjectured that there are three types of receptors, and later rediscovered, popularized, and extended by Hermann von Helmholtz in the later part of the nineteenth century.</p>
<p>The huge dimensionality reduction also means there are infinitely many lights (with different SPDs) that will be seen as having the same color, as long as they cause the same cone responses. One way to understand this is if we try to solve the system of linear equations in <a href="#eq-spd2cones" class="quarto-xref">Equation&nbsp;<span>4.2</span></a> given <span class="math inline">\([L, M, S]^T\)</span>, with the constraint that the <span class="math inline">\(\Phi\)</span> vector must be non-negative everywhere (since power cannot be negative), we would generally end up with infinitely many solutions, since it is an <em>under-determined</em> system. The fact that multiple physically different lights can end up having the same color is called <strong>metamerism</strong>, and these lights are called <strong>metamers</strong> of each other.</p>
</section>
<section id="sec-chpt-hvs-color-receptor-conespace" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="sec-chpt-hvs-color-receptor-conespace"><span class="header-section-number">4.1.2</span> Cone Excitation Space, Spectral Locus, and HVS Gamut</h3>
<div id="fig-spectral_locus_lms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spectral_locus_lms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/spectral_locus_lms.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spectral_locus_lms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2: Spectral locus in LMS cone space; from the interactive tutorial in <span class="citation" data-cites="zhu2022cone2cmf">Zhu (<a href="references.html#ref-zhu2022cone2cmf" role="doc-biblioref">2022a</a>)</span>.
</figcaption>
</figure>
</div>
<p>The cone fundamentals essentially give us a color space, which we call the <strong>LMS cone space</strong> or <strong>cone excitation space</strong>. A color space allows us to geometrically interpret a color as a point in the coordinate system. In the cone space, the color of a light is interpreted as the amount of responses in each of the three cone classes produced by the light (as calculated by <a href="#eq-spd2cones" class="quarto-xref">Equation&nbsp;<span>4.2</span></a>).</p>
<p>The <strong>spectral locus</strong> is a curve on which each point represents the color of a spectral light at a wavelength. <a href="#fig-spectral_locus_lms" class="quarto-xref">Figure&nbsp;<span>4.2</span></a> shows the spectral locus in the LMS cone space on the right and the cone fundamentals on the left. The L, M, and S cone responses of a spectral light at, for instance, 605 <span class="math inline">\(\text{nm}\)</span> are 0.775, 0.265, and 0, which corresponds to the point [0.775, 0.265, 0] in the cone space. Connecting these points for all the spectral lights gets us the spectral locus in the LMS space.</p>
<p>We know a color corresponds to a point in the cone space, but does an arbitrary point in the cone space correspond to a real color? <em>No</em>. For instance, if a point has a negative coordinate it obviously could not be a color of a real light, since that a negative cone response would require negative power in the light. Also, [1, 0, 0] is also not a real color, since there is no real light that can produce only L cone response but no responses from M and S cones — if you examine the cone fundamentals carefully. We call these colors <strong>imaginary colors</strong>, since they cannot be produced by physically realizable lights, where the power must be non-negative at any wavelength.</p>
<p>In principle, an [L, M, S] point corresponds to a real color if <a href="#eq-spd2cones" class="quarto-xref">Equation&nbsp;<span>4.2</span></a> has a non-negative solution for <span class="math inline">\(\Phi\)</span>. The total set of [L, M, S] points that have a non-negative <span class="math inline">\(\Phi\)</span> solution corresponds to all the colors that humans can see, which is called the <strong>gamut</strong> of the human visual system. Geometrically, if a point in the cone space cannot be constructed through a <em>positive</em>, linear combination of the points on the spectral locus, it then is not a real color, since the SPD of a real light must be a positive, linear combination of the SPDs of the spectral lights.</p>
<p>For instance, the line segment connecting two points on the spectral locus contains real colors that can be produced by mixing some amount (i.e., positive linear combinations) of the two spectral lights. Of course we can apply this iteratively: once you get a real color through combining spectral colors, the color itself can then be used as a basic color to create other colors. <span class="citation" data-cites="zhu2022gamut">Zhu (<a href="references.html#ref-zhu2022gamut" role="doc-biblioref">2022d</a>)</span> is an interactive tutorial that visualizes the HVS gamut in the cone space (and others), which you are invited to go through.</p>
</section>
</section>
<section id="sec-chpt-hvs-color-cme" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-chpt-hvs-color-cme"><span class="header-section-number">4.2</span> Trichromatic Color Matching</h2>
<p>We can produce, in theory, any color by mixing three other colors, which we call the <strong>primary colors</strong>. Here is the mathematical intuition. Let’s say the SPDs of the three primary lights are <span class="math inline">\(R(\lambda)\)</span>, <span class="math inline">\(G(\lambda)\)</span>, <span class="math inline">\(B(\lambda)\)</span>. What is the power of each of the primary lights we need to produce the color of a target light <span class="math inline">\(\Phi(\lambda)\)</span>? For the color of the mixed light to match that of the target light, their corresponding cone responses must match:</p>
<p><span id="eq-cme"><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
\sum R(\lambda)L(\lambda),~ \sum G(\lambda)L(\lambda),~ \sum B(\lambda)L(\lambda)\\
\sum R(\lambda)M(\lambda),~ \sum G(\lambda)M(\lambda),~ \sum B(\lambda)M(\lambda)\\
\sum R(\lambda)S(\lambda),~ \sum G(\lambda)S(\lambda),~ \sum B(\lambda)S(\lambda)\\
\end{bmatrix}
\times
\begin{bmatrix}
r\\
g\\
b \\
\end{bmatrix}
=
\begin{bmatrix}
\sum\Phi(\lambda)L(\lambda)\\
\sum\Phi(\lambda)M(\lambda)\\
\sum\Phi(\lambda)S(\lambda)\\
\end{bmatrix},
\end{aligned}
\tag{4.3}\]</span></span></p>
<p>where <span class="math inline">\(r, g, b\)</span> represent the power of the three primary lights, respectively. This system in general has one unique solution because we have the same number of unknowns (<span class="math inline">\(r, g, b\)</span>) as the number of equations. Each of the three equations constrains the cone-response matching of one class of cones. This means there is a single unique way to mix three primary lights to produce the color of an arbitrary target light.</p>
<p>What if we have more than three primary lights? We would end up with an <em>under-determined</em> system (e.g., three equations but four unknowns if given four primary lights), which means there are infinitely many ways to mix the primaries to produce the target color. If we have only two primaries, we end up with an <em>over-determined</em> system, where there is in general no solution.</p>
<!-- % https://scholar.harvard.edu/files/schwartz/files/lecture17-color.pdf; something to point students to? -->
<section id="sec-chpt-hvs-color-cme-cmf" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-chpt-hvs-color-cme-cmf"><span class="header-section-number">4.2.1</span> Color Matching Experiments and Color Matching Functions</h3>
<p><a href="#eq-cme" class="quarto-xref">Equation&nbsp;<span>4.3</span></a> gives a mathematical explanation for trichromatic color matching, but it requires knowing the cone fundamentals, which, as we have seen before in <a href="hvs-receptor.html#sec-chpt-hvs-receptor-absorb" class="quarto-xref"><span>Section 3.2</span></a>, were not experimentally measured until the mid 20<sup>th</sup> century, first through microspectrophotometry <span class="citation" data-cites="marks1964visual brown1964visual dartnall1983human">(<a href="references.html#ref-marks1964visual" role="doc-biblioref">Marks, Dobelle, and MacNichol Jr 1964</a>; <a href="references.html#ref-brown1964visual" role="doc-biblioref">Brown and Wald 1964</a>; <a href="references.html#ref-dartnall1983human" role="doc-biblioref">Dartnall, Bowmaker, and Mollon 1983</a>)</span> and then through suction electrode <span class="citation" data-cites="schnapf1987spectral">(<a href="references.html#ref-schnapf1987spectral" role="doc-biblioref">Schnapf, Kraft, and Baylor 1987</a>)</span>. But even without the cone fundamentals, nothing prevents us from performing an actual experiment to find the amount of primaries for producing a color. Thomas Young apparently had no interest in such an experiment <span class="citation" data-cites="mollon2003introduction">(<a href="references.html#ref-mollon2003introduction" role="doc-biblioref">Mollon 2003</a>)</span>. <span class="citation" data-cites="maxwell1857xviii">Maxwell (<a href="references.html#ref-maxwell1857xviii" role="doc-biblioref">1857</a>)</span> is believed to be the first to undertake an actual color matching experiment in the 19<sup>th</sup> century, but he did the experiments using rotating discs painted with different colors, relying on the temporal integration of the HVS.</p>
<p>Modern color matching experiments started with Wright and Guild <span class="citation" data-cites="wright1928trichromatic wright1929re wright1930re guild1931colorimetric">(<a href="references.html#ref-wright1928trichromatic" role="doc-biblioref">W. Wright 1928</a>, <a href="references.html#ref-wright1930re" role="doc-biblioref">1930</a>; <a href="references.html#ref-wright1929re" role="doc-biblioref">W. D. Wright 1929</a>; <a href="references.html#ref-guild1931colorimetric" role="doc-biblioref">Guild 1931</a>)</span>. International Commission on Illumination (CIE) in 1931 standardized the color matching experiment and synthesized Wright’s and Guild’s data (without any additional experiments) to obtain what is now known as the CIE 1931 RGB Color Matching Functions. This process is discussed in detail in <span class="citation" data-cites="broadbent2004critical">Broadbent (<a href="references.html#ref-broadbent2004critical" role="doc-biblioref">2004</a>)</span>, <span class="citation" data-cites="broadbent2008calculation">Broadbent (<a href="references.html#ref-broadbent2008calculation" role="doc-biblioref">2008</a>)</span>, <span class="citation" data-cites="service2016the">Service (<a href="references.html#ref-service2016the" role="doc-biblioref">2016</a>)</span>, and <span class="citation" data-cites="zhu2020how">Zhu (<a href="references.html#ref-zhu2020how" role="doc-biblioref">2020</a>)</span>. We summarize the key elements here; the experimental setup is illustrated in <a href="#fig-cme_setup" class="quarto-xref">Figure&nbsp;<span>4.3</span></a>.</p>
<div id="fig-cme_setup" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cme_setup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/cme_setup.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cme_setup-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.3: Color matching experiment setup. In CIE 1931 standardization of the experiment, the primary lights are spectral lights at 435.8 <span class="math inline">\(\text{nm}\)</span>, 546.1 <span class="math inline">\(\text{nm}\)</span>, and 700 <span class="math inline">\(\text{nm}\)</span>, and they swept the visible spectrum [380 <span class="math inline">\(\text{nm}\)</span>, 780 <span class="math inline">\(\text{nm}\)</span>] at a 5-<span class="math inline">\(\text{nm}\)</span> interval as the target light. Note that CIE 1931 did not do any actual experiments; they synthesized the data collected by Wright and Guild <span class="citation" data-cites="wright1928trichromatic wright1929re wright1930re guild1931colorimetric">(<a href="references.html#ref-wright1928trichromatic" role="doc-biblioref">W. Wright 1928</a>, <a href="references.html#ref-wright1930re" role="doc-biblioref">1930</a>; <a href="references.html#ref-wright1929re" role="doc-biblioref">W. D. Wright 1929</a>; <a href="references.html#ref-guild1931colorimetric" role="doc-biblioref">Guild 1931</a>)</span>.
</figcaption>
</figure>
</div>
<p>Observers are presented with a 2<span class="math inline">\(^{\circ}\)</span> visual field. They are given three primary lights, which in the CIE 1931 standard are <strong>spectral lights</strong> (lights that have photons at only one single wavelength; also called monochromatic lights) at wavelengths 435.8 <span class="math inline">\(\text{nm}\)</span>, 546.1 <span class="math inline">\(\text{nm}\)</span>, and 700 <span class="math inline">\(\text{nm}\)</span>. The three primary lights are pointed at the same point on one side of the visual field. On the other side of the visual field is the target light. Their goal is to adjust the power of each of the three primary lights so that the colors from the two sides of the visual field match. CIE 1931 swept the entire visible spectrum for the target light at a 5-<span class="math inline">\(\text{nm}\)</span> interval.</p>
<section id="color-matching-functions-require-a-unit-system-and-a-white-point" class="level4">
<h4 class="anchored" data-anchor-id="color-matching-functions-require-a-unit-system-and-a-white-point">Color Matching Functions Require a Unit System and a White Point</h4>
<p>The results obtained through the color matching experiments are shown in <a href="#fig-cie1931_rgb_cmf" class="quarto-xref">Figure&nbsp;<span>4.4</span></a> (left panel). The three curves are collectively called the CIE 1931 RGB <strong>Color Matching Functions</strong> (CMFs). Intuitively, the CMFs tell us the amount of primaries needed to match the color at each wavelength. But the devil is in the details. Let’s carefully walk through what this plot actually shows.</p>
<div id="fig-cie1931_rgb_cmf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cie1931_rgb_cmf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/cie1931_rgb_cmf.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cie1931_rgb_cmf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.4: Left: CIE 1931 RGB Color Matching Functions (CMFs); from <span class="citation" data-cites="cie1931rgbcmf">Marco Polo (<a href="references.html#ref-cie1931rgbcmf" role="doc-biblioref">2007</a>)</span>. The <span class="math inline">\(y\)</span>-axis shows the number of units needed of each primary so that the mixture matches the color at each wavelength (<span class="math inline">\(x\)</span>-axis) on an equal-energy basis. The unit system is so defined that mixing equal amounts (the number of units) of the three primaries produces the color of the equal-energy white, whose SPD is constant over the entire spectrum. Right: the negative values in the CMFs indicate that the corresponding primary light is to be mixed with the target light in order to match the color of the mixture of the other primaries.
</figcaption>
</figure>
</div>
<p>The <span class="math inline">\(y\)</span>-axis represents the number of units required of each primary so that the mixture matches the color at a given wavelength at <span class="math inline">\(x\)</span>-axis. What is a unit? The unit system is so defined that mixing the three primaries in equal units produces the color of the Equal-Energy White (EEW), whose SPD is a constant across the spectrum.</p>
<p>There are two judgment calls here. First, CIE 1931 decided that EEW was going to be the “white” color in their RGB color space. In general, however, there is no single color that we universally define as white, so if you were to design a color space you get to pick whatever color that you think is white in the color space. That said, an intuitive choice of white is one that is <strong>achromatic</strong> (colorless), a color that, subjectively, can only be described as having a certain level of gray but that has no apparent hue. Daylights at different times of a day are perceptually achromatic and could be used as the white point in a color space. The daylight colors are shown to be very similar to the colors of black-body radiation at different temperatures <span class="citation" data-cites="judd1964spectral">(<a href="references.html#ref-judd1964spectral" role="doc-biblioref">Judd et al. 1964</a>)</span>, shown in <a href="#fig-blackbody_colors" class="quarto-xref">Figure&nbsp;<span>4.5</span></a>.</p>
<div id="fig-blackbody_colors" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-blackbody_colors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/blackbody_colors.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-blackbody_colors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.5: Color from black-body radiation at different temperatures (<span class="math inline">\(x\)</span>-axis; unit: Kelvin). CIE Standard Illuminant D65 approximates the SPD of a noon daylight; its color is similar to that of a 6500 K black-body radiation. From <span class="citation" data-cites="blackbodyct">Bhutajata (<a href="references.html#ref-blackbodyct" role="doc-biblioref">2015</a>)</span>.
</figcaption>
</figure>
</div>
<p>You probably do not perceive most of the colors in <a href="#fig-blackbody_colors" class="quarto-xref">Figure&nbsp;<span>4.5</span></a> as achromatic on the display right now, but when you are in an environment illuminated by one of these colors, e.g., outdoors at noon, you do perceive the illuminant as achromatic; this is because of <strong>chromatic adaptation</strong>, a topic we will discuss later in <a href="hvs-adaptation.html#sec-chpt-hvs-adaptations-chroma" class="quarto-xref"><span>Section 6.3</span></a>. Briefly, the human visual system is evolved to adapt to different daylight colors so that when you spend enough time under such an illuminant, you will see the illuminant as achromatic. The adaptation to other colors, however, is weak (or “incomplete” in chromatic adaptation parlance)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, so it probably does not make much sense to pick other colors as the white point if you want your user to see your white as achromatic. CIE has standardized a set of what they call Standard Illuminants (D series), each of which approximates a different daylight color. For instance, the D65 standard illuminant approximates noon daylight and is similar to the color of a black-body radiation at a temperature of 6500 K. Many common color spaces, such as the sRGB color space, use D65 as the white point.</p>
<p>Second, CIE 1931 RGB space, and virtually all color spaces, define units so that white, however defined, must be produced by an equal-unit mixture of the primaries. This, again, is a judgment call. One could totally design a color space where white is produced by mixing, say, 2 units of red and 1 unit of green and blue each — nothing wrong with that. It is just more intuitive for most people that white is produced by equal amounts of the primaries.</p>
<p>The <span class="math inline">\(x\)</span>-axis in <a href="#fig-cie1931_rgb_cmf" class="quarto-xref">Figure&nbsp;<span>4.4</span></a> is defined on an equal-energy/power basis. That is, the CMFs are interpreted as showing the amount (units) of the primaries needed to produce spectral lights of equal power. So if we actually mix the three primaries at each wavelength as indicated by the CMFs, we will get a set of spectral lights that have the same power.</p>
</section>
<section id="what-does-a-negative-unit-mean" class="level4">
<h4 class="anchored" data-anchor-id="what-does-a-negative-unit-mean">What Does a Negative Unit Mean?</h4>
<p>If you observe <a href="#fig-cie1931_rgb_cmf" class="quarto-xref">Figure&nbsp;<span>4.4</span></a> carefully, you will see that some CMFs are negative over certain ranges. For instance, the red CMF is negative at 500 <span class="math inline">\(\text{nm}\)</span>. This is perhaps a bit surprising, but mathematically it is entirely possible that some values in <span class="math inline">\([r, g, b]^T\)</span> are negative when solving <a href="#eq-cme" class="quarto-xref">Equation&nbsp;<span>4.3</span></a>. Physically, however, what does it mean to have a negative amount/power of primary light? The right panel in <a href="#fig-cie1931_rgb_cmf" class="quarto-xref">Figure&nbsp;<span>4.4</span></a> provides the intuition. It turns out that it is impossible to find a combination of the three primary lights to match the color of a spectral light at 500 <span class="math inline">\(\text{nm}\)</span>. What does provide a match is to add a little red primary to the target light, and then we can find a combination of the primaries such as the blue and green mixture has the same color as the target light and red primary mixture.</p>
<p>In fact, if you examine the CMFs, you will see that there is a negative contribution from a primary at all but three wavelengths — the only three exceptions are the wavelengths of the three primaries (where two of the primary contributions are zero and the other is positive). This means that no spectral light color (except the three special cases) can be physically produced by mixing the three primaries.</p>
</section>
<section id="representing-colors-using-cmfs" class="level4">
<h4 class="anchored" data-anchor-id="representing-colors-using-cmfs">Representing Colors Using CMFs</h4>
<p>Given a set of CMFs, we can describe the color of a light with a SPD <span class="math inline">\(\Phi(\lambda)\)</span> using the following equation:</p>
<p><span id="eq-spd2rgb"><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
\bar{r}(380), \bar{r}(381), \cdots, \bar{r}(780)\\
\bar{g}(380), \bar{g}(381), \cdots, \bar{g}(780)\\
\bar{b}(380), \bar{b}(381), \cdots, \bar{b}(780)
\end{bmatrix}
\times
\begin{bmatrix}
\Phi(380)\\
\Phi(381)\\
\vdots \\
\Phi(780)\\
\end{bmatrix}
=
\begin{bmatrix}
R\\
G\\
B\\
\end{bmatrix}
\end{aligned}
\tag{4.4}\]</span></span></p>
<p>where <span class="math inline">\(\bar{r}(\lambda)\)</span>, <span class="math inline">\(\bar{g}(\lambda)\)</span>, and <span class="math inline">\(\bar{b}(\lambda)\)</span> are the CMFs, and <span class="math inline">\(R\)</span>, <span class="math inline">\(G\)</span>, and <span class="math inline">\(B\)</span> are the amounts of the three primaries needed to match the color of <span class="math inline">\(\Phi(\lambda)\)</span>.</p>
<p>The CMFs give us another color space, where the color of a light is interpreted as the amount of primary lights needed to match the color of the light. Of course, if we choose a different set of primary lights, we might end up with a new set of CMFs and a new RGB color space.</p>
</section>
</section>
<section id="sec-chpt-hvs-color-cme-cone" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-chpt-hvs-color-cme-cone"><span class="header-section-number">4.2.2</span> Connecting CMFs and Cone Fundamentals</h3>
<p>CMFs and cone fundamentals both yield trichromatic color vision, so they must be inherently related, as they are just different ways of describing the same thing. We show the two are linearly related in theory, and the measurement data of the two match well, too.</p>
<section id="deriving-color-matching-functions-from-cone-fundamentals" class="level4">
<h4 class="anchored" data-anchor-id="deriving-color-matching-functions-from-cone-fundamentals">Deriving Color Matching Functions From Cone Fundamentals</h4>
<p>Given the cone fundamentals, we can derive the CMFs based on the linear system shown in <a href="#eq-cme" class="quarto-xref">Equation&nbsp;<span>4.3</span></a>. The interactive tutorial by <span class="citation" data-cites="zhu2022cone2cmf">Zhu (<a href="references.html#ref-zhu2022cone2cmf" role="doc-biblioref">2022a</a>)</span> walks through the process, which you are invited to go over, and we will describe the main steps here.</p>
<p>In order to construct the CMFs, we have to match the colors of all the spectral lights, which means we have to specify cone-response matching at each wavelength. Using the basic idea of <a href="#eq-cme" class="quarto-xref">Equation&nbsp;<span>4.3</span></a>, we have:</p>
<p><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
\sum R(\lambda)L(\lambda),~ \sum G(\lambda)L(\lambda),~ \sum B(\lambda)L(\lambda)\\
\sum R(\lambda)M(\lambda),~ \sum G(\lambda)M(\lambda),~ \sum B(\lambda)M(\lambda)\\
\sum R(\lambda)S(\lambda),~ \sum G(\lambda)S(\lambda),~ \sum B(\lambda)S(\lambda)\\
\end{bmatrix}
\times
\begin{bmatrix}
r(380),\cdots,r(780)\\
g(380),\cdots,g(780)\\
b(380),\cdots,b(780)\\
\end{bmatrix}
=
\begin{bmatrix}
L(380),\cdots,L(780)\\
M(380),\cdots,M(780)\\
S(380),\cdots,S(780)\\
\end{bmatrix},
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(L(\lambda)\)</span>, <span class="math inline">\(M(\lambda)\)</span>, and <span class="math inline">\(S(\lambda)\)</span> are the cone fundamentals; <span class="math inline">\(L(\lambda_0)\)</span> is the L cone response of the spectral light at a particular wavelength <span class="math inline">\(\lambda_0\)</span>; <span class="math inline">\([r(\lambda_0), g(\lambda_0), b(\lambda_0)]^T\)</span> represents the (to-be-solved-for) power of each primary needed to match the color of the spectral light at <span class="math inline">\(\lambda_0\)</span>; <span class="math inline">\(R(\lambda)\)</span>, <span class="math inline">\(G(\lambda)\)</span>, and <span class="math inline">\(B(\lambda)\)</span> are the SPDs of the primary lights used in the CIE 1931 color matching experiment. The first matrix is a constant matrix given a particular set of CMFs, and we will denote it as the <span class="math inline">\(\mathbf{M}\)</span> matrix. We can solve the system of equations by inverting the first matrix:</p>
<p><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
r(380),\cdots,r(780)\\
g(380),\cdots,g(780)\\
b(380),\cdots,b(780)\\
\end{bmatrix}
=
\mathbf{M}^{-1}
\times
\begin{bmatrix}
L(380),\cdots,L(780)\\
M(380),\cdots,M(780)\\
S(380),\cdots,S(780)\\
\end{bmatrix}.
\end{aligned}
\]</span></p>
<p>To get the CMFs, however, we need to turn the power measure into a unit measure. Recall the requirement that white must be produced by equal units of the primaries. We calculate the power of each primary needed to produce the EEW; let’s denote the solution <span class="math inline">\([r_w, g_w, b_w]^T\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
r_{w}\\
g_{w}\\
b_{w}\\
\end{bmatrix}
=
\mathbf{M}^{-1}
\times
\begin{bmatrix}
L_{w}\\
M_{w}\\
S_{w}\\
\end{bmatrix},
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\([L_w, M_w, S_w]^T\)</span> denotes the total L, M, and S cone responses of EEW. For the so-calculated <span class="math inline">\([r_w, g_w, b_w]\)</span> to represent equal units, the last step is to scale <span class="math inline">\([\bar{r}(\lambda), \bar{g}(\lambda), \bar{b}(\lambda)]^T\)</span> at each <span class="math inline">\(\lambda\)</span> by <span class="math inline">\([r_w, g_w, b_w]\)</span>:</p>
<p><span id="eq-cone2cmf"><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
\bar{r}(380), \cdots, \bar{r}(780)\\
\bar{g}(380), \cdots, \bar{g}(780)\\
\bar{b}(380), \cdots, \bar{b}(780)
\end{bmatrix}
&amp;=
\begin{bmatrix}
r_w,~0,~0\\
0,~g_w,~0\\
0,~0,~b_w
\end{bmatrix}
\times
\begin{bmatrix}
r(380),\cdots,r(780)\\
g(380),\cdots,g(780)\\
b(380),\cdots,b(780)\\
\end{bmatrix}\\
&amp;=
\begin{bmatrix}
r_w,~0,~0\\
0,~g_w,~0\\
0,~0,~b_w
\end{bmatrix}
\times
\mathbf{M}^{-1}
\times
\begin{bmatrix}
L(380),\cdots,L(780)\\
M(380),\cdots,M(780)\\
S(380),\cdots,S(780)\\
\end{bmatrix}\\
&amp;=
\mathbf{T}_{lms2rgb}
\times
\begin{bmatrix}
L(380),\cdots,L(780)\\
M(380),\cdots,M(780)\\
S(380),\cdots,S(780)\\
\end{bmatrix},
\end{aligned}
\tag{4.5}\]</span></span></p>
<p>where <span class="math inline">\([\bar{r}(\lambda), \bar{g}(\lambda), \bar{b}(\lambda)]^T\)</span> gives us the unit measure, i.e., the values of the CMFs, at each <span class="math inline">\(\lambda\)</span>.</p>
</section>
<section id="cone-space-and-rgb-space-are-related-by-a-linear-transformation" class="level4">
<h4 class="anchored" data-anchor-id="cone-space-and-rgb-space-are-related-by-a-linear-transformation">Cone Space and RGB Space are Related by a Linear Transformation</h4>
<p>The rightmost matrix in <a href="#eq-cone2cmf" class="quarto-xref">Equation&nbsp;<span>4.5</span></a> is the cone fundamentals written out in the matrix form, and the leftmost matrix in <a href="#eq-cone2cmf" class="quarto-xref">Equation&nbsp;<span>4.5</span></a> is the CMFs written out at discrete wavelengths. So <a href="#eq-cone2cmf" class="quarto-xref">Equation&nbsp;<span>4.5</span></a> essentially describes a linear transformation from the cone fundamentals to the RGB CMFs, where the transformation is dictated by <span class="math inline">\(\mathbf{T}_{lms2rgb}\)</span>. We can look at this in two ways. One, we can think of the cone fundamentals as the CMFs in the cone space: they tell us how much of each cone response we need to match the color of a spectral light. Two, just like how we can construct the spectral locus from cone fundamentals, the RGB CMFs also give us a way to construct the spectral locus — in the RGB space. <span class="math inline">\(\mathbf{T}_{lms2rgb}\)</span> essentially transforms these two representations of the spectral locus, and this is visualized in <a href="#fig-cs_linear_transformations" class="quarto-xref">Figure&nbsp;<span>4.6</span></a>.</p>
<div id="fig-cs_linear_transformations" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cs_linear_transformations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/cs_linear_transformations.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cs_linear_transformations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.6: The spectral locus in the LMS cone space, CIE 1931 RGB space, and CIE 1931 XYZ space. The color spaces are a linear transformation away from each other. From the interactive tutorials in <span class="citation" data-cites="zhu2022cone2cmf">Zhu (<a href="references.html#ref-zhu2022cone2cmf" role="doc-biblioref">2022a</a>)</span> and <span class="citation" data-cites="zhu2022xyz">Zhu (<a href="references.html#ref-zhu2022xyz" role="doc-biblioref">2022b</a>)</span>.
</figcaption>
</figure>
</div>
<p>There is something deeper: <span class="math inline">\(\mathbf{T}_{lms2rgb}\)</span> not only transforms the spectral locus, it transforms the entire coordinate system from the cone space to the RGB space. In other words, it transforms every single color in the LMS space to its corresponding coordinates in the CIE 1931 RGB space. The way to think about this is to ask: given that the cone space and the CIE 1931 RGB space provide two ways to represent the color of a light <span class="math inline">\(\Phi\)</span>, how are the cone-space representation <span class="math inline">\([L_c, M_c, S_c]\)</span> and the RGB-space representation <span class="math inline">\([R_c, G_c, B_c]\)</span> related? Using <a href="#eq-spd2cones" class="quarto-xref">Equation&nbsp;<span>4.2</span></a>, <a href="#eq-spd2rgb" class="quarto-xref">Equation&nbsp;<span>4.4</span></a>, and <a href="#eq-cone2cmf" class="quarto-xref">Equation&nbsp;<span>4.5</span></a>, it is easy to see that they are related by a linear transformation through <span class="math inline">\(\mathbf{T}_{lms2rgb}\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
R_c\\
G_c\\
B_c
\end{bmatrix}
=
\mathbf{T}_{lms2rgb}
\times
\begin{bmatrix}
L_c\\
M_c\\
S_c
\end{bmatrix}.
\end{aligned}
\]</span></p>
</section>
<section id="cone-responses-fully-explain-psychophysical-color-matching" class="level4">
<h4 class="anchored" data-anchor-id="cone-responses-fully-explain-psychophysical-color-matching">Cone Responses Fully Explain Psychophysical Color Matching</h4>
<p>The CMFs can be both experimentally measured and calculated if we know the cone fundamentals (through a linear transformation), but do the mathematical estimation and the measurement data match? If so, we can say that the physiological process of encoding light power as cone responses can fully account for the color matching experiments in psychophysics.</p>
<p><span class="citation" data-cites="baylor1987spectral">Baylor, Nunn, and Schnapf (<a href="references.html#ref-baylor1987spectral" role="doc-biblioref">1987</a>)</span> performed one such comparison and showed the two sets of data matched very well. The results are shown in <a href="#fig-cmf_coneresponses_match" class="quarto-xref">Figure&nbsp;<span>4.7</span></a>, where the smooth curves are from <span class="citation" data-cites="stiles1955interim">W. Stiles and Burch (<a href="references.html#ref-stiles1955interim" role="doc-biblioref">1955</a>)</span>, which uses a different set of primaries and white point than those used in the CIE 1931 RGB CMFs. The markers are the predicted CMFs through a linear regression from the cone fundamentals measured from macaques, after accounting for ocular and macular absorptions<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<div id="fig-cmf_coneresponses_match" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cmf_coneresponses_match-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/cmf_coneresponses_match.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cmf_coneresponses_match-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.7: Smooth curves are the CMFs from <span class="citation" data-cites="stiles1955interim">W. Stiles and Burch (<a href="references.html#ref-stiles1955interim" role="doc-biblioref">1955</a>)</span>, which uses a different set of primaries and white point than those used in the CIE 1931 RGB CMFs. The markers are the predicted CMFs based on the cone fundamentals measured from macaques. From <span class="citation" data-cites="baylor1987spectral">Baylor, Nunn, and Schnapf (<a href="references.html#ref-baylor1987spectral" role="doc-biblioref">1987, fig. 4A</a>)</span>.
</figcaption>
</figure>
</div>
<p>In fact, the modern versions of the cone fundamentals are constructed so that they are precisely a linear transformation away from some RGB CMFs. For instance, the CIE 2006 “physiologically-relevant” LMS functions (based on <span class="citation" data-cites="stockman1999spectral">Stockman, Sharpe, and Fach (<a href="references.html#ref-stockman1999spectral" role="doc-biblioref">1999</a>)</span> and <span class="citation" data-cites="stockman2000spectral">Stockman and Sharpe (<a href="references.html#ref-stockman2000spectral" role="doc-biblioref">2000</a>)</span>) are constructed by 1) first experimentally measuring the cone fundamentals in psychophysics (from color-vision deficient observers), 2) calibrating the results with a set of RGB CMFs in <span class="citation" data-cites="stiles1959npl">W. S. Stiles and Burch (<a href="references.html#ref-stiles1959npl" role="doc-biblioref">1959</a>)</span> (which uses a different set of primary lights from the CIE 1931 RGB CMFs) to derive a best-fit linear transformation, and 3) applying the linear transformation to the CMFs to derive a “clean” set of cone fundamentals.</p>
</section>
</section>
</section>
<section id="sec-chpt-hvs-color-oppo" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-chpt-hvs-color-oppo"><span class="header-section-number">4.3</span> Post-Receptoral Color Encoding: Opponent Processes</h2>
<p>Cone-response encoding can perfectly explain the trichromatic theory of color vision, where any color can be mixed from three other colors. The trichromatic theory of color has a perfect neural basis: the human visual system has three classes of cones, so color is a three-dimensional system. But the trichromatic theory is not concerned with our subjective experience of color that we encounter on a daily basis. Here are two examples that highlight the difference between perceptual color experience and physical color mixing.</p>
<p>First, when we see an orange color, we feel that it has a little bit of yellow in it and a little bit of red in it. Even though there are many ways to produce orange, some of which do not require mixing yellow and red lights, we cannot help but perceptually feel that orange combines yellow and red. Second, when we mix a red light with a green light, we get yellow, but perceptually, if we stare at yellow, most people would not say that yellow has contributions from red or green.</p>
<p><span class="citation" data-cites="hering1878lehre">Hering (<a href="references.html#ref-hering1878lehre" role="doc-biblioref">1878</a>)</span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> hypothesized that, perceptually, there are four primary hues, which form two opposing pairs. Opposing hues cannot co-exist, perceptually, in a color. Any hue can be produced by combining two non-opposing hues. The four hues are: the Yellow and Blue opposing hues and the Red and Green opposing hues. Hering also considered light-dark as another opposing pair: no color can be simultaneously light and dark. In his theory, color vision is still a three-dimensional system, where the three axes are: Yellow-Blue axis, Red-Green axis, and light-dark axis. Any color, a point in this 3D space, is produced by mixing some amount of Red <em>or</em> Green, some amount of Yellow <em>or</em> Blue, and some level of lightness.</p>
<p>The opponent theory seems to contradict the trichromatic theory, which was dominant for the most part of the history — because it has both a solid psychophysical and neural basis. First, the color matching experiment quantitatively shows that, behaviorally, humans could match a color by mixing three other colors. In contrast, Hering had only a qualitative description of perceptual mixing. His description was something like “<em>after this blue comes blue of increasing redness…(blue violet, red violet, purple red), until the last trace of blueness vanishes in a true red.</em>” <span class="citation" data-cites="hering1964outlines">(<a href="references.html#ref-hering1964outlines" role="doc-biblioref">Hering 1964, p. 41</a>)</span>. To Hering’s theory’s rescue, Jameson and Hurvish performed a now-famous experiment, called the <strong>hue cancellation experiment</strong>, providing the first quantitative, psychophysical evidence of the opponent processes <span class="citation" data-cites="jameson1955some hurvich1957opponent">(<a href="references.html#ref-jameson1955some" role="doc-biblioref">Jameson and Hurvich 1955</a>; <a href="references.html#ref-hurvich1957opponent" role="doc-biblioref">Hurvich and Jameson 1957</a>)</span>.</p>
<p>Second, the trichromatic theory has a clear neural and physiological basis (i.e., wavelength encoding by cone responses), and the physiological data match the behavioral data very well, as shown before. So a natural question is: are there neural mechanisms that can account for the opponent processes and, if so, how does that mechanism relate to the encoding mechanisms by the cone photoreceptors?</p>
<p>It turns out that we do need a set of new neural mechanisms to start accounting for the opponent processes. Not only do these new mechanisms <em>not</em> contradict the cone encoding mechanisms, they build on top of the cone encodings and operate post-receptorally. <span class="citation" data-cites="schrodinger1925verhaltnis">Schrödinger (<a href="references.html#ref-schrodinger1925verhaltnis" role="doc-biblioref">1925</a>)</span><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> synthesized the earlier <em>zone theory</em> by <span class="citation" data-cites="kries1905ubersicht">Kries (<a href="references.html#ref-kries1905ubersicht" role="doc-biblioref">1905</a>)</span> and argued that the trichromatic theory and the opponent processes were nothing more than different stages of color encoding in the visual system. That said, while these new neural mechanisms seem to have what it takes to form the basis for the behavioral opponent observations, they do not fully explain those observations yet; the link between the two is still very much an open research question.</p>
<p>The rest of this section will discuss the hue cancellation experiment and the quest for a neural and physiological basis in more detail.</p>
<section id="sec-chpt-hvs-color-oppo-hue" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="sec-chpt-hvs-color-oppo-hue"><span class="header-section-number">4.3.1</span> Hue Cancellation Experiment</h3>
<p>In a landmark study, <span class="citation" data-cites="jameson1955some">Jameson and Hurvich (<a href="references.html#ref-jameson1955some" role="doc-biblioref">1955</a>)</span> (while working for Eastman Kodak in Rochester) quantitatively measured the perceptual color opponency using a behavioral experiment. The participant is given a test light and is asked to first judge whether the light appeared blue-ish or yellow-ish. If the test light is judged to be blue-ish, the participant is then given a yellow-ish <em>cancellation light</em> (e.g., a spectral light at 588 <span class="math inline">\(\text{nm}\)</span>) and is asked to adjust the intensity of the cancellation light so that the mixture of the test and cancellation light perceptually appears neither blue nor yellow. If the test light is judged to be yellow-ish, the participant is then asked to adjust the power of a blue-ish cancellation light (e.g., a spectral light at 467 <span class="math inline">\(\text{nm}\)</span>) so that the test-cancellation mixture is again neither blue nor yellow. We sweep the spectrum from about 400 <span class="math inline">\(\text{nm}\)</span> to 700 <span class="math inline">\(\text{nm}\)</span> for the test light of equal energy, and record the energy of yellow or blue cancellation light needed at each step.</p>
<div id="fig-hue_cancellation_experiment" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hue_cancellation_experiment-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/hue_cancellation_experiment_new.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hue_cancellation_experiment-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.8: Measurements from the hue cancellation experiment in <span class="citation" data-cites="jameson1955some">Jameson and Hurvich (<a href="references.html#ref-jameson1955some" role="doc-biblioref">1955</a>)</span>. (a) the Blue-Yellow measurement; the <span class="math inline">\(y\)</span>-axis shows the intensity of the Yellow/Blue cancellation light, i.e., the relative strength of the “Blue-ness” and “Yellow-ness” in the test light. (b) the Red-Green measurement; notice the two zero-crossings for Green. (c) The same data as A and B except we invert the Blue and Green curves so the <span class="math inline">\(y\)</span>-axis is interpreted as the strength of Red-ness and Yellow-ness.
</figcaption>
</figure>
</div>
<p>The result for one subject is shown in <a href="#fig-hue_cancellation_experiment" class="quarto-xref">Figure&nbsp;<span>4.8</span></a> (a), where the <span class="math inline">\(y\)</span>-axis is showing the intensity of the yellow and blue cancellation light, i.e., the strength of blue-ness and yellow-ness of the test light. For the reference, we attached a colorbar showing roughly the color of the test light between 400 <span class="math inline">\(\text{nm}\)</span> and 700 <span class="math inline">\(\text{nm}\)</span>, but take this color visualization as a huge grain of salt, since it is almost certain that your display will not be able to actually render the colors of the spectral lights.</p>
<p>Unsurprisingly, we get two peaks, one in the blue range and the other in the yellow range, indicating, respectively, that the participant needs a lot of the yellow and blue cancellation lights in those two regions. The test light at about 500 <span class="math inline">\(\text{nm}\)</span> requires no cancellation light, indicating light there, which roughly has a green-ish color is yellow-blue neutral: it naturally looks neither blue nor yellow.</p>
<p>Jameson and Hurvich then repeated the same experiment, but this time measuring the red-green opponent process, where the two cancellation lights are a 700 <span class="math inline">\(\text{nm}\)</span> red-ish light and a 490 <span class="math inline">\(\text{nm}\)</span> green-ish light. The results are in <a href="#fig-hue_cancellation_experiment" class="quarto-xref">Figure&nbsp;<span>4.8</span></a> (b), where the <span class="math inline">\(y\)</span>-axis indicates the amount of red-ness and green-ness in the test light. Two observations are worth noting. First, while it is unsurprising that long-wavelength lights have a strong red component, it is perhaps surprising that short-wavelength lights appear red-ish too. That, however, becomes less surprising when we realize that short-wavelength lights (shorter than pure blue) appear violet, which perceptually is a red-ish blue. Second, because of the two red-ish regions over the spectrum, the entire red-green curve has two zero-crossings, one at about 470 <span class="math inline">\(\text{nm}\)</span> and the other near 570 <span class="math inline">\(\text{nm}\)</span>: pure blue and pure yellow look neither green nor red.</p>
<p><a href="#fig-hue_cancellation_experiment" class="quarto-xref">Figure&nbsp;<span>4.8</span></a> (c) summarizes the two sets of data by inverting the blur section of the curve in (a) and the green section of the curve in (b). That way, the <span class="math inline">\(y\)</span>-axis can be simply interpreted as the relative strength of red-ness and yellow-ness over the spectrum.</p>
</section>
<section id="sec-chpt-hvs-color-oppo-light" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="sec-chpt-hvs-color-oppo-light"><span class="header-section-number">4.3.2</span> Light-Dark Mechanism and Luminous Efficiency Function</h3>
<p><span class="citation" data-cites="hurvich1957opponent">Hurvich and Jameson (<a href="references.html#ref-hurvich1957opponent" role="doc-biblioref">1957</a>)</span> also performed a measurement of the white-black (light-dark) opponent process, asking participants to assess the “whiteness” of spectral lights between 400 <span class="math inline">\(\text{nm}\)</span> and 700 <span class="math inline">\(\text{nm}\)</span> of equal power. %Intuitively, the measurement tells us the perceived brightness of lights at different wavelengths. A more modern method to measure the luminance mechanism is heterochromatic flicker photometry, where we alternate between a test light and a fixed reference light at a frequency of, say, 25 Hz. We adjust the intensity of the test light so that the alternation produces no visual flickering, at which point we say the two lights produce the same level of luminance <span class="citation" data-cites="sharpe2005luminous sharpe2011luminous">(<a href="references.html#ref-sharpe2005luminous" role="doc-biblioref">Sharpe et al. 2005</a>, <a href="references.html#ref-sharpe2011luminous" role="doc-biblioref">2011</a>)</span>. We again sweep the entire visible spectrum for the test light and record the relative intensity at each step. The so-obtained function is called the <strong>luminance efficiency function</strong> (LEF). The dashed gray curve in <a href="#fig-lef" class="quarto-xref">Figure&nbsp;<span>4.9</span></a> shows a modern version of the photopic LEF (the so-called CIE 2008 “physiologically-relevant” 2-deg function)<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<div id="fig-lef" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lef-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/lef.svg" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lef-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.9: The grey solid curve is the scotopic luminous efficiency function (CIE 1951 standard; based on <span class="citation" data-cites="wald1945human">Wald (<a href="references.html#ref-wald1945human" role="doc-biblioref">1945</a>)</span> and <span class="citation" data-cites="crawford1949scotopic">Crawford (<a href="references.html#ref-crawford1949scotopic" role="doc-biblioref">1949</a>)</span>). The grey dashed curve is the photopic luminous efficiency function (CIE 2008 “physiologically-relevant” 2-deg function; based on <span class="citation" data-cites="sharpe2005luminous">Sharpe et al. (<a href="references.html#ref-sharpe2005luminous" role="doc-biblioref">2005</a>)</span> and <span class="citation" data-cites="sharpe2011luminous">Sharpe et al. (<a href="references.html#ref-sharpe2011luminous" role="doc-biblioref">2011</a>)</span>) The other three curves are the cone fundamentals, shown for the reference.
</figcaption>
</figure>
</div>
<p>The way to interpret the LEF is that the <span class="math inline">\(y\)</span>-axis is inversely proportional to the light power at each wavelength needed to produce the same level of perceptual brightness. The photopic LEF at 509 <span class="math inline">\(\text{nm}\)</span> is about 0.5, half of that at 555 <span class="math inline">\(\text{nm}\)</span>. It means we need twice as much power at 509 <span class="math inline">\(\text{nm}\)</span> to produce the same level of brightness as that at 555 <span class="math inline">\(\text{nm}\)</span>. It also explains the word “efficiency” in the name: if a wavelength needs less power to produce a criterion level of brightness, the wavelength is more efficient in its use of power. The way LEF is obtained, however, does <em>not</em> permit us to interpret the result as the relative brightness at different wavelengths. That is, 555 <span class="math inline">\(\text{nm}\)</span> is not twice as bright as 509 <span class="math inline">\(\text{nm}\)</span>. This is similar to our interpretation of the cone fundamentals.</p>
<p>For comparison, the gray curve in <a href="#fig-lef" class="quarto-xref">Figure&nbsp;<span>4.9</span></a> is the scotopic LEF. The CIE 1951 scotopic LEF synthesizes the psychophysical measurements from <span class="citation" data-cites="wald1945human">Wald (<a href="references.html#ref-wald1945human" role="doc-biblioref">1945</a>)</span> and <span class="citation" data-cites="crawford1949scotopic">Crawford (<a href="references.html#ref-crawford1949scotopic" role="doc-biblioref">1949</a>)</span>. Both used a threshold method where they measured the light intensity at each wavelength needed to produce a just detectable flash. Note that the photopic LEF peaks at about 555 <span class="math inline">\(\text{nm}\)</span> and the scotopic LEF peaks at about 507 <span class="math inline">\(\text{nm}\)</span>.</p>
<p>As a result, the relative brightness of longer-wavelength colors and shorter-wavelength colors is inverted when our vision transitions from the cone-mediated photopic vision to the rod-mediated scotopic vision. This phenomenon is called the <strong>Purkinje shift</strong>. In the words of <span class="citation" data-cites="glassner1995principles">Glassner (<a href="references.html#ref-glassner1995principles" role="doc-biblioref">1995, p. 21</a>)</span>, “<em>When the sun is still above the horizon, your cones are active, and the yellow flower will appear lighter than the leaves because yellow is closer to peak of the photopic sensitivity curve than dark green. When the sun has set and light levels are lower, your rods are the principal sensors. The scotopic sensitivity curve is more responsive in the shorter wavelengths, so the green leaves will now appear relatively lighter than the yellow flower, though both will of course be much darker due to the lower amount of incident light.</em>”</p>
<div id="fig-hue_cancellation_experiment_white" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hue_cancellation_experiment_white-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/hue_cancellation_experiment_white.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hue_cancellation_experiment_white-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.10: The solid curve is the white-black measurement, indicating the amount of whiteness in a light across the spectrum. The white-black curve in theory matches the luminous efficiency function. The two plots are for two participants. From <span class="citation" data-cites="hurvich1957opponent">Hurvich and Jameson (<a href="references.html#ref-hurvich1957opponent" role="doc-biblioref">1957, fig. 4</a>)</span>.
</figcaption>
</figure>
</div>
<p>Combining the light-dark (luminance efficiency) curve with the two opponent curves in <a href="#fig-hue_cancellation_experiment" class="quarto-xref">Figure&nbsp;<span>4.8</span></a> (c), we again have three spectral sensitivity functions. <a href="#fig-hue_cancellation_experiment_white" class="quarto-xref">Figure&nbsp;<span>4.10</span></a> puts the three opponent measurements in one plot (the two plots are for two separate participants). Compare this plot with the cone fundamentals in <a href="#fig-normalized_cone_fundamentals" class="quarto-xref">Figure&nbsp;<span>4.1</span></a>. Once again, a light with its SPD can be reduce to three-dimensional point, using <a href="#eq-spd2cones_int" class="quarto-xref">Equation&nbsp;<span>4.1</span></a>, except 1) instead of the three cone fundamentals we use the three opponent functions and 2) instead of getting the three cone responses we get the strength of the three opponent mechanisms. Effectively, the hue cancellation curves and the light-dark curve construct a new three-dimensional color space. We call this the <strong>hue-opponent</strong> space, and we will return to this space in <a href="#sec-chpt-hvs-color-oppobasis-model" class="quarto-xref"><span>Section 4.4.3</span></a> and discuss how this space relates to the colorimetric spaces we have discussed so far.</p>
</section>
</section>
<section id="sec-chpt-hvs-color-oppobasis" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="sec-chpt-hvs-color-oppobasis"><span class="header-section-number">4.4</span> Neural and Physiological Basis of Opponent Processes</h2>
<p>The hue cancellation experiment solidifies Hering’s opponent theory at the level of psychophysics. But recall <a href="intro.html#fig-abstractions" class="quarto-xref">Figure&nbsp;<span>1.2</span></a>; any behavioral responses measured through psychophysics are fundamentally the result of the underlying neural and physiological mechanisms. So the next natural step in the scientific quest is to understand what underlying neural and physiological mechanisms can account for the behavioral opponent processes.</p>
<div id="fig-opponent_lgn_cells" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-opponent_lgn_cells-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/opponent_lgn_cells.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-opponent_lgn_cells-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.11: Responses of six typical classes of LGN neurons to incremental flashes of varying wavelengths. <span class="math inline">\(y\)</span>-axis shows the spikes/second under spectral lights of equal energy. Each curve represents a particular energy level. (A): these cells are excited (activity exceeds the spontaneous firing rate) by red hues and inhibited by green hues, denoted +R-G cells. (B): +G-R cells. (C): +B-Y cells. (D): +Y-B cells. (E): non-opponent excitatory cell. (F): non-opponent inhibitory cell. From <span class="citation" data-cites="devalois1990spatial">DeValois and DeValois (<a href="references.html#ref-devalois1990spatial" role="doc-biblioref">1990, fig. 7.5</a>)</span>, which is adapted from <span class="citation" data-cites="de1966analysis">R. L. De Valois, Abramov, and Jacobs (<a href="references.html#ref-de1966analysis" role="doc-biblioref">1966, figs. 9–12, 15–16</a>)</span>.
</figcaption>
</figure>
</div>
<section id="sec-chpt-hvs-color-oppobasis:neurons" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="sec-chpt-hvs-color-oppobasis:neurons"><span class="header-section-number">4.4.1</span> Spectrally-Opponent and Non-Opponent Neurons</h3>
<p>There are RGC and LGN neurons that show opponent properties. <span class="citation" data-cites="svaetichin1953cone">G. Svaetichin (<a href="references.html#ref-svaetichin1953cone" role="doc-biblioref">1953</a>)</span>, <span class="citation" data-cites="svaetichin1956spectral">G. Svaetichin (<a href="references.html#ref-svaetichin1956spectral" role="doc-biblioref">1956</a>)</span>, and <span class="citation" data-cites="svaetichin1958retinal">G. Svaetichin and MacNichol Jr (<a href="references.html#ref-svaetichin1958retinal" role="doc-biblioref">1958</a>)</span> are the first to identify opponent neurons in a fish retina; they recorded from horizontal cells. <span class="citation" data-cites="de1958response">R. De Valois et al. (<a href="references.html#ref-de1958response" role="doc-biblioref">1958</a>)</span> and <span class="citation" data-cites="de1966analysis">R. L. De Valois, Abramov, and Jacobs (<a href="references.html#ref-de1966analysis" role="doc-biblioref">1966</a>)</span> measured the responses of LGN neurons in macaques using monochromatic lights, and found spectral opponent neurons, which get excited or inhibited depending on the wavelengths. (A – D) in <a href="#fig-opponent_lgn_cells" class="quarto-xref">Figure&nbsp;<span>4.11</span></a> show the recordings of four classes of opponent cells. (A) shows a class of LGN cells whose firing rate exceeds the spontaneous rate under long-wavelength, red-ish lights and whose firing rate drops below the spontaneous rate under short-wavelength, blue-is lights. These cells are denoted +R-G (red-ON/green-OFF) cells. (B), (C), and (D) show that there exists +G-R, +B-Y, and +Y-B cells, respectively.</p>
<p><span class="citation" data-cites="de1966analysis">R. L. De Valois, Abramov, and Jacobs (<a href="references.html#ref-de1966analysis" role="doc-biblioref">1966</a>)</span> also identified non-opponent cells, whose responses are universally inhibited or excited across the spectrum, as shown in (E) and (F) in <a href="#fig-opponent_lgn_cells" class="quarto-xref">Figure&nbsp;<span>4.11</span></a>, respectively. These neurons are still wavelength-sensitive, but their responses are either universally excited or universally inhibited across the spectrum, unlike the spectrally-opponent neurons whose responses change polarity across the spectrum.</p>
</section>
<section id="sec-chpt-hvs-color-oppobasis-cir" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="sec-chpt-hvs-color-oppobasis-cir"><span class="header-section-number">4.4.2</span> Potential Neural Circuitries</h3>
<p>What are some of the underlying visual pathways that could potentially give rise to these spectral tuning curves? Recall that LGN cells/RGCs have antagonistic Receptive Fields (RFs), and the antagonism seems to be a perfect mechanism to implement the opponent process. This suggests that in order to understand the opponent cells we must study their RF structures.</p>
<p>Much of the early work is done by <span class="citation" data-cites="wiesel1966spatial">Wiesel and Hubel (<a href="references.html#ref-wiesel1966spatial" role="doc-biblioref">1966</a>)</span>. While De Valois and his collaborators used diffuse lights to illuminate a large visual field, <span class="citation" data-cites="wiesel1966spatial">Wiesel and Hubel (<a href="references.html#ref-wiesel1966spatial" role="doc-biblioref">1966</a>)</span> used both small spot lights that stimulated the center of the RF and larger lights that covered the entire RF. By comparing the responses under these two stimuli across different wavelengths (and white), they suggested potential RF structures of both opponent and non-opponent cells in macaque LGN. <span class="citation" data-cites="derrington1984chromatic">Derrington, Krauskopf, and Lennie (<a href="references.html#ref-derrington1984chromatic" role="doc-biblioref">1984</a>)</span> designed a clever experiment that explicitly tied cone responses to LGN cell responses and thus more directly revealed the RF structure.</p>
<p>Before getting into the details, it is worth reminding ourselves that studying the LGN cells and studying the RGCs are equivalent (<a href="hvs-intro.html#sec-chpt-hvs-percept-postretina-lgn" class="quarto-xref"><span>Section 2.5.1</span></a>), since different classes of RGCs project to distinct LGN layers with virtually the same RFs: midget RGCs project to the Parvocellular layers (P cells) in the LGN (forming the P pathway/stream), parasol RGCs project to the Magnocellular layers (M cells) in the LGN (forming the M pathway/stream), and bistratetified RGCs project to the Koniocellular layers (K cells) in the LGN (forming the K pathway/stream).</p>
<section id="y-b-opponent-cells" class="level4">
<h4 class="anchored" data-anchor-id="y-b-opponent-cells">Y-B Opponent Cells</h4>
<p>The visual pathway for the Y-B opponent cells seems to be clear. <span class="citation" data-cites="derrington1984chromatic">Derrington, Krauskopf, and Lennie (<a href="references.html#ref-derrington1984chromatic" role="doc-biblioref">1984</a>)</span> showed that some LGN cells receive antagonistic inputs from S cone vs.&nbsp;L and M cones. <span class="citation" data-cites="dacey1994blue">Dacey and Lee (<a href="references.html#ref-dacey1994blue" role="doc-biblioref">1994</a>)</span> later identified that the small bistratified RGCs (which project to the K cells in the LGN) are responsible for carrying such signals. The small bistratified RGCs are excited by S cone responses and inhibited by L and M cone responses (or vice versa). Since blue-ish lights produce strong S cone responses and red/green lights produce strong L/M cone responses (recall red + green is yellow), it stands to reason that if a cell is excited by S cones and inhibited by L and M cones, it would give a vigorous on-response under blue lights and a vigorous off-response under yellow lights, producing the kind of yellow-ON/blue-OFF spectral tuning curve that we see in <a href="#fig-opponent_lgn_cells" class="quarto-xref">Figure&nbsp;<span>4.11</span></a> (C).</p>
<div id="fig-yb_pathway" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-yb_pathway-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/yb_pathway.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-yb_pathway-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.12: The small bistratefied RGCs might be the substrate for the Y-B pathway. (A): illustration of the receptive field structure of a small bistratefied RGC, which is S-on and L/M-off (there are also S-off and L/M-on ones); from <span class="citation" data-cites="rodieck1998first">Rodieck (<a href="references.html#ref-rodieck1998first" role="doc-biblioref">1998, p. 348</a>)</span>. (B): a small bistratefied RGC receives excitatory inputs from S cones through the S-cone bipolar cells and inhibitory inputs from L and M cones through another class of bipolar cells; from <span class="citation" data-cites="rodieck1998first">Rodieck (<a href="references.html#ref-rodieck1998first" role="doc-biblioref">1998, p. 346</a>)</span>. (C): membrane potential and spike rate of small bistratified cells under periodic, out-of-phase blue-yellow lights; adapted from <span class="citation" data-cites="dacey1994blue">Dacey and Lee (<a href="references.html#ref-dacey1994blue" role="doc-biblioref">1994, fig. 3C</a>)</span>.
</figcaption>
</figure>
</div>
<p><a href="#fig-yb_pathway" class="quarto-xref">Figure&nbsp;<span>4.12</span></a> (A) illustrates the potential Receptive Field (RF) of a yellow-ON/blue-OFF small bistratefied cell, and (B) shows the neutral circuitry that gives rise to such an RF (but also see <span class="citation" data-cites="field2007spatial">Field et al. (<a href="references.html#ref-field2007spatial" role="doc-biblioref">2007</a>)</span>). The small bistratefied RGC have a center-only RF, which receives excitatory responses from a S-cone bipolar cell and inhibitory responses from another class of bipolar cells that are connected to L and M cones. <span class="citation" data-cites="dacey1994blue">Dacey and Lee (<a href="references.html#ref-dacey1994blue" role="doc-biblioref">1994</a>)</span> records both the membrane potential and the spiking rate of a small bistratified RGC, shown in (C), under periodic, out-of-phase blue and yellow (red+green) lights. The cell’s responses are the strongest under maximum yellow light (maximum excitatory S cone responses) and minimum blue lights (minimum inhibitory L and M cone responses).</p>
</section>
<section id="r-g-opponent-cells" class="level4">
<h4 class="anchored" data-anchor-id="r-g-opponent-cells">R-G Opponent Cells</h4>
<p><span class="citation" data-cites="derrington1984chromatic">Derrington, Krauskopf, and Lennie (<a href="references.html#ref-derrington1984chromatic" role="doc-biblioref">1984</a>)</span> showed that most of the midget RGCs (and thus P cells in LGN) are either excited by L cone responses and inhibited by M cone responses (L-ON/M-OFF) or the other way around. Given that, loosely, L cones are excited by red-ish lights but not so much by green-ish lights and M cones behave oppositely, it stands to reason that L-ON/M-OFF cells produce vigorous on-responses (above spontaneous rate) under red lights and vigorous off-responses (below spontaneous rate) under green lights, giving a spectral tuning curves shown in <a href="#fig-opponent_lgn_cells" class="quarto-xref">Figure&nbsp;<span>4.11</span></a> (A).</p>
<p>The actual RF structure of these cells takes two forms <span class="citation" data-cites="wiesel1966spatial">(<a href="references.html#ref-wiesel1966spatial" role="doc-biblioref">Wiesel and Hubel 1966</a>)</span>. Some of these cells have a center-surround RF, so there are four combinations: L+/M- (L center-ON/M surround-OFF), L-/M+, M-/L+, and M+/L-. Other midget RGCs have no center-surround arrangement. The excitatory and inhibitory regions have the same spatial extent. Either way, signals from the L cones and M cones are antagonistic in these cells.</p>
</section>
<section id="non-opponent-cells" class="level4">
<h4 class="anchored" data-anchor-id="non-opponent-cells">Non-Opponent Cells</h4>
<p>Finally, the parasol RGCs (and thus M cells in LGN) seem to be the most probable source for the luminance opponent mechanism <span class="citation" data-cites="lee1988physiological">(<a href="references.html#ref-lee1988physiological" role="doc-biblioref">B. Lee, Martin, and Valberg 1988</a>)</span>. These cells do have a center-surround RF but the L cones and M cones contribute to both the center and the surround <span class="citation" data-cites="wiesel1966spatial">(<a href="references.html#ref-wiesel1966spatial" role="doc-biblioref">Wiesel and Hubel 1966</a>)</span>; S cones seem to be contribute little, if any, to these cells <span class="citation" data-cites="lennie1993luminance">(<a href="references.html#ref-lennie1993luminance" role="doc-biblioref">Lennie, Pokorny, and Smith 1993</a>)</span>. When the total excitation by the L and M cones to the center out-weighs the total inhibition to the surround, the entire cell appears to be excited by L and M cone responses, giving a broadband, non-opponent spectral tuning curve in <a href="#fig-opponent_lgn_cells" class="quarto-xref">Figure&nbsp;<span>4.11</span></a> (E); otherwise we see a tuning curve like <a href="#fig-opponent_lgn_cells" class="quarto-xref">Figure&nbsp;<span>4.11</span></a> (F).</p>
<!-- See Dowling for this as well. -->
</section>
</section>
<section id="sec-chpt-hvs-color-oppobasis-model" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="sec-chpt-hvs-color-oppobasis-model"><span class="header-section-number">4.4.3</span> A Cone-Opponent Model for Color-Opponent Mechanisms</h3>
<p>It is clear that there are cells that receive opponent cone signals; the spectral tuning curves of these cells seem to largely account for the perceptual opponent mechanisms. Based on these observations, <span class="citation" data-cites="derrington1984chromatic">Derrington, Krauskopf, and Lennie (<a href="references.html#ref-derrington1984chromatic" role="doc-biblioref">1984</a>)</span> proposed a <em>cone-opponent</em> color space, which is now commonly used (in color science and, to a large extent, visual neuroscience) to give a first-order approximation of the perceptual color-opponent processes. The color space is now famously known as the DKL color space<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<ul>
<li>The Y-B channel is given by <span class="math inline">\(a\)</span>S-(<span class="math inline">\(b\)</span>L+<span class="math inline">\(c\)</span>M), where <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(c\)</span> are all positive values representing the contributions of the S, L, and M cones to the Y-B opponent process. It is generally said that this signal is delivered by the Koniocellular pathway.</li>
<li>The R-G channel is given by <span class="math inline">\(d\)</span>L-<span class="math inline">\(e\)</span>M, where <span class="math inline">\(d\)</span> and <span class="math inline">\(e\)</span> are all positive values representing the contributions of the L and M cones to the R-G opponent process. This opponent signal is generally said to be delivered by the Parvocellular pathway.</li>
<li>The Light-Dark or luminance channel is given by <span class="math inline">\(f\)</span>L+<span class="math inline">\(g\)</span>M, where <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are all positive values representing the contributions of the L and M cones to the luminance channel. This luminance channel is meant to represent the LEF (<a href="#sec-chpt-hvs-color-oppo-light" class="quarto-xref"><span>Section 4.3.2</span></a>), which generally is believed to be delivered by the Magnocellular pathway.</li>
</ul>
<p>The DKL space operates not on raw cone responses but on response <em>contrasts</em> with respect to a perceptually neutral/achromatic color. The inherent assumption is that the achromatic color should have no strength in any of the three cone-opponent channels and be the origin in the cone-opponent space. The achromatic color depends on an observer’s state of chromatic adaptation, a topic we will discuss later in <a href="hvs-adaptation.html#sec-chpt-hvs-adaptations-chroma" class="quarto-xref"><span>Section 6.3</span></a>. People usually fit data to regress the values of the free parameters, and the exact values depend on which cone fundamentals are used and the normalization convention. <span class="citation" data-cites="brainard1996cone">Brainard (<a href="references.html#ref-brainard1996cone" role="doc-biblioref">1996</a>)</span> describes one such procedure.</p>
<p>Since the cone-opponent model operates on (contrast of) cone responses, a common theory of color vision is that it is a two-stage process: the wavelength encoding by cone photoreceptors followed by opponent encoding of cone responses post-receptorally. While the cone response encoding can perfectly explain the color matching experiments as we have see earlier, the cone opponent encoding is only an approximation of the hue cancellation experiments, as we will see next.</p>
</section>
<section id="sec-chpt-hvs-color-oppobasis-truth" class="level3" data-number="4.4.4">
<h3 data-number="4.4.4" class="anchored" data-anchor-id="sec-chpt-hvs-color-oppobasis-truth"><span class="header-section-number">4.4.4</span> There are Many Inconvenient Truths</h3>
<p>The cone-opponent model is a good approximation for behavioral color-opponent mechanisms, but there are many inconsistencies between these two. Reconciling the two and thus elucidating how humans perceptually code opponent hues is still an open research question.</p>
<section id="p-and-k-pathways-do-not-fully-account-for-r-g-and-y-b-opponent-processes" class="level4">
<h4 class="anchored" data-anchor-id="p-and-k-pathways-do-not-fully-account-for-r-g-and-y-b-opponent-processes">P and K Pathways Do Not Fully Account For R-G and Y-B Opponent Processes</h4>
<p>The opponent neurons clearly have what it takes to start accounting for the perceptual opponent processes, but the spectral tuning curves of those neurons have only a weak correlation with the hue cancellation curves. Thus, it is unlikely that excitation and inhibition in opponent neurons cause our perception of red-green and blue-yellow opponency.</p>
<p>The most jarring difference appears in the R-G process. The R-G hue cancellation curve (<a href="#fig-hue_cancellation_experiment" class="quarto-xref">Figure&nbsp;<span>4.8</span></a> (C)) shows two perceptually neutral colors, as there are two zero-crossings. However, the spectral tuning curve of the R-G neurons (<a href="#fig-opponent_lgn_cells" class="quarto-xref">Figure&nbsp;<span>4.11</span></a> (A–B)) shows only one zero-crossing. These neurons do not predict the R-G neutral color in the short-wavelength range and, by extension, cannot explain the fact that short-wavelength violet-ish lights appear to have a red hue. <span class="citation" data-cites="derrington1984chromatic">Derrington, Krauskopf, and Lennie (<a href="references.html#ref-derrington1984chromatic" role="doc-biblioref">1984</a>)</span> (also see <span class="citation" data-cites="wandell1995foundations">Wandell (<a href="references.html#ref-wandell1995foundations" role="doc-biblioref">1995, fig. 9.18</a>)</span>) shows a great deal of variation of the spectral tuning property within P cells, making them even less certain as the sole candidate for R-G opponent mechanism.</p>
<p>In fact, people have shown that the perceptual R-G hue cancellation data can be fit by <span class="math inline">\(a'\)</span>L-<span class="math inline">\(b'\)</span>M+<span class="math inline">\(c'\)</span>S, where <span class="math inline">\(a'\)</span>, <span class="math inline">\(b'\)</span>, and <span class="math inline">\(c'\)</span> are cone contributions <span class="citation" data-cites="poirson1993appearance bauml1996color">(<a href="references.html#ref-poirson1993appearance" role="doc-biblioref">Poirson and Wandell 1993</a>; <a href="references.html#ref-bauml1996color" role="doc-biblioref">Bäuml and Wandell 1996</a>)</span>. Intuitively, the contribution by S cones in the short-wavelength range could give rise to a positive response there. However, there is no physiological evidence that L cone and S cone responses combine at some point in the visual pathway, suggesting the phenomenological nature of these models.</p>
<p>Even though the K pathway clearly shows the capability of carrying S vs.&nbsp;L+M signals, the latter do not accurately predict Y-B neutral signals and, thus, do not fully account for the Y-B hue opponency. That is, a color that leads to a null response (no significant increase or decrease compared to the spontaneous response rate) in the L-M channel is not perceptually pure yellow or pure blue <span class="citation" data-cites="shevell2017color">(<a href="references.html#ref-shevell2017color" role="doc-biblioref">Shevell and Martin 2017, fig. 4f</a>)</span>. Similarly, a color that causes a null response in the S-(L+M) channel is not perceptually pure red or pure green. That is, null-response colors in the DKL cone-opponent space are not perceptually neutral in the hue-opponent space, implying fundamental discrepancies between cone-opponent and hue-opponent spaces. <!-- talk about the threshold of detecting chromatic change and that it matches well with the neural curves? --></p>
</section>
<section id="m-pathway-does-not-fully-account-for-luminance" class="level4">
<h4 class="anchored" data-anchor-id="m-pathway-does-not-fully-account-for-luminance">M Pathway Does Not Fully Account For Luminance</h4>
<p>The Magnocellular pathway (starting from the parasol RGCs) is said to be responsible for the dark-light opponent cells, but that poses a dilemma. We know that parasol RGCs have large RFs. A large RF is equivalently to applying an aggressive low-pass filter to the optical image; as a result, the M pathway has a low spatial acuity. So if the M pathway is fully responsible for mediating our luminance perception, we should be insensitive to spatial blurring (low-pass filtering) in the luminance signal. But the result is the opposite: our vision is very sensitive to spatial blurring in in the luminance channel (but relatively insensitive to blurring in the two color opponent channels).</p>
<div id="fig-channel_blurring" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-channel_blurring-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/channel_blurring_new.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-channel_blurring-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.13: We take an image, decouple it into three channels: luminance, red-green, and blue-yellow. We then spatially blur one of the channels while keeping the other two channels unchanged and then reconstruct the image. Our vision is much more sensitive to spatially blurring in the luminance channel (a) than is to blurring in the red-green channel (b) and in the blue-yellow channel (c). This is the basis of chroma subsampling used in modern image and video compression algorithms. The original image is <em>The Art of Painting</em> from Johannes Vermeer <span class="citation" data-cites="aop">Johannes Vermeer (<a href="references.html#ref-aop" role="doc-biblioref">1668</a>)</span>. See another example in <span class="citation" data-cites="wandell1995foundations">Wandell (<a href="references.html#ref-wandell1995foundations" role="doc-biblioref">1995, fig. 9.23</a>)</span>.
</figcaption>
</figure>
</div>
<p>This is illustrated in <a href="#fig-channel_blurring" class="quarto-xref">Figure&nbsp;<span>4.13</span></a>, where we take an image, decouple it into three channels: luminance, red-green, and blue-yellow. We then spatially blur one of the channels while keeping the other two channels unchanged and then reconstruct the image. Our vision is much more sensitive to spatially blurring in the luminance channel (a) than is to blurring in the red-green channel (b) and in the blue-yellow channel (c); in fact, this is the basis of <strong>chroma subsampling</strong>, a key step in modern image and video compression algorithms. This suggests that the M pathway alone cannot be exclusively responsible for our luminance perception.</p>
<p><span class="citation" data-cites="gouras1979enhancement">Gouras and Zrenner (<a href="references.html#ref-gouras1979enhancement" role="doc-biblioref">1979</a>)</span> also shows that P cells, which are ordinarily thought of as L-M spectrally-opponent, could also give a LEF-like spectral tuning curve as if it acts as the luminance channel. The reason is that the surround signals reach a cell later than do the center signals, so at a high frequency the out-of-phase center-surround signals can actually come in the same phase.</p>
</section>
<section id="hue-opponent-space-is-not-a-linear-transformation-from-cone-space" class="level4">
<h4 class="anchored" data-anchor-id="hue-opponent-space-is-not-a-linear-transformation-from-cone-space">Hue-Opponent Space is Not a Linear Transformation from Cone Space</h4>
<p>It is perhaps not surprising, by now, that if there is a color space that can fully account for the perceptual coding of opponent hues, it is never going to be a linear transformation from the LMS space (or any other space that is a linear transformation away from the LMS space, e.g., the CIE 1931 XYZ space or the DKL cone-opponent space).</p>
<p>As we have seen above, for instance, the DKL space <span class="citation" data-cites="derrington1984chromatic">(<a href="references.html#ref-derrington1984chromatic" role="doc-biblioref">Derrington, Krauskopf, and Lennie 1984</a>)</span>, which is a linear transformation from the LMS cone space, does not fully account for the perceptual opponent processes, e.g., does not predict any unique hue. People have shown that one can construct a linear transformation from the LMS space that can accurately predict three of the four unique perceptual hues by fitting data from psychophysical measurements that do not presuppose the existence of opponent mechanisms <span class="citation" data-cites="poirson1993appearance bauml1996color">(<a href="references.html#ref-poirson1993appearance" role="doc-biblioref">Poirson and Wandell 1993</a>; <a href="references.html#ref-bauml1996color" role="doc-biblioref">Bäuml and Wandell 1996</a>)</span>, but they cannot predict the fourth unique hue. <span class="citation" data-cites="schrodinger1925verhaltnis">Schrödinger (<a href="references.html#ref-schrodinger1925verhaltnis" role="doc-biblioref">1925</a>)</span> also estimated a linear transformation between the cone response space and the hue-opponent space based on the four unique hues, but the transformation could not accurately predict the achromatic color (also see the commentary by Zaidi in <span class="citation" data-cites="schrodinger1994relationship">Schrödinger (<a href="references.html#ref-schrodinger1994relationship" role="doc-biblioref">1994</a>)</span>).</p>
<p>The reason is that perceptually unique red and green hues are not <em>collinear</em> with white, the achromatic color that is perceptually neutral in both the Y-B and R-G channel, i.e., does not appear yellow, blue, red, nor green<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. That is, red, white, and green do not lie on a line. Why is this significant? Assuming there was a linear transformation <span class="math inline">\(T\)</span> from the cone responses to the strengths of the hue-opponent mechanisms:</p>
<p><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
\text{Y/B}\\
\text{R/G}\\
\text{Lum}
\end{bmatrix}
=
T
\times
\begin{bmatrix}
L\\
M\\
S
\end{bmatrix}
\end{aligned}
\]</span></p>
<p>Both unique red hue (<span class="math inline">\([L_R, M_R, S_R]\)</span>) and unique green hue (<span class="math inline">\([L_G, M_G, S_G]\)</span>) have no yellow (or blue) hue, so their response in the Y-B channel response would be 0:</p>
<p><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
\text{0}\\
|\\
|
\end{bmatrix}
=
T
\times
\begin{bmatrix}
L_R\\
M_R\\
S_R
\end{bmatrix},~~~
\begin{bmatrix}
\text{0}\\
|\\
|
\end{bmatrix}
=
T
\times
\begin{bmatrix}
L_G\\
M_G\\
S_G
\end{bmatrix}
\end{aligned}
\]</span></p>
<p>Therefore, any mixture of the unique red hue and the unique green hue would not appear to have a yellow hue either:</p>
<p><span class="math display">\[
\begin{aligned}
\begin{bmatrix}
\text{0}\\
|\\
|
\end{bmatrix}
=
T
\times
\begin{bmatrix}
a L_R + b L_G\\
a M_R + b M_G\\
a S_R + b S_G
\end{bmatrix},
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are contributions of red and green to the mixed color. However, we know that when we mix red with green colors we get yellow. The fact that two colors without any yellow hue can generate a color that does have a yellow hue means the hue-opponent space cannot be a linear transformation from the LMS cone space.</p>
<div id="fig-unique_hues" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-unique_hues-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/unique_hues.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-unique_hues-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.14: Circles are unique hues derived from psychophysics reported in <span class="citation" data-cites="bauml1993ratio">Bäuml (<a href="references.html#ref-bauml1993ratio" role="doc-biblioref">1993</a>)</span>. Fitting lines and extrapolating the lines give us estimations of unique hues that are spectral colors. Three of the four unique spectral hues (blue at 474 <span class="math inline">\(\text{nm}\)</span>, green at 506 <span class="math inline">\(\text{nm}\)</span>, and yellow at 568 <span class="math inline">\(\text{nm}\)</span>) can be accurately predicted by a linear transformation constructed by <span class="citation" data-cites="bauml1996color">Bäuml and Wandell (<a href="references.html#ref-bauml1996color" role="doc-biblioref">1996</a>)</span>, but not the unique red hue. The fact that the red, white, and green are not collinear suggests that there is no linear transformation between the hue-opponent space and the cone space. Adapted from <span class="citation" data-cites="bauml1996color">Bäuml and Wandell (<a href="references.html#ref-bauml1996color" role="doc-biblioref">1996, fig. 12</a>)</span>.
</figcaption>
</figure>
</div>
<p><a href="#fig-unique_hues" class="quarto-xref">Figure&nbsp;<span>4.14</span></a> illustrates this point with some real data. The empty markers are three sets of perceptually unique hues (which do not have to be spectral colors) measured psychophysically in <span class="citation" data-cites="bauml1993ratio">Bäuml (<a href="references.html#ref-bauml1993ratio" role="doc-biblioref">1993</a>)</span>. When we fit a straight line across each set of unique hues and extrapolate the line we can estimate what spectral colors are unique hues (blue Ⓑ, green Ⓖ, and yellow Ⓨ). No spectral color is seen as a unique red hue (all spectral red-ish colors appear to have a yellow hue), which requires a mixture of unique blue hue and a spectral red to cancel the yellow percept <span class="citation" data-cites="dimmick1939spectralyellow larimer1975opponent">(<a href="references.html#ref-dimmick1939spectralyellow" role="doc-biblioref">Dimmick and Hubbard 1939b</a>; <a href="references.html#ref-larimer1975opponent" role="doc-biblioref">Larimer, Krantz, and Cicerone 1975</a>)</span> (and also see the commentary by Zaidi in <span class="citation" data-cites="schrodinger1994relationship">Schrödinger (<a href="references.html#ref-schrodinger1994relationship" role="doc-biblioref">1994</a>)</span>). <span class="citation" data-cites="dimmick1939spectralred">Dimmick and Hubbard (<a href="references.html#ref-dimmick1939spectralred" role="doc-biblioref">1939a</a>)</span> measured that unique red hues Ⓡ are complementary to a spectral light at 494 <span class="math inline">\(\text{nm}\)</span>; that is, spectral light at 494 <span class="math inline">\(\text{nm}\)</span>, white Ⓦ, and unique red hues should fall on a straight line<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>.</p>
<p><span class="citation" data-cites="bauml1996color">Bäuml and Wandell (<a href="references.html#ref-bauml1996color" role="doc-biblioref">1996</a>)</span> constructed a linear transformation from the cone space to the hue-opponent space that can accurately predict the unique spectral hues of blue, green, and yellow. It is comforting, and corroborates others <span class="citation" data-cites="larimer1974opponent">(<a href="references.html#ref-larimer1974opponent" role="doc-biblioref">Larimer, Cicerone, et al. 1974</a>)</span>, that blue Ⓑ, white Ⓦ, and yellow Ⓨ are collinear, as would be required by a linear transformation from the cone space to the hue-opponent space: mixing colors that have no green or red hue will not give a color that does. But clearly the predicted red hue Ⓡ’ deviates significantly away from red hue Ⓡ from actual measurements. If we connect the unique green hue Ⓖ and unique red hue Ⓡ, the line would not across Ⓦ. This suggests that a simple linear transformation does not exist; at least the Y-B null-response axis is not linear with respect to the cone responses. Non-linear models have been proposed <span class="citation" data-cites="larimer1975opponent shevell2017color">(<a href="references.html#ref-larimer1975opponent" role="doc-biblioref">Larimer, Krantz, and Cicerone 1975</a>; <a href="references.html#ref-shevell2017color" role="doc-biblioref">Shevell and Martin 2017</a>)</span>.</p>
<!-- so maybe an explanation is that the actual transformation, which has to be non-linear, coincides with the linear transformation at hues that do match, but not at others. just imagine two transformations, Tlinear and Tnon; both can transform YBGR correctly from LMS space to the opponent space, but in Tlinear the points along the RG line are not correctly transformed but they are in Tnon. Maybe Tnon is a piece-wise linear transformation? see also \citet[p. 257]{kaiser1996human}; related? -->
</section>
</section>
</section>
<section id="sec-chpt-hvs-color-evo" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="sec-chpt-hvs-color-evo"><span class="header-section-number">4.5</span> Evolution of Color Vision</h2>
<p>See <span class="citation" data-cites="lamb2013evolution">Lamb (<a href="references.html#ref-lamb2013evolution" role="doc-biblioref">2013</a>)</span>, <span class="citation" data-cites="lamb2020evolution">Lamb (<a href="references.html#ref-lamb2020evolution" role="doc-biblioref">2020</a>)</span>, <span class="citation" data-cites="lamb2022photoreceptor">Lamb (<a href="references.html#ref-lamb2022photoreceptor" role="doc-biblioref">2022</a>)</span>, <span class="citation" data-cites="lamb2007evolution">Lamb, Collin, and Pugh (<a href="references.html#ref-lamb2007evolution" role="doc-biblioref">2007</a>)</span>, <span class="citation" data-cites="shichida2009evolution">Shichida and Matsuyama (<a href="references.html#ref-shichida2009evolution" role="doc-biblioref">2009</a>)</span>, <span class="citation" data-cites="jacobs2009evolution">Jacobs (<a href="references.html#ref-jacobs2009evolution" role="doc-biblioref">2009</a>)</span>, <span class="citation" data-cites="bowmaker2008evolution">Bowmaker (<a href="references.html#ref-bowmaker2008evolution" role="doc-biblioref">2008</a>)</span>, and <span class="citation" data-cites="bowmaker1998evolution">Bowmaker (<a href="references.html#ref-bowmaker1998evolution" role="doc-biblioref">1998</a>)</span> for comprehensive discussions. We provide a concise summary of what is relevant to our discussions in this chapter.</p>
<section id="sec-chpt-hvs-color-evo-tri" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="sec-chpt-hvs-color-evo-tri"><span class="header-section-number">4.5.1</span> The Rise of Trichromacy</h3>
<section id="proto-vertebrates-had-four-cone-opsin-genes" class="level4">
<h4 class="anchored" data-anchor-id="proto-vertebrates-had-four-cone-opsin-genes">Proto-Vertebrates Had Four Cone Opsin Genes</h4>
<p>When studying the evolution of vision and performing comparative studies of vision across species, we must understand the differences in all the molecules that participate in phototransduction and the subsequent neural circuitry. The photopigment/opsin itself is one of the most important components (e.g., pigments differ in their peak absorption wavelength), and its evolution is the most well-understood. It is the main focus of our discussion.</p>
<!-- %Animal opsins are G-protein-coupled receptors and a group of proteins made light-sensitive via a chromophore, typically retinal. When bound to retinal, opsins become retinylidene proteins but are usually still called opsins regardless.
%https://en.wikipedia.org/wiki/Opsin -->
<p>A primordial opsin gene that existed in ancestral bilateria (before the separation of protostomes and deuterostomes), through duplications and mutations, gave rise to many opsin genes, some of which are even expressed in non-visual opsins (e.g., ipRGCs and RPEs). One of them is called the Long-Wavelength Sensitive (LWS) opsin gene. <!-- %in \citep{lamb2007evolution} an ancestral c-opsin is duplicated with two copies. the first copy duplicated (according to \citep{lamb2022photoreceptor}) to form pinopsin and LWS, and the second copy evolved to be SWS.
% it's perhaps better to say ``the ancestral LWS'', since the LWS gene in ancestral vertebrates are most definitely different from the LWS gene in humans.
%Pinopsins mediates (scotopic) vision in proto-vertebrates.
%how did c-opsin come about? See figure 3 and the section on ``The evolution of vertebrate opsins.'' Before the separation of protostomes and deuterostomes, a primordial opsin had divided into three main branches: one of which is the ciliary opsin, which has given rise to many opsins that are expressed in pineal complex, retina and deep-brain regions (see also: https://en.wikipedia.org/wiki/Opsin#Opsins_in_the_human_eye,_brain,_and_skin). --> The LWS opsin gene was duplicated multiple times, each of which went through mutations, and eventually four opsin genes existed in proto-vertebrates. The sequence of duplications most likely went like the following. The LWS gene was duplicated, and the duplicated copy evolved to be Short-Wavelength Sensitive and is called the SWS opsin gene. <!-- %Both LWS and SWS genes evolved independently. --> The SWS gene was duplicated again. One of the copies is called the SWS1 gene. The other was duplicated once again. Of its two copies, one is called the SWS2 gene, and the other is called the RHL gene. RHL means “rod like”; it is given the name because its duplicate would later evolve to be expressed in rhodopsin (photopigment in rods).</p>
<p>As a result, proto-vertebrates (primitive animals from which the vertebrates evolved; think of them as ancestors to vertebrates but are not vertebrates themselves) possessed 4 opsin genes: LWS, SWS1, SWS2, and RHL. These genes were expressed in pigments that mediate photopic vision, just like modern cones, so we will simply call them cone opsins, but keep in mind that proto-vertebrate “cones” are most definitely different from modern vertebrate cones.</p>
<p>Generally, a modern form of a gene is different from its ancestral form, but for simplicity, we usually call them by the same name. This might be a common source of confusion when studying evolutionary biology. For instance, modern vertebrates all have LWS opsin genes (that are slightly different); they are all evolved from, but most definitively different from, the ancestral LWS gene at the time of duplication that gave rise to the SWS branch. It is perhaps more rigorous to say, “the ancestral LWS was duplicated; one copy evolved to become the modern LWS genes, and the other evolved to become the ancestral SWS gene, which was duplicated again; its two copies are the ancestral SWS1 gene and the ancestral SWS2 gene”, but you can see how cumbersome this would be. Even with this it is sometimes unclear at which point in the evolution does “ancestral” refer to. <!-- %https://courses.lumenlearning.com/suny-mcc-biology2/chapter/the-evolution-of-primates/ --></p>
</section>
<section id="most-vertebrates-are-tetrachromatic-and-most-mammals-are-dichromatic" class="level4">
<h4 class="anchored" data-anchor-id="most-vertebrates-are-tetrachromatic-and-most-mammals-are-dichromatic">Most Vertebrates are Tetrachromatic and Most Mammals are Dichromatic</h4>
<p>Then something remarkable happened. During the Cambrian epoch, at around 530 to 500 million years ago (Mya), there were two rounds of Whole Genome Duplication (WGD), a.k.a., polyploidy. Each WGD made a complete copy of all the genes. So two rounds of WGD would quadruple the number of genes. Each WGD was followed by a relatively short period of genome instability with extensive loss of genes. As a result, not all four copies (a result of two rounds of WGD) of a gene were retained. WGD in general is a major source of speciation, and the two rounds of WGD were responsible for the explosion of new species at the end of the Cambrian epoch (Cambrian explosion). WGDs increased the number of genes and made more genes available for mutation. As a result, there was a sudden radiation of species and diversification of life. Perhaps most importantly to human evolution, vertebrates appeared after the first round (1R) WGD.</p>
<p>As far as the four cone opsin genes are concerned, all their copies were lost except two copies of RHL, which are now called RH1 and RH2. So after the two rounds of WGD, our ancestral vertebrates possessed five cone opsin genes: SWS1, SWS2, RH1, RH2, and LWS. RH1 evolved to be expressed in rhodopsins (pigments for rods) to mediate scotopic vision in vertebrates; the other four evolved too but retained their ability to mediate photopic vision. This is why most vertebrates are tetrachromatic. From the sequence of duplications, we can also deduce that the rod pigment evolved after all four classes of cone pigment were already present <span class="citation" data-cites="okano1992primary">(<a href="references.html#ref-okano1992primary" role="doc-biblioref">Okano et al. 1992</a>)</span>. In fact, rod signals largely piggyback onto the pre-existing circuitry for cone signaling <span class="citation" data-cites="lamb2016rods">(<a href="references.html#ref-lamb2016rods" role="doc-biblioref">Lamb 2016</a>)</span>.</p>
<!-- %It is worth keeping in mind that each gene perhaps has been mutated many times.
%So SWS1, SWS2, RH1, RH2, and LWS genes found in modern species are most likely different from those in their ancestors.
%Duplications took place in the ancestral genes, even though for the simplicity of exposition we will simply say something like ``LWS duplicated.'' -->
<p>Early mammals arose at the age of dinosaurs and were nocturnal, so they had no need for strong color vision and lost two of the four cone opsin genes. Only LWS and SWS1 genes were retained. This is why most mammals are dichromatic.</p>
<div id="fig-opsin_evolution" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-opsin_evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/opsin_evolution.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-opsin_evolution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.15: Left: Phylogenetic tree of vertebrate visual opsins; adapted from <span class="citation" data-cites="bowmaker2008evolution">Bowmaker (<a href="references.html#ref-bowmaker2008evolution" role="doc-biblioref">2008, fig. 2</a>)</span>. Note how humans are trichromatic (three cone opsins), chickens (non-mammalian vertebrates) are tetrachromatic (four cone opsins), and mice (mammals) are dichromatic (two cone opsins). Right: approximate spectral sensitivity of the five visual opsins; from <span class="citation" data-cites="jacobs2009evolution">Jacobs (<a href="references.html#ref-jacobs2009evolution" role="doc-biblioref">2009, fig. 1</a>)</span>.
</figcaption>
</figure>
</div>
<p><a href="#fig-opsin_evolution" class="quarto-xref">Figure&nbsp;<span>4.15</span></a> shows the phylogenetic tree of vertebrate visual opsins, of which there are five classes. I say “class” of opsin genes here because there are variations between, say, the SWS1 gene in humans and that in mice. Circles represent gene duplications. The first duplication on the ancestral LWS gene was local and gave rise to the SWS branch. The other duplications within the SWS branch are part of the two rounds of WGDs (which, recall, were followed by gene losses, which are omitted in the diagram). The local duplication within the LWS branch gave humans trichromacy, which we will discuss next.</p>
</section>
<section id="lws-gene-duplication-in-catarrhini-gave-human-trichromacy" class="level4">
<h4 class="anchored" data-anchor-id="lws-gene-duplication-in-catarrhini-gave-human-trichromacy">LWS Gene Duplication in Catarrhini Gave Human Trichromacy</h4>
<p>Then primates evolved from some mammals, first to prosimians, and then anthropoids (higher primates) split off from prosimians. Anthropoids include Platyrrhini (broad noses) and Catarrhini (narrow noses). Platyrrhini evolved into modern New World (South America) monkeys. Catarrhini is the common ancestor of Old World (Africa and Asia) monkeys, apes, and humans.</p>
<p>Trichromacy emerged in an early Catarrhini through gene duplication. The LWS gene is duplicated. One copy is evolved to be expressed in modern L cones, and the other evolved to be expressed in modern M cones. Since the duplication occurred “only” about 30 Mya, which is fairly recent from an evolutionary standpoint, the L and M cone pigments are very similar. 96% of the amino acids in the L cone opsin and M cone opsin are the same <span class="citation" data-cites="nathans1986molecular">(<a href="references.html#ref-nathans1986molecular" role="doc-biblioref">Nathans, Thomas, and Hogness 1986</a>)</span>: they simply have not had much time to be mutated enough yet. With the SWS1 gene being expressed in S cones, all Catarrhini (including humans) are trichromatic. <a href="#fig-lws_duplication" class="quarto-xref">Figure&nbsp;<span>4.16</span></a> illustrates the duplication and the spectral sensitivities before and after the duplication.</p>
<div id="fig-lws_duplication" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lws_duplication-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/lws_duplication.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lws_duplication-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.16: Left: LWS duplication gave two copies of the same gene in the X chromosome, and subsequent mutations to both copies gave rise to modern L and M cone opsin genes. Middle and Right: spectral sensitivities of the two cone pigments in mammals (middle) and the three sensitivity spectra in primates (note the <span class="math inline">\(x\)</span>-axis is frequency rather than wavelength); from <span class="citation" data-cites="rodieck1998first">(<a href="references.html#ref-rodieck1998first" role="doc-biblioref">Rodieck 1998, p. 218</a>)</span>.
</figcaption>
</figure>
</div>
<p>What was the evolutionary pressure for the duplication that gave rise to the trichromacy? Since the duplication of the LWS gene gave us medium-wavelength pigments that peak at green-ish lights, one interesting theory is that the duplication offered the ability to distinguish red-ish colors from green-ish colors in order to select ripe from unripe fruit (or ripe fruits against the background of green leaves), which had an obvious evolutionary advantage <span class="citation" data-cites="hunt1998molecular bowmaker1998evolution">(<a href="references.html#ref-hunt1998molecular" role="doc-biblioref">Hunt et al. 1998</a>; <a href="references.html#ref-bowmaker1998evolution" role="doc-biblioref">Bowmaker 1998, p. 544</a>)</span>.</p>
</section>
</section>
<section id="sec-chpt-hvs-color-evo-duplex" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="sec-chpt-hvs-color-evo-duplex"><span class="header-section-number">4.5.2</span> The Rise of Scotopic vs.&nbsp;Photopic Vision</h3>
<section id="only-jawed-vertebrates-have-a-modern-scotopic-vision" class="level4">
<h4 class="anchored" data-anchor-id="only-jawed-vertebrates-have-a-modern-scotopic-vision">Only Jawed Vertebrates Have a “Modern” Scotopic Vision</h4>
<p>Vertebrates arose after 1R. 1R is important for the rod-cone duplex vision in today’s vertebrates. RH1, which eventually is evolved to be expressed in rhodopsins, appeared after 1R. 1R also duplicated other non-opsin genes important for phototransduction (e.g., G proteins, PDEs, cGMPs, etc.) <span class="citation" data-cites="lamb2020evolution">(<a href="references.html#ref-lamb2020evolution" role="doc-biblioref">Lamb 2020</a>)</span>. These genes evolved to be expressed in distinct isoforms of many of the molecules that participate in the rod vs.&nbsp;cone phototransduction cascades.</p>
<p>Jawless and jawed vertebrates (from which humans evolved) split after 1R, so they both possessed distinct scotopic and photopic vision. But there are differences in the scotopic vision between the two. Why? Because the second round (2R) WGD happened only to jawed vertebrates. 2R introduces a few new genes that allow jawed vertebrates to possess “true”, modern rod photoreceptors, where rod pigments are more thermally stable (lower dark noise) than cone pigments and regenerate faster than cone pigments <span class="citation" data-cites="lamb2007evolution lamb2022photoreceptor">(<a href="references.html#ref-lamb2007evolution" role="doc-biblioref">Lamb, Collin, and Pugh 2007</a>; <a href="references.html#ref-lamb2022photoreceptor" role="doc-biblioref">Lamb 2022</a>)</span>. In jawless vertebrates, rods also have a cone-like anatomical structure, but 2R changed the morphology of rods in jawed vertebrates so that their rods look different from cones, e.g., having sealed-off discs. Interestingly, morphology apparently is not important for scotopic vision: northern hemisphere lampreys (a kind of jawless vertebrate) have rods that look like cones but physiologically behave like rods, e.g., they are very sensitive to lights, so they do mediate scotopic vision <span class="citation" data-cites="morshedian2015single">(<a href="references.html#ref-morshedian2015single" role="doc-biblioref">Morshedian and Fain 2015</a>)</span>. Whether you call the these photoreceptors rods or cones is largely a matter of definition.</p>
</section>
<section id="scotopic-vision-predates-vertebrates" class="level4">
<h4 class="anchored" data-anchor-id="scotopic-vision-predates-vertebrates">Scotopic Vision Predates Vertebrates</h4>
<p>It is also interesting to note that proto-vertebrates, likely some chordate ancestors of ours, also possessed distinct photopic and scotopic vision way before vertebrates, except those ancestral scotopic photoreceptors utilized pinopsin <span class="citation" data-cites="okano1994pinopsin">(<a href="references.html#ref-okano1994pinopsin" role="doc-biblioref">Okano, Yoshizawa, and Fukada 1994</a>)</span>, rather than rhodopsin, as their photopigments <span class="citation" data-cites="lamb2020evolution sato2018pinopsin">(<a href="references.html#ref-lamb2020evolution" role="doc-biblioref">Lamb 2020</a>; <a href="references.html#ref-sato2018pinopsin" role="doc-biblioref">Sato et al. 2018</a>)</span>. Pinopsin evolved prior to 1R and, in fact, was duplicated along with LWS cone opsin in proto-vertebrates from a ciliary opsin (C-opsin).</p>
<p>After 1R, presumably RH1-expressed rhodopsins had better performance under scotopic conditions, so they gradually superseded pinopsins to be the pigments expressed in scotopic photoreceptors. Mammals do not possess pinopsins anymore, but some vertebrate species still use pinopsins for scotopic vision <span class="citation" data-cites="sato2018pinopsin">(<a href="references.html#ref-sato2018pinopsin" role="doc-biblioref">Sato et al. 2018</a>)</span>, and many vertebrates use pinopsins for non-vision functions such as regulating circadian rhythm (as they are expressed in the pineal organ) <span class="citation" data-cites="takanaka1998light">(<a href="references.html#ref-takanaka1998light" role="doc-biblioref">Takanaka et al. 1998</a>)</span>.</p>
<!-- %C-opsins are very ancient; they are widely used even in protostomes (700 Mya), though rarely for imaging vision~\citep{lamb2020evolution}.
%See \citet{lamb2013evolution} for discussions of how C-opsins evolved to ancestral cone and rod opsins and of where the origin of opsins in life was in the first place. -->
</section>
</section>
</section>
<section id="sec-chpt-hvs-color-cvd" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="sec-chpt-hvs-color-cvd"><span class="header-section-number">4.6</span> Color Vision Deficiencies</h2>
<p>Normal color vision is trichromatic in that there are three classes of cone photoreceptors on the retina. If the retina is deprived of the functions of one of two cone classes, the color vision is no longer trichromatic. Instead of being represented in a three-dimensional space, a color would now be expressed in a two-dimensional or one-dimensional space. Individuals with two functioning classes of cones are <strong>dichromatic</strong>, and those with one functioning cone class are <strong>monochromatic</strong>. Dichromatic vision is further classified into three types: <strong>Protanopia</strong>, where L cones are missing; <strong>Deuteranopia</strong>, where M cones are missing; and <strong>Tritanopia</strong>, where S cones are missing. An interesting form of dichromatic vision is called <strong>small-field dichromacy</strong>. At the central 20 arcmin of the fovea there are no S cones, so human vision is effectively dichromatic there. There are also individuals who have no functioning cones, only rods, and those people have <strong>rod monochromacy</strong>.</p>
<div id="fig-trichromatic_anomalous" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-trichromatic_anomalous-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/trichromatic_anomalous.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-trichromatic_anomalous-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.17: Illustration of how cone fundamentals shift under each anomalous trichromatic vision; adapted from <span class="citation" data-cites="milic2015enhancement">Milić, Novaković, and Milosavljević (<a href="references.html#ref-milic2015enhancement" role="doc-biblioref">2015</a>)</span>.
</figcaption>
</figure>
</div>
<p>In addition to strict dichromatic vision, another important form of CVD is <strong>anomalous trichromatic</strong> vision, where individuals have all three cone types, but the spectral sensitivity of a cone type deviates from normal. <strong>Protanomaly</strong>, <strong>Deuteranomaly</strong>, and <strong>Tritanomaly</strong> are the names given to the three types of anomalous trichromatic vision. <a href="#fig-trichromatic_anomalous" class="quarto-xref">Figure&nbsp;<span>4.17</span></a> illustrates how the cone fundamentals change under different anomalous trichromacy compared to normal trichromacy. For protanomalous and deuteranomalous individuals (by far the most common anomalous trichromats), their L and M cone fundamentals are closer than normal, so the L and M cone excitations are very similar. In theory their color vision is still three-dimensional, but the L and M dimensions are very correlated, which weakens their color discrimination ability.</p>
<p>Finally, some females with anomalous trichromacy may have four cone classes on the retinal mosaic owing to random X chromosome inactivation. However, it is unclear whether their color vision is four-dimensional or they have a stronger color discrimination ability <span class="citation" data-cites="jordan2010dimensionality simunovic2010colour">(<a href="references.html#ref-jordan2010dimensionality" role="doc-biblioref">Jordan et al. 2010</a>; <a href="references.html#ref-simunovic2010colour" role="doc-biblioref">Simunovic 2010</a>)</span>.</p>
<p>We will primarily focus on dichromatic vision, building a phenomenological model for simulating dichromacy, and then discuss the genetic basis of CVD now that we have a good understanding of the evolution of color vision.</p>
<section id="sec-chpt-hvs-color-cvd-model" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="sec-chpt-hvs-color-cvd-model"><span class="header-section-number">4.6.1</span> Models of Deficient Color Vision</h3>
<p>Perhaps one of the most important questions in CVD is this: what exactly do individuals with CVD actually see? In other words, how do we simulate a particular CVD? It is incredibly difficult to answer, since color is a subjective experience, and we can never be so certain of one another’s subjective experience. With the help of some luck (yes, some luck, from evolution) and some psychophysics, there is at least a consensus on how to model dichromatic vision. Taking Deuteranopia as an example, the interactive tutorial <span class="citation" data-cites="zhu2022cvd">Zhu (<a href="references.html#ref-zhu2022cvd" role="doc-biblioref">2022c</a>)</span> walks through a commonly used model. We will give the main intuitions here.</p>
<section id="confusion-lines" class="level4">
<h4 class="anchored" data-anchor-id="confusion-lines">Confusion Lines</h4>
<p>Dichromatic individuals see colors only in a 2D space, because they lack (the functionality of) one cone type. For instance, Deuteranopes lack the M cones and, thus, any color is encoded only in the L and S cone excitations, resulting in a 2D color space. Therefore, any colors that differ only in the M dimension are seen as the same color by a Deuteranope. A line parallel to the M dimension in the LMS space is called a Deuteranopic <strong>confusion line</strong>, as all colors on that line look the same to a Deuteranope. The left panel in <a href="#fig-confusion_lines" class="quarto-xref">Figure&nbsp;<span>4.18</span></a> plots two such confusion lines for Deuteranopia, although it is easy to see that there are infinitely many confusion lines.</p>
<div id="fig-confusion_lines" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-confusion_lines-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/confusion_lines.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-confusion_lines-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.18: Left: two confusion lines for Deuteranopia (missing functioning M cones). Right: confusion lines in the CIE 1931 xy-chromaticity space; from <span class="citation" data-cites="confusionlines">Curran919 (<a href="references.html#ref-confusionlines" role="doc-biblioref">2022</a>)</span>.
</figcaption>
</figure>
</div>
<p>The confusion lines are more commonly visualized in the CIE 1931 xy-chromaticity diagram, as illustrated in the three diagrams in <a href="#fig-confusion_lines" class="quarto-xref">Figure&nbsp;<span>4.18</span></a> to the right. We will discuss the xy diagram in the colorimetry lecture soon, but briefly, the xy diagram is a <em>perspective projection</em> from the LMS space that provides a useful 2D representation of colors by discarding the luminance dimension. Therefore, parallel confusion lines in the LMS space <em>converge</em> in the xy diagram.</p>
<div id="fig-protanomalous_confusion_line" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-protanomalous_confusion_line-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/protanomalous_confusion_line.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-protanomalous_confusion_line-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.19: In a protanomalous color space, the L and M cone fundamentals are very similar, so the L and M cone excitations are similar. C1 and C2 are colors in a trichromatic color space. They are mapped to C1’ and C2’ in a protanomalous color space, where both are moved closer to the L=M line (while keeping the M-axis unchanged, since the M cone fundamental is unaffected). When C1’ and C2’ are sufficiently close, they become confusing.
</figcaption>
</figure>
</div>
<p>Not all colors on a dichromatic confusion line are confusing to the corresponding anomalous trichromatic individuals. From a modeling perspective, a typical approach is to restrict the confusing colors to a small segment on a confusion line <span class="citation" data-cites="flatla2015colourid">(<a href="references.html#ref-flatla2015colourid" role="doc-biblioref">Flatla et al. 2015</a>)</span>. <a href="#fig-protanomalous_confusion_line" class="quarto-xref">Figure&nbsp;<span>4.19</span></a> illustrates a model to reason about this using Protanomaly as an example. C1 and C2 are two colors that differ only in the L cone response. For simplicity, <a href="#fig-protanomalous_confusion_line" class="quarto-xref">Figure&nbsp;<span>4.19</span></a> shows only the L and M dimensions. Since the L and M cone fundamentals are very similar, the L and M cone responses are similar too (the extreme case being L = M). So C1 and C2 are mapped to C1’ and C2’ in a protanomalous color space, where both colors are pulled toward the L=M line. C1’ and C2’ are never going to exactly coincide, because the L and M cone fundamentals do not exactly overlap, but when C1’ and C2’ are sufficiently close, they can still be perceptually undiscriminable. This is not unique to CVD individuals: even for normal trichromats the color discrimination is not perfect, as has been demonstrated extensively through psychophysics <span class="citation" data-cites="macadam1942visual">Krauskopf and Karl (<a href="references.html#ref-krauskopf1992color" role="doc-biblioref">1992</a>)</span>, which we will discuss in <a href="hvs-colorimetry.html#sec-chpt-hvs-cori-diff" class="quarto-xref"><span>Section 5.5</span></a> soon.</p>
</section>
<section id="isochromes" class="level4">
<h4 class="anchored" data-anchor-id="isochromes">Isochromes</h4>
<p>We know that all colors on the same confusion line are perceptually the same, but still we do not know, for all those colors on a confusion line, exactly what is the color a dichromate sees. The key to answering this question is the notion of <strong>isochromes</strong>, which are colors perceived correctly by a dichromate. The question is, how do we find the isochromes?</p>
<p>It is impossible to find isochromes by simply querying trichromats and dichromates. Imagine we have a normal trichromat and a Protanope looking at a color; even if they have the same color sensation, how would they communicate with each other about it? You might be tempted to find isochromes by asking a dichromate whether two colors appear the same.</p>
<p>Remarkably, there is an exceedingly rare form of CVD called <strong>unilateral dichromacy</strong>, where an individual has one dichromatic eye and another trichromatic eye. Color matching between the two eyes by a unilateral dichromate would allow us to identify isochromes, assuming, of course, that the dichromatic eye and the trichromatic eye are similar to those of a “normal” dichromatic and trichromatic eye, respectively. This is a remarkable luck we get from nature; without unilateral dichromats, we might never be able to quantitatively study dichromats’ color vision. There are a handful of studies reported on unilaterial dichromates. <span class="citation" data-cites="judd1949color">Judd (<a href="references.html#ref-judd1949color" role="doc-biblioref">1949</a>)</span> meticulously summarized data from prior studies, where only 8 had quantitative data that were useful. <span class="citation" data-cites="sloan1948case">Sloan and Wollach (<a href="references.html#ref-sloan1948case" role="doc-biblioref">1948</a>)</span>, <span class="citation" data-cites="graham1958color">Graham and Hsia (<a href="references.html#ref-graham1958color" role="doc-biblioref">1958</a>)</span>, and <span class="citation" data-cites="macleod1976red">MacLeod and Lennie (<a href="references.html#ref-macleod1976red" role="doc-biblioref">1976</a>)</span> reported results for unilateral Protanopes/Deuteranopes, while <span class="citation" data-cites="alpern1983perception">Alpern, Kitahara, and Krantz (<a href="references.html#ref-alpern1983perception" role="doc-biblioref">1983</a>)</span> reported results for a unilateral Tritanope.</p>
<p>Such studies show that monochromatic lights at 475 <span class="math inline">\(\text{nm}\)</span> and 575 <span class="math inline">\(\text{nm}\)</span> are isochromes for protanopes and deuteranopes (i.e., no significant difference between these two types when it comes to isochromes, but of course their confusion lines are different), and for tritanopes isochromes are found at 485 <span class="math inline">\(\text{nm}\)</span> and 660 <span class="math inline">\(\text{nm}\)</span>.</p>
<div id="fig-cvd_model" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cvd_model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/cvd_model.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cvd_model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.20: Left: isochrome planes and Protanopia confusion lines in LMS cone space; from <span class="citation" data-cites="zhu2022cvd">Zhu (<a href="references.html#ref-zhu2022cvd" role="doc-biblioref">2022c</a>)</span>. According to the <span class="citation" data-cites="brettel1997computerized">Brettel, Viénot, and Mollon (<a href="references.html#ref-brettel1997computerized" role="doc-biblioref">1997</a>)</span> model, the intersection between the isochrome planes and a confusion line is the color a dichromat actually sees for all the colors on that confusion line. Right; the isochrome lines and Deuteranopia confusion lines in the xy-diagram; adapted from <span class="citation" data-cites="confusionlines">Curran919 (<a href="references.html#ref-confusionlines" role="doc-biblioref">2022</a>)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="brettel-et-al.-model" class="level4">
<h4 class="anchored" data-anchor-id="brettel-et-al.-model">Brettel et al.&nbsp;Model</h4>
<p>There have been two main ways to build a model for dichromatic color vision: that of a phenomenological nature such as <span class="citation" data-cites="brettel1997computerized">Brettel, Viénot, and Mollon (<a href="references.html#ref-brettel1997computerized" role="doc-biblioref">1997</a>)</span>, <span class="citation" data-cites="vienot1999digital">Viénot, Brettel, and Mollon (<a href="references.html#ref-vienot1999digital" role="doc-biblioref">1999</a>)</span>, and <span class="citation" data-cites="meyer1988color">Meyer and Greenberg (<a href="references.html#ref-meyer1988color" role="doc-biblioref">1988</a>)</span> and that based on first principles of the visual pathway, such as <span class="citation" data-cites="jiang2016spectral">Jiang, Farrell, and Wandell (<a href="references.html#ref-jiang2016spectral" role="doc-biblioref">2016</a>)</span> and <span class="citation" data-cites="rodriguez2011dichromatic">Rodriguez-Pardo and Sharma (<a href="references.html#ref-rodriguez2011dichromatic" role="doc-biblioref">2011</a>)</span>. We will primarily focus on the phenomenological model described in <span class="citation" data-cites="brettel1997computerized">Brettel, Viénot, and Mollon (<a href="references.html#ref-brettel1997computerized" role="doc-biblioref">1997</a>)</span>. Like all other models, this model is not perfect. It makes assumptions that are not experimentally validated on unilateral dichromats, but it is a popular model that seems to work well in practice. <span class="citation" data-cites="zhu2022cvd">Zhu (<a href="references.html#ref-zhu2022cvd" role="doc-biblioref">2022c</a>)</span> discusses cases where this model falls apart.</p>
<p><span class="citation" data-cites="brettel1997computerized">Brettel, Viénot, and Mollon (<a href="references.html#ref-brettel1997computerized" role="doc-biblioref">1997</a>)</span> assumes that Equal-Energy White (EEW) is also an isochrome. In fact, they assume that the entire plane that contains EEW, 475 <span class="math inline">\(\text{nm}\)</span>, 575 <span class="math inline">\(\text{nm}\)</span>, and Black is an isochrome plane, on which all colors are isochromes for deuteranopes and protanopes. Similarly, the plane that contains EEW, 485 <span class="math inline">\(\text{nm}\)</span>, 660 <span class="math inline">\(\text{nm}\)</span>, and Black is an isochrome plane for tritanopes. Two caveats must be noted here. First, this is not validated against unilateral dichromats; it is just an assumption. Second, the isochrome “plane” is not an actual plane. It is more like two half-planes that share a border. For Protanopia and Deuteranopia, the two half-planes are almost parallel so that they look like part of one plane. The left panel in <a href="#fig-cvd_model" class="quarto-xref">Figure&nbsp;<span>4.20</span></a> shows the two half planes (with distinct colors) for Protanopia.</p>
<p>Assuming that the isochrome plane assumption by <span class="citation" data-cites="brettel1997computerized">Brettel, Viénot, and Mollon (<a href="references.html#ref-brettel1997computerized" role="doc-biblioref">1997</a>)</span> is true, we can then reason about the colors that dichromats actually see: the intersection between the isochrome planes and a confusion line is the color a dichromat actually sees for all the colors on that confusion line. The left panel in <a href="#fig-cvd_model" class="quarto-xref">Figure&nbsp;<span>4.20</span></a> visualizes this, where the trichromatic spectral locus is projected to the isochrome planes along the direction of the confusion lines. The resulting locus lies completely on the isochrome planes and represents how the spectral colors will actually be perceived by a Protanope.</p>
<p>The two isochrome half-planes become two line segments in the xy-diagram. The right panel in <a href="#fig-cvd_model" class="quarto-xref">Figure&nbsp;<span>4.20</span></a> shows how the <span class="citation" data-cites="brettel1997computerized">Brettel, Viénot, and Mollon (<a href="references.html#ref-brettel1997computerized" role="doc-biblioref">1997</a>)</span> model predicts a Deuteranope’s color perception in the xy-diagram.</p>
<p>Modeling anomalous trichromacy is “easy” as long as we know the new set of cone fundamentals. Assuming their subsequent neural processing is the same as that of normal trichromacy, we can then calculate the cone responses in an anomalous trichromatic color space given any light spectrum.</p>
</section>
</section>
<section id="cvd-assistive-technologies" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="cvd-assistive-technologies"><span class="header-section-number">4.6.2</span> CVD Assistive Technologies</h3>
<p>There are many assistive techniques attempting to enhance the color vision of CVD individuals. <span class="citation" data-cites="zhu2024computational">Zhu et al. (<a href="references.html#ref-zhu2024computational" role="doc-biblioref">2024, sec. 3</a>)</span> provides a good review.</p>
<section id="re-coloring-helps-color-discrimination" class="level4">
<h4 class="anchored" data-anchor-id="re-coloring-helps-color-discrimination">Re-Coloring Helps Color Discrimination</h4>
<p>By far the most commonly used technique is called “re-coloring”; it is available on most Operating Systems in laptops, PCs, and smartphones. The idea is to apply a (usually linear) transformation to colors in an image (colloquially referred to as color filters) so that initially confusing colors become distinct (i.e., no longer on a confusion line).</p>
<p>The main limitation of re-coloring is that, while initially confusing colors might be distinguishable after a transformation, these colors will inevitably be confused with others. Fundamentally, a dichromat’s color vision is still two-dimensional, and the confusion lines are still there. Usually the transformation is designed so that a set of ecologically relevant, confusing colors (colors that we commonly encounter in everyday life and are important to discriminate, e.g., red flowers and green leaves) become distinct.</p>
<p>Re-coloring can also be done optically. Many commercially available glasses for CVD individuals, such as those from EnChroma and VINO, use identical spectral “notch filters” for both eyes. The filter eliminates light from a narrow spectral band, where the human L and M cone sensitivities overlap the most. Recall that for Protanomalous and Deuteranomalous individuals, their L and M cone fundamentals are closer than normal, so the L and M cone excitations are very similar. The notch filters act to pull the two cone fundamentals apart and amplify the difference between L cone and M cone excitations. Therefore, in principle, the method can enhance color discrimination for anomalous trichromats but provides no benefit for strict dichromats. In comparative tests, the functional effectiveness of such glasses for anomalous trichromats is also not definitive <span class="citation" data-cites="gomez2018enchroma patterson2022effects">(<a href="references.html#ref-gomez2018enchroma" role="doc-biblioref">Gómez-Robledo et al. 2018</a>; <a href="references.html#ref-patterson2022effects" role="doc-biblioref">Patterson et al. 2022</a>)</span>.</p>
</section>
<section id="color-recognition-by-reconstructing-the-missing-dimension" class="level4">
<h4 class="anchored" data-anchor-id="color-recognition-by-reconstructing-the-missing-dimension">Color Recognition By Reconstructing the Missing Dimension</h4>
<p>Re-coloring methods, thus, do not help with color <em>recognition</em> and <em>naming</em> (“pass me that pink marker” or “look at the person in a red shirt”), which is a common user complaint found in a user study <span class="citation" data-cites="geddes202330">(<a href="references.html#ref-geddes202330" role="doc-biblioref">Geddes, Flatla, and Connelly 2023</a>)</span>. For color recognition, we must restore a three-dimensional color space for dichromats. So the key is to somehow reconstruct the missing dimension.</p>
<p>One idea is to introduce binocular color disparity, where the stimuli are differentially altered for the two eyes. The idea was originated by <span class="citation" data-cites="maxwell1857xviii">Maxwell (<a href="references.html#ref-maxwell1857xviii" role="doc-biblioref">1857</a>)</span> and then later revived by <span class="citation" data-cites="cornsweet1970visual">Cornsweet (<a href="references.html#ref-cornsweet1970visual" role="doc-biblioref">1970</a>)</span>. Maxwell conjectured that the disparity across the two eyes would essentially introduce a new dimension of perception, which would augment the existing 2D percept of a dichromat, providing 3D color perception. <span class="citation" data-cites="knoblauch1995discrimination">Knoblauch and McMahon (<a href="references.html#ref-knoblauch1995discrimination" role="doc-biblioref">1995</a>)</span> shows that the improved color discrimination afforded by binocular filters might have limited use for Protanopes and Deuteranopes.</p>
<p><span class="citation" data-cites="zhu2024computational">Zhu et al. (<a href="references.html#ref-zhu2024computational" role="doc-biblioref">2024</a>)</span> introduces a smartphone App to reconstruct the missing dimension through temporally modulating colors. The idea is that as a user swipes their finger in the App, they apply a color-space transformation such that originally confusing colors undergo distinct color shifts. The combination of the initial 2D color precept with the induced temporal shifts reconstructs a new 3D space for the user. By spending time interacting with our system, users then learn to associate different color names in this new 3D space, thereby recognizing colors.</p>
</section>
</section>
<section id="sec-chpt-hvs-color-cvd-gene" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="sec-chpt-hvs-color-cvd-gene"><span class="header-section-number">4.6.3</span> Genetic Basis of CVD</h3>
<p>L and M cone genes are on the X chromosome. Because the L and M genes are created from a duplication, they are tandemly arrayed (spatially adjacent in a head-to-tail manner) and, thus, are subject to crossovers during recombination of meiosis, which might lead to deletion of a whole gene or hybrid genes in a X chromosome. This is the genetic basis of Protanopia, Deuteranopia, Protanomaly, and Deuteranomaly. <span class="citation" data-cites="onishi2002variations">Onishi et al. (<a href="references.html#ref-onishi2002variations" role="doc-biblioref">2002</a>)</span> shows that only two in a sample of over 3000 macaque monkeys (an Old World monkey) have CVD, much lower than the CVD rate in humans, indicating that the crossovers might be recent <span class="citation" data-cites="lee2008evolution">(<a href="references.html#ref-lee2008evolution" role="doc-biblioref">B. B. Lee 2008</a>)</span>.</p>
<section id="intergenic-crossovers-give-protanopia-and-deuteranopia" class="level4">
<h4 class="anchored" data-anchor-id="intergenic-crossovers-give-protanopia-and-deuteranopia">Intergenic Crossovers Give Protanopia and Deuteranopia</h4>
<p><a href="#fig-recombination" class="quarto-xref">Figure&nbsp;<span>4.21</span></a> illustrates a crossover that can potentially lead to Deuteranopia. The two X chromosomes, due to an <strong>intergenic crossover</strong>, either lose or gain an M gene after recombination. One of the new X chromosomes has only the L cone gene, so an individual inheriting that X chromosome from the mother would get Deuteranopia. Interestingly, while the other X chromosome gets an additional M open gene, only the first two genes are sufficiently expressed. The fact that the L and M cone genes are in an X chromosome means that biological females are less vulnerable to Protanopia and Deuteranopia than biological males, simply because there are two X chromosomes in females. Even if one of the inherited X chromosomes has only, say, a L cone gene, the other inherited X chromosome, if normal, can still be sufficiently be expressed to give both L and M cones.</p>
<div id="fig-recombination" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-recombination-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/recombination.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-recombination-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.21: An intergenic that can potentially give rise to Deuteranopia. Adapted from <span class="citation" data-cites="rodieck1998first">Rodieck (<a href="references.html#ref-rodieck1998first" role="doc-biblioref">1998, p. 219–20</a>)</span>.
</figcaption>
</figure>
</div>
</section>
<section id="intragenic-crossovers-give-protanomaly-and-deuteranomaly" class="level4">
<h4 class="anchored" data-anchor-id="intragenic-crossovers-give-protanomaly-and-deuteranomaly">Intragenic Crossovers Give Protanomaly and Deuteranomaly</h4>
<div id="fig-intragenic_crossover" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-intragenic_crossover-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/intragenic_crosssover.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-intragenic_crossover-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.22: An intragenic crossover that might give rise to Deuteranomaly and “Protanopia”. See text.
</figcaption>
</figure>
</div>
<p><strong>Intragenic crossover</strong> might also occur during recombination, and this would lead to anomalous trichromacy. <a href="#fig-intragenic_crossover" class="quarto-xref">Figure&nbsp;<span>4.22</span></a> shows an intragenic crossover that might give rise to Deuteranomaly and “Protanopia”. The second X chromosome after recombination has a normal L opsin gene and another gene that is a mixture of the L cone gene and the M cone gene. The spectral sensitivity of such a hybrid pigment is in between that of an L cone and an M cone <span class="citation" data-cites="sharpe1999opsin">(<a href="references.html#ref-sharpe1999opsin" role="doc-biblioref">Sharpe et al. 1999</a>)</span>, as illustrated in the left panel in <a href="#fig-abnormal_cone_fundamentals" class="quarto-xref">Figure&nbsp;<span>4.23</span></a>. This is the source of anomalous trichromats.</p>
<div id="fig-abnormal_cone_fundamentals" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-abnormal_cone_fundamentals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/abnormal_cone_fundamentals.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-abnormal_cone_fundamentals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.23: Left: the spectral sensitivities of the hybrid photopigments vary between those of the M- and L-cones depending on where the crossover occurs. Right: if two hybrid genes are sufficiently similar, the individual is effectively dichromatic. Slides credit: Andrew Stockman.
</figcaption>
</figure>
</div>
</section>
<section id="intergenic-crossovers-can-give-abnormal-protanopia-and-deuteranopia" class="level4">
<h4 class="anchored" data-anchor-id="intergenic-crossovers-can-give-abnormal-protanopia-and-deuteranopia">Intergenic Crossovers Can Give Abnormal Protanopia and Deuteranopia</h4>
<p>It is interesting to observe that intragenic crossovers can also give a dichromatic vision, although in a somewhat abnormal form. Observe in <a href="#fig-intragenic_crossover" class="quarto-xref">Figure&nbsp;<span>4.22</span></a> that the first X chromosome after recombination also has a hybrid gene. If the L cone gene dominates, that gene, when inherited, will be expressed in a pigment that has a spectral sensitivity that is closer to that of a L cone. If you want, you can still say that the inheriting individual has “Protanopia”, but its L cone sensitivity is different from that of a normal L cone.</p>
<p>The right panel in <a href="#fig-abnormal_cone_fundamentals" class="quarto-xref">Figure&nbsp;<span>4.23</span></a> illustrates another scenario where dichromatic vision can arise from intragenic crossovers. If the two hybrid genes in the chromosome are sufficiently similar, they will be expressed in two pigments that are sufficiently similar, and the individual effectively has a dichromatic vision <span class="citation" data-cites="sharpe1999opsin">(<a href="references.html#ref-sharpe1999opsin" role="doc-biblioref">Sharpe et al. 1999</a>)</span>.</p>
</section>
<section id="deuteranomaly-is-the-most-common-cvd" class="level4">
<h4 class="anchored" data-anchor-id="deuteranomaly-is-the-most-common-cvd">Deuteranomaly is the Most Common CVD</h4>
<p>Tritanopia and tritanomaly are much rarer than the other forms of CVDs. The gene for S cone opsin is in a nonsex chromosome (chromosome 7), which is not subject to L/M gene crossovers. Gene mutations causing changes in S-cone pigment are much more rare. Among CVDs that are caused by the crossovers, anomalous trichromacy is more common than strict dichromats, and Deuteranomaly is the most common (about 4.9% in caucasians) <span class="citation" data-cites="wyszecki1982color">(<a href="references.html#ref-wyszecki1982color" role="doc-biblioref">Wyszecki and Stiles 1982</a>, Table 1(5.4.2), p.&nbsp;464)</span>, but the statistics certainly vary across ethnic groups <span class="citation" data-cites="birch2012worldwide">(<a href="references.html#ref-birch2012worldwide" role="doc-biblioref">Birch 2012</a>)</span>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-alpern1983perception" class="csl-entry" role="listitem">
Alpern, M, K Kitahara, and DH Krantz. 1983. <span>“Perception of Colour in Unilateral Tritanopia.”</span> <em>The Journal of Physiology</em> 335 (1): 683–97.
</div>
<div id="ref-bauml1993ratio" class="csl-entry" role="listitem">
Bäuml, Karl-Heinz. 1993. <span>“A Ratio Principle for a Red/Green and a Yellow/Blue Channel?”</span> <em>Perception &amp; Psychophysics</em> 53 (3): 338–44.
</div>
<div id="ref-bauml1996color" class="csl-entry" role="listitem">
Bäuml, Karl-Heinz, and Brian A Wandell. 1996. <span>“Color Appearance of Mixture Gratings.”</span> <em>Vision Research</em> 36 (18): 2849–64.
</div>
<div id="ref-baylor1987spectral" class="csl-entry" role="listitem">
Baylor, Denis A, BJ Nunn, and JL Schnapf. 1987. <span>“Spectral Sensitivity of Cones of the Monkey Macaca Fascicularis.”</span> <em>The Journal of Physiology</em> 390 (1): 145–60.
</div>
<div id="ref-blackbodyct" class="csl-entry" role="listitem">
Bhutajata. 2015. <span>“<span class="nocase">Color temperature black body; CC BY-SA 4.0 license</span>.”</span> <a href="https://commons.wikimedia.org/wiki/File:Color_temperature_black_body_800-12200K.svg" class="uri">https://commons.wikimedia.org/wiki/File:Color_temperature_black_body_800-12200K.svg</a>.
</div>
<div id="ref-birch2012worldwide" class="csl-entry" role="listitem">
Birch, Jennifer. 2012. <span>“Worldwide Prevalence of Red-Green Color Deficiency.”</span> <em>JOSA A</em> 29 (3): 313–20.
</div>
<div id="ref-bowmaker1998evolution" class="csl-entry" role="listitem">
Bowmaker, James K. 1998. <span>“Evolution of Colour Vision in Vertebrates.”</span> <em>Eye</em> 12 (3): 541–47.
</div>
<div id="ref-bowmaker2008evolution" class="csl-entry" role="listitem">
———. 2008. <span>“Evolution of Vertebrate Visual Pigments.”</span> <em>Vision Research</em> 48 (20): 2022–41.
</div>
<div id="ref-brainard1996cone" class="csl-entry" role="listitem">
Brainard, DH. 1996. <span>“Cone Contrast and Opponent Modulation Color Spaces.”</span> In <em>Human Color Vision</em>, 2nd ed., 563–79. Optical Society of America.
</div>
<div id="ref-brettel1997computerized" class="csl-entry" role="listitem">
Brettel, Hans, Françoise Viénot, and John D Mollon. 1997. <span>“Computerized Simulation of Color Appearance for Dichromats.”</span> <em>Josa a</em> 14 (10): 2647–55.
</div>
<div id="ref-broadbent2004critical" class="csl-entry" role="listitem">
Broadbent, Arthur D. 2004. <span>“A Critical Review of the Development of the CIE1931 RGB Color-Matching Functions.”</span> <em>Color Research &amp; Application</em> 29 (4): 267–72.
</div>
<div id="ref-broadbent2008calculation" class="csl-entry" role="listitem">
———. 2008. <span>“Calculation from the Original Experimental Data of the CIE 1931 RGB Standard Observer Spectral Chromaticity Coordinates and Color Matching Functions.”</span> <em>Qu<span>é</span>bec, Canada: D<span>é</span>partement de g<span>é</span>nie Chimique, Universit<span>é</span> de Sherbrooke</em>, 1–17.
</div>
<div id="ref-brown1964visual" class="csl-entry" role="listitem">
Brown, Paul K, and George Wald. 1964. <span>“Visual Pigments in Single Rods and Cones of the Human Retina.”</span> <em>Science</em> 144 (3614): 45–52.
</div>
<div id="ref-cornsweet1970visual" class="csl-entry" role="listitem">
Cornsweet, Tom. 1970. <em>Visual Perception</em>. Academic press.
</div>
<div id="ref-crawford1949scotopic" class="csl-entry" role="listitem">
Crawford, BH. 1949. <span>“The Scotopic Visibility Function.”</span> <em>Proceedings of the Physical Society. Section B</em> 62 (5): 321.
</div>
<div id="ref-confusionlines" class="csl-entry" role="listitem">
Curran919. 2022. <span>“<span class="nocase">Color Blind Confusion Lines; CC BY-SA 4.0 license</span>.”</span> <a href="https://commons.wikimedia.org/wiki/File:Color_Blind_Confusion_Lines.png" class="uri">https://commons.wikimedia.org/wiki/File:Color_Blind_Confusion_Lines.png</a>.
</div>
<div id="ref-dacey1994blue" class="csl-entry" role="listitem">
Dacey, Dennis M, and Barry B Lee. 1994. <span>“The’blue-on’opponent Pathway in Primate Retina Originates from a Distinct Bistratified Ganglion Cell Type.”</span> <em>Nature</em> 367 (6465): 731–35.
</div>
<div id="ref-dartnall1983human" class="csl-entry" role="listitem">
Dartnall, Herbert JA, James K Bowmaker, and John Dixon Mollon. 1983. <span>“Human Visual Pigments: Microspectrophotometric Results from the Eyes of Seven Persons.”</span> <em>Proceedings of the Royal Society of London. Series B. Biological Sciences</em> 220 (1218): 115–30.
</div>
<div id="ref-de1958response" class="csl-entry" role="listitem">
De Valois, RL, CJ Smith, ST Kitai, and AJ Karoly. 1958. <span>“Response of Single Cells in Monkey Lateral Geniculate Nucleus to Monochromatic Light.”</span> <em>Science</em> 127 (3292): 238–39.
</div>
<div id="ref-de1966analysis" class="csl-entry" role="listitem">
De Valois, Russell L, Israel Abramov, and Gerald H Jacobs. 1966. <span>“Analysis of Response Patterns of LGN Cells.”</span> <em>JOSA</em> 56 (7): 966–77.
</div>
<div id="ref-derrington1984chromatic" class="csl-entry" role="listitem">
Derrington, Andrew M, John Krauskopf, and Peter Lennie. 1984. <span>“Chromatic Mechanisms in Lateral Geniculate Nucleus of Macaque.”</span> <em>The Journal of Physiology</em> 357 (1): 241–65.
</div>
<div id="ref-devalois1990spatial" class="csl-entry" role="listitem">
DeValois, Russell L, and Karen K DeValois. 1990. <span>“Spatial Vision.”</span>
</div>
<div id="ref-dimmick1939spectralred" class="csl-entry" role="listitem">
Dimmick, Forrest L, and Margaret R Hubbard. 1939a. <span>“The Spectral Components of Psychologically Unique Red.”</span> <em>The American Journal of Psychology</em> 52 (3): 348–53.
</div>
<div id="ref-dimmick1939spectralyellow" class="csl-entry" role="listitem">
———. 1939b. <span>“The Spectral Location of Psychologically Unique Yellow, Green, and Blue.”</span> <em>The American Journal of Psychology</em> 52 (2): 242–54.
</div>
<div id="ref-field2007spatial" class="csl-entry" role="listitem">
Field, Greg D, Alexander Sher, Jeffrey L Gauthier, Martin Greschner, Jonathon Shlens, Alan M Litke, and EJ Chichilnisky. 2007. <span>“Spatial Properties and Functional Organization of Small Bistratified Ganglion Cells in Primate Retina.”</span> <em>Journal of Neuroscience</em> 27 (48): 13261–72.
</div>
<div id="ref-flatla2015colourid" class="csl-entry" role="listitem">
Flatla, David R, Alan R Andrade, Ross D Teviotdale, Dylan L Knowles, and Craig Stewart. 2015. <span>“ColourID.”</span> In <em>Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</em>. ACM.
</div>
<div id="ref-geddes202330" class="csl-entry" role="listitem">
Geddes, Connor, David R Flatla, and Ciabhan L Connelly. 2023. <span>“30 Years of Solving the Wrong Problem: How Recolouring Tool Design Fails Those with Colour Vision Deficiency.”</span> In <em>Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility</em>, 1–13.
</div>
<div id="ref-gegenfurtner2003cortical" class="csl-entry" role="listitem">
Gegenfurtner, Karl R. 2003. <span>“Cortical Mechanisms of Colour Vision.”</span> <em>Nature Reviews Neuroscience</em> 4 (7): 563–72.
</div>
<div id="ref-glassner1995principles" class="csl-entry" role="listitem">
Glassner, Andrew S. 1995. <em>Principles of Digital Image Synthesis</em>. Elsevier.
</div>
<div id="ref-gomez2018enchroma" class="csl-entry" role="listitem">
Gómez-Robledo, Luis, EM Valero, R Huertas, MA Martı́nez-Domingo, and Javier Hernández-Andrés. 2018. <span>“Do EnChroma Glasses Improve Color Vision for Colorblind Subjects?”</span> <em>Optics Express</em> 26 (22): 28693–703.
</div>
<div id="ref-gouras1979enhancement" class="csl-entry" role="listitem">
Gouras, P, and E Zrenner. 1979. <span>“Enhancement of Luminance Flicker by Color-Opponent Mechanisms.”</span> <em>Science</em> 205 (4406): 587–89.
</div>
<div id="ref-graham1958color" class="csl-entry" role="listitem">
Graham, Clarence Henry, and Yun Hsia. 1958. <span>“Color Defect and Color Theory: Studies of Normal and Color-Blind Persons, Including a Subject Color-Blind in One Eye but Not in the Other.”</span> <em>Science</em> 127 (3300): 675–82.
</div>
<div id="ref-guild1931colorimetric" class="csl-entry" role="listitem">
Guild, John. 1931. <span>“The Colorimetric Properties of the Spectrum.”</span> <em>Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character</em> 230 (681-693): 149–87.
</div>
<div id="ref-hering1878lehre" class="csl-entry" role="listitem">
Hering, Ewald. 1878. <em>Zur Lehre Vom Lichtsinne: Sechs Mittheilungen an Die Kaiser. Akad. Der Wissenschaften in Wien</em>. C. Gerold’s Sohn.
</div>
<div id="ref-hering1964outlines" class="csl-entry" role="listitem">
———. 1964. <em>Outlines of a Theory of the Light Sense (Translation by Jameson and Hurvish; Originally Published in 1878)</em>. Harvard University Press.
</div>
<div id="ref-hunt1998molecular" class="csl-entry" role="listitem">
Hunt, David M, Kanwaljit S Dulai, Jill A Cowing, Catherine Julliot, John D Mollon, James K Bowmaker, Wen-Hsiung Li, and David Hewett-Emmett. 1998. <span>“Molecular Evolution of Trichromacy in Primates.”</span> <em>Vision Research</em> 38 (21): 3299–3306.
</div>
<div id="ref-hurvich1955some" class="csl-entry" role="listitem">
Hurvich, Leo M, and Dorothea Jameson. 1955. <span>“Some Quantitative Aspects of an Opponent-Colors Theory. II. Brightness, Saturation, and Hue in Normal and Dichromatic Vision.”</span> <em>JOSA</em> 45 (8): 602–16.
</div>
<div id="ref-hurvich1957opponent" class="csl-entry" role="listitem">
———. 1957. <span>“An Opponent-Process Theory of Color Vision.”</span> <em>Psychological Review</em> 64 (6p1): 384.
</div>
<div id="ref-jacobs2009evolution" class="csl-entry" role="listitem">
Jacobs, Gerald H. 2009. <span>“Evolution of Colour Vision in Mammals.”</span> <em>Philosophical Transactions of the Royal Society B: Biological Sciences</em> 364 (1531): 2957–67.
</div>
<div id="ref-jameson1955some" class="csl-entry" role="listitem">
Jameson, Dorothea, and Leo M Hurvich. 1955. <span>“Some Quantitative Aspects of an Opponent-Colors Theory. I. Chromatic Responses and Spectral Saturation.”</span> <em>JOSA</em> 45 (7): 546–52.
</div>
<div id="ref-jiang2016spectral" class="csl-entry" role="listitem">
Jiang, Haomiao, Joyce Farrell, and Brian Wandell. 2016. <span>“A Spectral Estimation Theory for Color Appearance Matching.”</span> <em>Electronic Imaging</em> 28:1–4.
</div>
<div id="ref-aop" class="csl-entry" role="listitem">
Johannes Vermeer. 1668. <span>“<span class="nocase">The Art of Painting; released into the public domain</span>.”</span> <a href="https://en.wikipedia.org/wiki/File:Jan_Vermeer_-_The_Art_of_Painting_-_Google_Art_Project.jpg" class="uri">https://en.wikipedia.org/wiki/File:Jan_Vermeer_-_The_Art_of_Painting_-_Google_Art_Project.jpg</a>.
</div>
<div id="ref-jordan2010dimensionality" class="csl-entry" role="listitem">
Jordan, Gabriele, Samir S Deeb, Jenny M Bosten, and John D Mollon. 2010. <span>“The Dimensionality of Color Vision in Carriers of Anomalous Trichromacy.”</span> <em>Journal of Vision</em> 10 (8): 12–12.
</div>
<div id="ref-judd1949color" class="csl-entry" role="listitem">
Judd, Deane B. 1949. <span>“The Color Perceptions of Deuteranopic and Protanopic Observers.”</span> <em>JOSA</em> 39 (3): 252–56.
</div>
<div id="ref-judd1951report" class="csl-entry" role="listitem">
———. 1951. <span>“Report of US Secretariat Committee on Colorimetry and Artificial Daylight.”</span> <em>CIE Proceedings, 1951</em> 1:11.
</div>
<div id="ref-judd1964spectral" class="csl-entry" role="listitem">
Judd, Deane B, David L MacAdam, Günter Wyszecki, HW Budde, HR Condit, ST Henderson, and JL Simonds. 1964. <span>“Spectral Distribution of Typical Daylight as a Function of Correlated Color Temperature.”</span> <em>Josa</em> 54 (8): 1031–40.
</div>
<div id="ref-knoblauch1995discrimination" class="csl-entry" role="listitem">
Knoblauch, Kenneth, and Matthew J McMahon. 1995. <span>“Discrimination of Binocular Color Mixtures in Dichromacy: Evaluation of the Maxwell–Cornsweet Conjecture.”</span> <em>JOSA A</em> 12 (10): 2219–29.
</div>
<div id="ref-krauskopf1992color" class="csl-entry" role="listitem">
Krauskopf, John, and Gegenfurtner Karl. 1992. <span>“Color Discrimination and Adaptation.”</span> <em>Vision Research</em> 32 (11): 2165–75.
</div>
<div id="ref-kries1905ubersicht" class="csl-entry" role="listitem">
Kries, Johannes von. 1905. <span>“<span>Ü</span>bersicht Der Tatsachen, Ergebnisse f<span>ü</span>r Die Theoretische Auffassung Des Sehorgans: Zonentheorie.”</span> In <em>Handbuch Der Physiologie Des Menschen, Dritter Band: Physiologie Der Sinne</em>, edited by Willibald Nagel, 3rd ed., 269--274. Vieweg und Sohn, Braunschweig.
</div>
<div id="ref-lamb2013evolution" class="csl-entry" role="listitem">
Lamb, Trevor D. 2013. <span>“Evolution of Phototransduction, Vertebrate Photoreceptors and Retina.”</span> <em>Progress in Retinal and Eye Research</em> 36:52–119.
</div>
<div id="ref-lamb2016rods" class="csl-entry" role="listitem">
———. 2016. <span>“Why Rods and Cones?”</span> <em>Eye</em> 30 (2): 179–85.
</div>
<div id="ref-lamb2020evolution" class="csl-entry" role="listitem">
———. 2020. <span>“Evolution of the Genes Mediating Phototransduction in Rod and Cone Photoreceptors.”</span> <em>Progress in Retinal and Eye Research</em> 76:100823.
</div>
<div id="ref-lamb2022photoreceptor" class="csl-entry" role="listitem">
———. 2022. <span>“Photoreceptor Physiology and Evolution: Cellular and Molecular Basis of Rod and Cone Phototransduction.”</span> <em>The Journal of Physiology</em> 600 (21): 4585–4601.
</div>
<div id="ref-lamb2007evolution" class="csl-entry" role="listitem">
Lamb, Trevor D, Shaun P Collin, and Edward N Pugh. 2007. <span>“Evolution of the Vertebrate Eye: Opsins, Photoreceptors, Retina and Eye Cup.”</span> <em>Nature Reviews Neuroscience</em> 8 (12): 960–76.
</div>
<div id="ref-larimer1974opponent" class="csl-entry" role="listitem">
Larimer, James, Carol M Cicerone, et al. 1974. <span>“Opponent-Process Additivity-i: Red/Green Equilibria.”</span> <em>Vision Research</em> 14 (11): 1127–40.
</div>
<div id="ref-larimer1975opponent" class="csl-entry" role="listitem">
Larimer, James, David H Krantz, and Carol M Cicerone. 1975. <span>“Opponent Process Additivity—II. Yellow/Blue Equilibria and Nonlinear Models.”</span> <em>Vision Research</em> 15 (6): 723–31.
</div>
<div id="ref-lee2008evolution" class="csl-entry" role="listitem">
Lee, Barry B. 2008. <span>“The Evolution of Concepts of Color Vision.”</span> <em>Neurociencias</em> 4 (4): 209.
</div>
<div id="ref-lee1988physiological" class="csl-entry" role="listitem">
Lee, BB, PR Martin, and A Valberg. 1988. <span>“The Physiological Basis of Heterochromatic Flicker Photometry Demonstrated in the Ganglion Cells of the Macaque Retina.”</span> <em>The Journal of Physiology</em> 404 (1): 323–47.
</div>
<div id="ref-lennie1993luminance" class="csl-entry" role="listitem">
Lennie, Peter, Joel Pokorny, and Vivianne C Smith. 1993. <span>“Luminance.”</span> <em>JOSA A</em> 10 (6): 1283–93.
</div>
<div id="ref-macadam1942visual" class="csl-entry" role="listitem">
MacAdam, David L. 1942. <span>“Visual Sensitivities to Color Differences in Daylight.”</span> <em>Josa</em> 32 (5): 247–74.
</div>
<div id="ref-macadam1943specification" class="csl-entry" role="listitem">
———. 1943. <span>“Specification of Small Chromaticity Differences.”</span> <em>Josa</em> 33 (1): 18–26.
</div>
<div id="ref-macleod1976red" class="csl-entry" role="listitem">
MacLeod, Donald IA, and Peter Lennie. 1976. <span>“Red-Green Blindness Confined to One Eye.”</span> <em>Vision Research</em> 16 (7): 691–702.
</div>
<div id="ref-cie1931rgbcmf" class="csl-entry" role="listitem">
Marco Polo. 2007. <span>“<span class="nocase">CIE1931 RGB CMF; released into the public domain by the copyright holder</span>.”</span> <a href="https://commons.wikimedia.org/wiki/File:CIE1931_RGBCMF.svg" class="uri">https://commons.wikimedia.org/wiki/File:CIE1931_RGBCMF.svg</a>.
</div>
<div id="ref-marks1964visual" class="csl-entry" role="listitem">
Marks, WB, William H Dobelle, and Edward F MacNichol Jr. 1964. <span>“Visual Pigments of Single Primate Cones.”</span> <em>Science</em> 143 (3611): 1181–83.
</div>
<div id="ref-maxwell1857xviii" class="csl-entry" role="listitem">
Maxwell, James Clerk. 1857. <span>“XVIII.—Experiments on Colour, as Perceived by the Eye, with Remarks on Colour-Blindness.”</span> <em>Earth and Environmental Science Transactions of the Royal Society of Edinburgh</em> 21 (2): 275–98.
</div>
<div id="ref-meyer1988color" class="csl-entry" role="listitem">
Meyer, Gary W, and Donald P Greenberg. 1988. <span>“Color-Defective Vision and Computer Graphics Displays.”</span> <em>IEEE Computer Graphics and Applications</em> 8 (5): 28–40.
</div>
<div id="ref-milic2015enhancement" class="csl-entry" role="listitem">
Milić, Neda, Dragoljub Novaković, and Branko Milosavljević. 2015. <span>“Enhancement of Image Content for Observers with Colour Vision Deficiencies.”</span> <em>Color Image and Video Enhancement</em>, 315–43.
</div>
<div id="ref-mollon2003introduction" class="csl-entry" role="listitem">
Mollon, John D. 2003. <span>“Introduction: Thomas Young and the Trichromatic Theory of Colour Vision.”</span> In <em>Normal &amp; Defective Colour Vision</em>, edited by John D Mollon, Joel Pokorny, and Ken Knoblauch, 19--34. Oxford University Press.
</div>
<div id="ref-morshedian2015single" class="csl-entry" role="listitem">
Morshedian, Ala, and Gordon L Fain. 2015. <span>“Single-Photon Sensitivity of Lamprey Rods with Cone-Like Outer Segments.”</span> <em>Current Biology</em> 25 (4): 484–87.
</div>
<div id="ref-nathans1986molecular" class="csl-entry" role="listitem">
Nathans, Jeremy, Darcy Thomas, and David S Hogness. 1986. <span>“Molecular Genetics of Human Color Vision: The Genes Encoding Blue, Green, and Red Pigments.”</span> <em>Science</em> 232 (4747): 193–202.
</div>
<div id="ref-newton1952opticks" class="csl-entry" role="listitem">
Newton, Isaac. 1704. <em>Opticks, or, a Treatise of the Reflections, Refractions, Inflections &amp; Colours of Light</em>. London: Smith; Walford.
</div>
<div id="ref-okano1992primary" class="csl-entry" role="listitem">
Okano, Toshiyuki, DAISUKE KoJIMA, Yoshitaka Fukada, Yoshinori Shichida, and Toru Yoshizawa. 1992. <span>“Primary Structures of Chicken Cone Visual Pigments: Vertebrate Rhodopsins Have Evolved Out of Cone Visual Pigments.”</span> <em>Proceedings of the National Academy of Sciences</em> 89 (13): 5932–36.
</div>
<div id="ref-okano1994pinopsin" class="csl-entry" role="listitem">
Okano, Toshiyuki, Toru Yoshizawa, and Yoshitaka Fukada. 1994. <span>“Pinopsin Is a Chicken Pineal Photoreceptive Molecule.”</span> <em>Nature</em> 372 (6501): 94–97.
</div>
<div id="ref-onishi2002variations" class="csl-entry" role="listitem">
Onishi, Akishi, Satoshi Koike, Miki Ida-Hosonuma, Hiroo Imai, Yoshinori Shichida, Osamu Takenaka, Akitoshi Hanazawa, et al. 2002. <span>“Variations in Long-and Middle-Wavelength-Sensitive Opsin Gene Loci in Crab-Eating Monkeys.”</span> <em>Vision Research</em> 42 (3): 281–92.
</div>
<div id="ref-patterson2022effects" class="csl-entry" role="listitem">
Patterson, EJ, RR Mastey, JA Kuchenbecker, Jessica Rowlan, Jay Neitz, Maureen Neitz, and Joseph Carroll. 2022. <span>“Effects of Color-Enhancing Glasses on Color Vision in Congenital Red-Green Color Deficiencies.”</span> <em>Optics Express</em> 30 (17): 31182–94.
</div>
<div id="ref-poirson1993appearance" class="csl-entry" role="listitem">
Poirson, Allen B, and Brian A Wandell. 1993. <span>“Appearance of Colored Patterns: Pattern–Color Separability.”</span> <em>JOSA A</em> 10 (12): 2458–70.
</div>
<div id="ref-rodieck1998first" class="csl-entry" role="listitem">
Rodieck, Robert W. 1998. <em>The First Steps in Seeing</em>. Sinauer Associates.
</div>
<div id="ref-rodriguez2011dichromatic" class="csl-entry" role="listitem">
Rodriguez-Pardo, Carlos Eduardo, and Gaurav Sharma. 2011. <span>“Dichromatic Color Perception in a Two Stage Model: Testing for Cone Replacement and Cone Loss Models.”</span> In <em>2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis</em>, 12–17. IEEE.
</div>
<div id="ref-sato2018pinopsin" class="csl-entry" role="listitem">
Sato, Keita, Takahiro Yamashita, Keiichi Kojima, Kazumi Sakai, Yuki Matsutani, Masataka Yanagawa, Yumiko Yamano, et al. 2018. <span>“Pinopsin Evolved as the Ancestral Dim-Light Visual Opsin in Vertebrates.”</span> <em>Communications Biology</em> 1 (1): 156.
</div>
<div id="ref-schnapf1987spectral" class="csl-entry" role="listitem">
Schnapf, JL, TW Kraft, and Denis A Baylor. 1987. <span>“Spectral Sensitivity of Human Cone Photoreceptors.”</span> <em>Nature</em> 325 (6103): 439–41.
</div>
<div id="ref-schrodinger1925verhaltnis" class="csl-entry" role="listitem">
Schrödinger, Erwin. 1925. <span>“<span>Ü</span>ber Das Verh<span>ä</span>ltnis Der Vierfarben-Zur Dreifarbentheorie.”</span> <em>Sitzungberichte Abt 2a, Mathematik, Astronomie, Physik, Meteorologie Und Mechanik Akademie Der Wissenschaften in Wien, Mathematisch-Naturwissenschaftliche Klasse</em> 134:471–90.
</div>
<div id="ref-schrodinger1994relationship" class="csl-entry" role="listitem">
———. 1994. <span>“On the Relationship of Four-Color Theory to Three-Color Theory (Translation by National Translation Center; Originally Published in 1925).”</span> <em>Color Research and Application</em> 19 (1): 37.
</div>
<div id="ref-service2016the" class="csl-entry" role="listitem">
Service, Phil. 2016. <span>“The Wright – Guild Experiments and the Development of the CIE 1931 RGB and XYZ Color Spaces.”</span>
</div>
<div id="ref-sharpe2005luminous" class="csl-entry" role="listitem">
Sharpe, Lindsay T, Andrew Stockman, Wolfgang Jagla, and Herbert Jägle. 2005. <span>“A Luminous Efficiency Function, v*(<span class="math inline">\(\lambda\)</span>), for Daylight Adaptation.”</span> <em>Journal of Vision</em> 5 (11): 3–3.
</div>
<div id="ref-sharpe2011luminous" class="csl-entry" role="listitem">
———. 2011. <span>“A Luminous Efficiency Function, VD65*(<span class="math inline">\(\lambda\)</span>), for Daylight Adaptation: A Correction.”</span> <em>Color Research &amp; Application</em> 36 (1): 42–46.
</div>
<div id="ref-sharpe1999opsin" class="csl-entry" role="listitem">
Sharpe, Lindsay T, Andrew Stockman, Herbert Jägle, and Jeremy Nathans. 1999. <span>“Opsin Genes, Cone Photopigments, Color Vision, and Color Blindness.”</span> <em>Color Vision: From Genes to Perception</em> 351:3–52.
</div>
<div id="ref-shevell2017color" class="csl-entry" role="listitem">
Shevell, Steven K, and Paul R Martin. 2017. <span>“Color Opponency: Tutorial.”</span> <em>JOSA A</em> 34 (7): 1099–1108.
</div>
<div id="ref-shichida2009evolution" class="csl-entry" role="listitem">
Shichida, Yoshinori, and Take Matsuyama. 2009. <span>“Evolution of Opsins and Phototransduction.”</span> <em>Philosophical Transactions of the Royal Society B: Biological Sciences</em> 364 (1531): 2881–95.
</div>
<div id="ref-simunovic2010colour" class="csl-entry" role="listitem">
Simunovic, MP. 2010. <span>“Colour Vision Deficiency.”</span> <em>Eye</em> 24 (5): 747–55.
</div>
<div id="ref-sloan1948case" class="csl-entry" role="listitem">
Sloan, Louise L, and Lorraine Wollach. 1948. <span>“A Case of Unilateral Deuteranopia.”</span> <em>JOSA</em> 38 (6): 502–9.
</div>
<div id="ref-stiles1959npl" class="csl-entry" role="listitem">
Stiles, Walter Stanley, and Jennifer M Burch. 1959. <span>“NPL Colour-Matching Investigation: Final Report (1958).”</span> <em>Optica Acta: International Journal of Optics</em> 6 (1): 1–26.
</div>
<div id="ref-stiles1955interim" class="csl-entry" role="listitem">
Stiles, WS, and JM Burch. 1955. <span>“Interim Report to the Commission Internationale de l’eclairage, Zurich, 1955, on the National Physical Laboratory’s Investigation of Colour-Matching (1955).”</span> <em>Optica Acta: International Journal of Optics</em> 2 (4): 168–81.
</div>
<div id="ref-stockman2000spectral" class="csl-entry" role="listitem">
Stockman, Andrew, and Lindsay T Sharpe. 2000. <span>“The Spectral Sensitivities of the Middle-and Long-Wavelength-Sensitive Cones Derived from Measurements in Observers of Known Genotype.”</span> <em>Vision Research</em> 40 (13): 1711–37.
</div>
<div id="ref-stockman1999spectral" class="csl-entry" role="listitem">
Stockman, Andrew, Lindsay T Sharpe, and Clemens Fach. 1999. <span>“The Spectral Sensitivity of the Human Short-Wavelength Sensitive Cones Derived from Thresholds and Color Matches.”</span> <em>Vision Research</em> 39 (17): 2901–27.
</div>
<div id="ref-svaetichin1953cone" class="csl-entry" role="listitem">
Svaetichin, G. 1953. <span>“The Cone Action Potential.”</span> <em>Acta Physiol Scand 29</em> 29:565–600.
</div>
<div id="ref-svaetichin1956spectral" class="csl-entry" role="listitem">
Svaetichin, G. 1956. <span>“Spectral Response Curves from Single Cones.”</span> <em>Acta Physiol Scand</em> 39:17–46.
</div>
<div id="ref-svaetichin1958retinal" class="csl-entry" role="listitem">
Svaetichin, G., and Edward F MacNichol Jr. 1958. <span>“Retinal Mechanisms for Chromatic and Achromatic Vision.”</span> <em>Annals of the New York Academy of Sciences</em> 74 (2): 385–404.
</div>
<div id="ref-takanaka1998light" class="csl-entry" role="listitem">
Takanaka, Yoko, Toshiyuki Okano, Masayuki Iigo, and Yoshitaka Fukada. 1998. <span>“Light-Dependent Expression of Pinopsin Gene in Chicken Pineal Gland.”</span> <em>Journal of Neurochemistry</em> 70 (3): 908–13.
</div>
<div id="ref-vienot1999digital" class="csl-entry" role="listitem">
Viénot, Françoise, Hans Brettel, and John D Mollon. 1999. <span>“Digital Video Colourmaps for Checking the Legibility of Displays by Dichromats.”</span> <em>Color Research &amp; Application</em> 24 (4): 243–52.
</div>
<div id="ref-vos1978colorimetric" class="csl-entry" role="listitem">
Vos, Johannes J. 1978. <span>“Colorimetric and Photometric Properties of a 2 Fundamental Observer.”</span> <em>Color Research &amp; Application</em> 3 (3): 125–28.
</div>
<div id="ref-wald1945human" class="csl-entry" role="listitem">
Wald, George. 1945. <span>“Human Vision and the Spectrum.”</span> <em>Science</em> 101 (2635): 653–58.
</div>
<div id="ref-wandell1995foundations" class="csl-entry" role="listitem">
Wandell, Brian A. 1995. <em>Foundations of Vision</em>. Sinauer Associates.
</div>
<div id="ref-wiesel1966spatial" class="csl-entry" role="listitem">
Wiesel, Torsten N, and David H Hubel. 1966. <span>“Spatial and Chromatic Interactions in the Lateral Geniculate Body of the Rhesus Monkey.”</span> <em>Journal of Neurophysiology</em> 29 (6): 1115–56.
</div>
<div id="ref-wright1928trichromatic" class="csl-entry" role="listitem">
Wright, WD. 1928. <span>“A Trichromatic Colorimeter with Spectral Primaries.”</span> <em>Transactions of the Optical Society</em> 29 (5): 225.
</div>
<div id="ref-wright1930re" class="csl-entry" role="listitem">
———. 1930. <span>“A Re-Determination of the Mixture Curves of the Spectrum.”</span> <em>Transactions of the Optical Society</em> 31 (4): 201.
</div>
<div id="ref-wright1929re" class="csl-entry" role="listitem">
Wright, William David. 1929. <span>“A Re-Determination of the Trichromatic Coefficients of the Spectral Colours.”</span> <em>Transactions of the Optical Society</em> 30 (4): 141.
</div>
<div id="ref-wyszecki1982color" class="csl-entry" role="listitem">
Wyszecki, Günther, and WS Stiles. 1982. <em>Color Science: Concepts and Methods, Quantitative Data and Formulae</em>. John wiley &amp; sons.
</div>
<div id="ref-young1802ii" class="csl-entry" role="listitem">
Young, Thomas. 1802. <span>“II. The Bakerian Lecture. On the Theory of Light and Colours.”</span> <em>Philosophical Transactions of the Royal Society of London</em>, no. 92, 12–48.
</div>
<div id="ref-zhu2020how" class="csl-entry" role="listitem">
Zhu, Yuhao. 2020. <span>“<span class="nocase">How the CIE 1931 RGB Color Matching Functions Were Developed from the Initial Color Matching Experiments</span>.”</span> <a href="https://yuhaozhu.com/blog/cmf.html" class="uri">https://yuhaozhu.com/blog/cmf.html</a>.
</div>
<div id="ref-zhu2022cone2cmf" class="csl-entry" role="listitem">
———. 2022a. <span>“<span class="nocase">Interative Tutorial: Building a Color Space From Cone Fundamentals</span>.”</span> <a href="https://horizon-lab.org/colorvis/cone2cmf.html" class="uri">https://horizon-lab.org/colorvis/cone2cmf.html</a>.
</div>
<div id="ref-zhu2022xyz" class="csl-entry" role="listitem">
———. 2022b. <span>“<span>Interative Tutorial: CIE 1931 XYZ Color Space</span>.”</span> <a href="https://horizon-lab.org/colorvis/xyz.html" class="uri">https://horizon-lab.org/colorvis/xyz.html</a>.
</div>
<div id="ref-zhu2022cvd" class="csl-entry" role="listitem">
———. 2022c. <span>“<span class="nocase">Interative Tutorial: Understanding and Modeling Color Blindness</span>.”</span> <a href="https://horizon-lab.org/colorvis/colorblind.html" class="uri">https://horizon-lab.org/colorvis/colorblind.html</a>.
</div>
<div id="ref-zhu2022gamut" class="csl-entry" role="listitem">
———. 2022d. <span>“<span>Interative Tutorial: Visualizing Human Visual Gamut</span>.”</span> <a href="https://horizon-lab.org/colorvis/gamutvis.html" class="uri">https://horizon-lab.org/colorvis/gamutvis.html</a>.
</div>
<div id="ref-zhu2024computational" class="csl-entry" role="listitem">
Zhu, Yuhao, Ethan Chen, Colin Hascup, Yukang Yan, and Gaurav Sharma. 2024. <span>“Computational Trichromacy Reconstruction: Empowering the Color-Vision Deficient to Recognize Colors Using Augmented Reality.”</span> In <em>Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology</em>, 1–17.
</div>
</div>
</section>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>After all, artificial lights are a very recent thing in the scale of evolution, so our HVS has not had a chance to adapt to non-daylight colors yet, if ever.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>One subtlety is that <span class="citation" data-cites="baylor1987spectral">Baylor, Nunn, and Schnapf (<a href="references.html#ref-baylor1987spectral" role="doc-biblioref">1987</a>)</span> used suction electrode to measure electrical responses (<a href="hvs-receptor.html#sec-chpt-hvs-receptor-suction" class="quarto-xref"><span>Section 3.2.2</span></a>), so they obtained only the relative absorbance not the absolute absorption of the pigments. So what they actually ended up doing is to use the psychophysical CMFs to fit the peak axial absorption and calculate the cone fundamentals, and show that the regressed CMFs from the so-obtained cone fundamentals match that from psychophysics.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>see translation in <span class="citation" data-cites="hering1964outlines">Hering (<a href="references.html#ref-hering1964outlines" role="doc-biblioref">1964</a>)</span><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>see translation in <span class="citation" data-cites="schrodinger1994relationship">Schrödinger (<a href="references.html#ref-schrodinger1994relationship" role="doc-biblioref">1994</a>)</span><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>In later research by Jameson and Hurvich, their white-black function was made equal to the CIE 1924 luminous efficiency function <span class="citation" data-cites="hurvich1955some">(<a href="references.html#ref-hurvich1955some" role="doc-biblioref">Hurvich and Jameson 1955, p. 604</a>)</span>, which is known to have severe flaws at low wavelengths and which is later corrected by <span class="citation" data-cites="judd1951report">Judd (<a href="references.html#ref-judd1951report" role="doc-biblioref">1951</a>)</span> and <span class="citation" data-cites="vos1978colorimetric">Vos (<a href="references.html#ref-vos1978colorimetric" role="doc-biblioref">1978</a>)</span>. Compared to the Judd and Vos corrections, the function shown here has the advantage of being “physiologically relevant” in that the LEF is a linear combination of the cone fundamentals, whereas both the CIE 1924 LEF and its later corrections are not intentionally designed to be linear combinations of anything.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>named after the three authors; the L is Peter Lennie, who was twice on the faculty at University of Rochester and served as the Provost<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Again, what is considered achromatic depends on the observer’s adaptation state; there is no single achromatic color.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Of course, it is conceivable the result might vary in population and depend on the adaptation state (i.e., what is considered white/achromatic).<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./hvs-receptor.html" class="pagination-link" aria-label="Photoreceptors">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Photoreceptors</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./hvs-colorimetry.html" class="pagination-link" aria-label="Colorimetry">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Colorimetry</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>