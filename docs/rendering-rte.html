<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>13&nbsp; Rendering Volume and Subsurface Scattering – Foundations of Visual Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./rendering-nflux.html" rel="next">
<link href="./rendering-sss.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./rendering.html">Rendering</a></li><li class="breadcrumb-item"><a href="./rendering-rte.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Rendering Volume and Subsurface Scattering</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Foundations of Visual Computing</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Foundations-of-Visual-Computing.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">An Invitation to Visual Computing</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./hvs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Human Visual System</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">From Light to Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-receptor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Photoreceptors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-color.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Color Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-colorimetry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Colorimetry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Visual Adaptations and Constancy</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./rendering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rendering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-radiometry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Radiometry and Photometry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-lightfield.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Light Field</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-re.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Rendering Surface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-surface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Modeling Material Surface</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-sss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Volume and Subsurface Scattering Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-rte.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Rendering Volume and Subsurface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-nflux.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">The N-Flux Theory</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./imaging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Imaging</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Imaging Optics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-sensor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Image Sensor Architecture</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-noise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-isp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Camera Signal Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./display.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Display</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Optical Mechanisms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-electronics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Driving Circuits</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-signal-processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Display Signal Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-chpt-mat-vs-rte-rte" id="toc-sec-chpt-mat-vs-rte-rte" class="nav-link active" data-scroll-target="#sec-chpt-mat-vs-rte-rte"><span class="header-section-number">13.1</span> Radiative Transfer Equation</a></li>
  <li><a href="#sec-chpt-mat-vs-rte-vre" id="toc-sec-chpt-mat-vs-rte-vre" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-vre"><span class="header-section-number">13.2</span> Volume Rendering Equation</a></li>
  <li><a href="#sec-chpt-mat-vs-rte-vis" id="toc-sec-chpt-mat-vs-rte-vis" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-vis"><span class="header-section-number">13.3</span> Discrete VRE and Scientific Volume Visualization</a>
  <ul class="collapse">
  <li><a href="#another-discrete-form-of-vre" id="toc-another-discrete-form-of-vre" class="nav-link" data-scroll-target="#another-discrete-form-of-vre"><span class="header-section-number">13.3.1</span> Another Discrete Form of VRE</a></li>
  <li><a href="#sec-chpt-mat-vs-rte-vis-compare" id="toc-sec-chpt-mat-vs-rte-vis-compare" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-vis-compare"><span class="header-section-number">13.3.2</span> The Second Form is More Flexible</a></li>
  <li><a href="#sec-chpt-mat-vs-rte-vis-vis" id="toc-sec-chpt-mat-vs-rte-vis-vis" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-vis-vis"><span class="header-section-number">13.3.3</span> Visualization is Not (Necessarily) Physically-Based Rendering!</a></li>
  <li><a href="#density-fields" id="toc-density-fields" class="nav-link" data-scroll-target="#density-fields"><span class="header-section-number">13.3.4</span> Density Fields</a></li>
  </ul></li>
  <li><a href="#sec-chpt-mat-vs-rte-nr" id="toc-sec-chpt-mat-vs-rte-nr" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-nr"><span class="header-section-number">13.4</span> Discrete VRE in (Neural) Radiance-Field Rendering</a>
  <ul class="collapse">
  <li><a href="#sec-chpt-mat-vs-rte-nr-why" id="toc-sec-chpt-mat-vs-rte-nr-why" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-nr-why"><span class="header-section-number">13.4.1</span> VRE for Surface Rendering?</a></li>
  <li><a href="#volume-graphics-vs.-point-based-graphics" id="toc-volume-graphics-vs.-point-based-graphics" class="nav-link" data-scroll-target="#volume-graphics-vs.-point-based-graphics"><span class="header-section-number">13.4.2</span> Volume Graphics vs.&nbsp;Point-Based Graphics</a></li>
  <li><a href="#sec-chpt-mat-vs-rte-nr-splatting" id="toc-sec-chpt-mat-vs-rte-nr-splatting" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-rte-nr-splatting"><span class="header-section-number">13.4.3</span> Splatting is Signal Filtering</a></li>
  </ul></li>
  <li><a href="#sec-chpt-mat-vs-sca-bssrdf" id="toc-sec-chpt-mat-vs-sca-bssrdf" class="nav-link" data-scroll-target="#sec-chpt-mat-vs-sca-bssrdf"><span class="header-section-number">13.5</span> Integrating Surface Scattering with Volume Scattering</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./rendering.html">Rendering</a></li><li class="breadcrumb-item"><a href="./rendering-rte.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Rendering Volume and Subsurface Scattering</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-chpt-mat-vs-rte" class="quarto-section-identifier"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Rendering Volume and Subsurface Scattering</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="hidden">
<p><span class="math display">\[
\def\oi{{\omega_i}}
\def\os{{\omega_s}}
\def\Oi{{\Omega_i}}
\def\Os{{\Omega_s}}
\def\d{{\text{d}}}
\def\D{{\Delta}}
\def\do{{\d\omega}}
\def\Do{{\Delta\omega}}
\def\doi{{\d\omega_i}}
\def\dos{{\d\omega_s}}
\def\Doi{{\D\omega_i}}
\def\Dos{{\D\omega_s}}
\def\H{{\mathbf{H}}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cL}{\mathcal{L}}
\]</span></p>
</div>
<p>So far we have assumed that a ray can only be attenuated, which can happen only when the illumination is collimated and we assume single scattering. Under this assumption, <a href="rendering-sss.html#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>12.14</span></a> allows us to calculate any radiance in the medium (by weakening the initial radiance). General media are much more complicated: illumination can be from anywhere, and multiple scattering must be accounted for. As a result, external photons can be scattered into a ray of interest, as we have intuitively discussed in <a href="rendering-sss.html#sec-chpt-mat-vs-sca-intuition" class="quarto-xref"><span>Section 12.2.1</span></a>.</p>
<p>In the realm of geometric optics and radiometry, the general way to model lights going through a material/medium amounts to solving the so-called <strong>Radiative Transfer Equation</strong> (RTE), whose modern version was established by <span class="citation" data-cites="chandrasekhar1960radiative">Chandrasekhar (<a href="references.html#ref-chandrasekhar1960radiative" role="doc-biblioref">1960</a>)</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, and <span class="citation" data-cites="kajiya1984ray">Kajiya and Von Herzen (<a href="references.html#ref-kajiya1984ray" role="doc-biblioref">1984</a>)</span> was the first to introduce it to computer graphics. The RTE provides the mathematical tool to model an arbitrary radiance in a medium (<a href="#sec-chpt-mat-vs-rte-rte" class="quarto-xref"><span>Section 13.1</span></a>).</p>
<p>We will then discuss an important way to solve the RTE by turning it to the Volume Rendering Equation (VRE) (<a href="#sec-chpt-mat-vs-rte-vre" class="quarto-xref"><span>Section 13.2</span></a>), discuss the discrete form of the VRE that is commonly used in scientific visualization (<a href="#sec-chpt-mat-vs-rte-vis" class="quarto-xref"><span>Section 13.3</span></a>) and, more recently, radiance-field rendering (<a href="#sec-chpt-mat-vs-rte-nr" class="quarto-xref"><span>Section 13.4</span></a>), a modern iteration of image-based rendering (<a href="rendering-lightfield.html#sec-chpt-mat-basics-radiometry-lf-ren" class="quarto-xref"><span>Section 9.2.2</span></a>) that uses discrete VRE to parameterize the image formation process. Finally, we will show a simple phenomenological model that integrates surface scattering with volume scattering (<a href="#sec-chpt-mat-vs-sca-bssrdf" class="quarto-xref"><span>Section 13.5</span></a>).</p>
<section id="sec-chpt-mat-vs-rte-rte" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-rte"><span class="header-section-number">13.1</span> Radiative Transfer Equation</h2>
<p>The basic idea is to set up a differential equation to describe the (rate) of the radiance <em>change</em>. Given an incident radiance <span class="math inline">\(L(p, \os)\)</span>, we are interested in <span class="math inline">\(L(p+\D s \os, \os)\)</span>, the radiance after the ray has gone a small distance <span class="math inline">\(\D s\)</span>. The radiance can be:</p>
<ul>
<li>attenuated by the medium because of absorption;</li>
<li>attenuated by the medium because photons are scattered out into other directions; this is called <strong>out-scattering</strong> in graphics;</li>
<li>augmented by photons that are scattered into the ray direction from all other directions — because of multiple scattering<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>; this is called <em>in-scattering</em> in graphics;</li>
<li>augmented because particles can emit photons.</li>
</ul>
<p>The attenuation (reduction) of the radiance over <span class="math inline">\(\D s\)</span> is:</p>
<p><span id="eq-radiance_sub"><span class="math display">\[
    -L(p, \os) \sigma_t(p, \os) \D s.
\tag{13.1}\]</span></span></p>
<p>The radiance augmentation due to in-scattering is given by:</p>
<p><span id="eq-radiance_add_insca"><span class="math display">\[
    \int^{\Omega = 4\pi} f_p(p, \os, \oi) \sigma_s(p, \os) \D s L(\oi) \doi = \sigma_s(p, \os) \D s \int^{\Omega = 4\pi} L(p, \oi) f_p(p, \os, \oi) \doi.
\tag{13.2}\]</span></span></p>
<!-- %\fixme{different oi will have different optical length, but that can be folded into sigma. the fact that we are integrating over 4pi means we should absolutely consider photons that hit all six faces of the cube. also recall that we considering single scattering, so a scattered photon will not go through other scatterings in that volume/entire medium.} -->
<p>The way to interpret <a href="#eq-radiance_add" class="quarto-xref">Equation&nbsp;<span>13.5</span></a> is the following. <span class="math inline">\(L(p, \oi)\)</span> is the incident radiance from a direction <span class="math inline">\(\oi\)</span>, <span class="math inline">\(L(p, \oi) \doi\)</span> is the irradiance received from <span class="math inline">\(\doi\)</span>, of which <span class="math inline">\(\sigma_s(p, \oi)\D s L(p, \os) \doi\)</span> is the irradiance scattered in all directions after traveling a distance <span class="math inline">\(\D s\)</span>. That portion of the scattered irradiance is multiplied by <span class="math inline">\(f_p(\os, \oi)\)</span> to give us the radiance toward <span class="math inline">\(\os\)</span> (see <a href="rendering-sss.html#eq-phase_func_def2" class="quarto-xref">Equation&nbsp;<span>12.19</span></a>). We then integrate over the entire sphere, accounting for the fact that lights can come from anywhere over the space, to obtain the total augmented radiance toward <span class="math inline">\(\os\)</span>.</p>
<p>If we consider emission, the total radiance augmentation is:</p>
<p><span id="eq-radiance_add_total"><span class="math display">\[
    \sigma_a(p, \os) \D s L_e(p, \os) + \sigma_s(p, \os) \D s \int^{\Omega = 4\pi} L(p, \oi) f_p(p, \os, \oi) \doi,
\tag{13.3}\]</span></span></p>
<p>where <span class="math inline">\(L_e(p, \os)\)</span> is the emitted radiance at <span class="math inline">\(p\)</span> toward <span class="math inline">\(\os\)</span>, so the first term represents the total emission over <span class="math inline">\(\D s\)</span>. If we let:</p>
<p><span id="eq-source_term_em"><span class="math display">\[
    L_s(p, \os) = \sigma_a(p, \os) L_e(p, \os) + \sigma_s(p, \os) \int^{\Omega = 4\pi} L(p, \oi) f_p(p, \os, \oi) \doi,
\tag{13.4}\]</span></span></p>
<p>the total augmentation can be simplified to:</p>
<p><span id="eq-radiance_add"><span class="math display">\[
    L_s(p, \os) \D s,
\tag{13.5}\]</span></span></p>
<p>where the <span class="math inline">\(L_s\)</span> term is sometimes called the <strong>source term</strong> or <strong>source function</strong> in computer graphics, because it is the source of power at <span class="math inline">\(p\)</span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<p>Combining <a href="#eq-radiance_sub" class="quarto-xref">Equation&nbsp;<span>13.1</span></a> and <a href="#eq-radiance_add" class="quarto-xref">Equation&nbsp;<span>13.5</span></a>, the net radiance change is<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>:</p>
<p><span id="eq-rte_1"><span class="math display">\[
\begin{aligned}
    \D L(p, \os) &amp;= L(p + \D s \os, \os) - L(p, \os) \\
    &amp;= -L(p, \os) \sigma_t(p, \os) \D s + L_s(p, \os) \D s.
\end{aligned}
\tag{13.6}\]</span></span></p>
<p>As <span class="math inline">\(\D s\)</span> approaches 0, we get (assuming <span class="math inline">\(\os\)</span> is a unit vector as in <a href="rendering-sss.html#eq-abs_cont" class="quarto-xref">Equation&nbsp;<span>12.13</span></a> and <a href="rendering-sss.html#eq-scat_cont" class="quarto-xref">Equation&nbsp;<span>12.14</span></a>):</p>
<p><span id="eq-rte_2"><span class="math display">\[
\begin{aligned}
    \os \cdot \nabla_p L(p, \os) &amp;= \frac{\d L(p, \os)}{\d s} = \lim_{\D s \rightarrow 0} \frac{L(p + \D s \os, \os) - L(p, \os)}{\D s} \nonumber \\
    &amp;= -\sigma_t(p, \os) L(p, \os) + L_s(p, \os),
\end{aligned}
\tag{13.7}\]</span></span></p>
<p>where <span class="math inline">\(\nabla_p\)</span> denotes the gradient of <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(p\)</span>, and <span class="math inline">\(\os \cdot \nabla_p\)</span> denotes the directional derivative, which is used because technically <span class="math inline">\(p\)</span> and <span class="math inline">\(\os\)</span> are both defined in a three-dimensional space, so what we are really calculating is the rate of radiance change at <span class="math inline">\(p\)</span> along <span class="math inline">\(\os\)</span>.</p>
<p><a href="#eq-rte_2" class="quarto-xref">Equation&nbsp;<span>13.7</span></a> is the RTE, which is an integro-differential equation, because it is a differential equation with an integral embedded. The RTE has an intuitive interpretation: if we think of radiance as the power of a ray, as a ray propagates, its power is attenuated by the medium but also augmented by “stray photons” from other rays. The latter is given by <span class="math inline">\(L_s(p, \os)\)</span>, which can be thought of as the augmentation of the radiance per unit length.</p>
<p>The RTE describes the rate of change of an arbitrary radiance <span class="math inline">\(L(p, \os)\)</span>. But our ultimate goal is to calculate the radiance itself? Generally the RTE has no analytical solution. There are two strategies to solve it. First, we can derive analytical solutions under certain certain assumptions and simplifications.</p>
<ul>
<li><p>For instance, the integral in <a href="#eq-rte_2" class="quarto-xref">Equation&nbsp;<span>13.7</span></a> can be approximated by a summation along <span class="math inline">\(N\)</span> directions; then we can turn <a href="#eq-rte_2" class="quarto-xref">Equation&nbsp;<span>13.7</span></a> into a system of <span class="math inline">\(N\)</span> differential equations to be solved. This is sometimes called the <strong>N-flux theory</strong>. <!-- We will omit a formal treatment but refer you to @bohren2006fundamentals[chap. 6.1], @volz2001industrial[chap. 3.1.2], and @klein2010industrial[chap. 5.5] for details. --> You might have heard of the famous Kubelka-Munk model <span class="citation" data-cites="kubelka1931beitrag kubelka1931article kubelka1948new">(<a href="references.html#ref-kubelka1931beitrag" role="doc-biblioref">Kubelka and Munk 1931b</a>, <a href="references.html#ref-kubelka1931article" role="doc-biblioref">1931a</a>; <a href="references.html#ref-kubelka1948new" role="doc-biblioref">Kubelka 1948</a>)</span> widely used in modeling the color of pigment mixture; it is essentially a special case of the N-flux theory where <span class="math inline">\(N=2\)</span>, which we will discuss in <a href="rendering-nflux.html#sec-chpt-mat-vs-km" class="quarto-xref"><span>Section 14.1</span></a>.</p></li>
<li><p>Another assumption people make is to assume that volume scattering is isotropic and can be approximated as a <em>diffusion</em> process. This is called the <strong>diffusion approximation</strong> <span class="citation" data-cites="ishimaru1977theory ishimaru1978wave">(<a href="references.html#ref-ishimaru1977theory" role="doc-biblioref">Ishimaru 1977</a>; <a href="references.html#ref-ishimaru1978wave" role="doc-biblioref">Ishimaru et al. 1978</a>)</span>, which is widely used in both scientific modeling <span class="citation" data-cites="farrell1992diffusion eason1978theory schweiger1995finite boas2001imaging">(<a href="references.html#ref-farrell1992diffusion" role="doc-biblioref">Farrell, Patterson, and Wilson 1992</a>; <a href="references.html#ref-eason1978theory" role="doc-biblioref">Eason et al. 1978</a>; <a href="references.html#ref-schweiger1995finite" role="doc-biblioref">Schweiger et al. 1995</a>; <a href="references.html#ref-boas2001imaging" role="doc-biblioref">Boas et al. 2001</a>)</span> and in rendering <span class="citation" data-cites="stam1995multiple wann2001practical dong2013material">(<a href="references.html#ref-stam1995multiple" role="doc-biblioref">Stam 1995, chap. 7</a>; <a href="references.html#ref-wann2001practical" role="doc-biblioref">Jensen et al. 2001</a>; <a href="references.html#ref-dong2013material" role="doc-biblioref">Dong et al. 2013</a>)</span>; see <span class="citation" data-cites="bohren2006fundamentals">Bohren and Clothiaux (<a href="references.html#ref-bohren2006fundamentals" role="doc-biblioref">2006, chap. 6.2</a>)</span> for a theoretical treatment.</p></li>
</ul>
<p>The second approach deserves its own section.</p>
</section>
<section id="sec-chpt-mat-vs-rte-vre" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-vre"><span class="header-section-number">13.2</span> Volume Rendering Equation</h2>
<p>The second approach, which is particularly popular in computer graphics, is to first turn the RTE into a purely integral equation and then <em>numerically</em> (rather than analytically) estimate the integral using Monte Carlo integration, very similar to how the rendering equation is dealt with for surface scattering (<a href="rendering-re.html#sec-chpt-mat-ss-re" class="quarto-xref"><span>Section 10.3</span></a>).</p>
<div id="fig-vre" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vre-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/vre.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vre-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.1: (a): Illustration of the continuous VRE (<a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>13.8</span></a>). (b): Illustration of a discrete VRE (<a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>13.9</span></a>), where the integral in the continuous VRE is replaced by a summation between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> at an interval of <span class="math inline">\(\D s\)</span>; <span class="math inline">\(t_i\)</span> is the total transmittance between <span class="math inline">\(p_i\)</span> and <span class="math inline">\(p_{i+1}\)</span>; <span class="math inline">\(L_i\)</span> is a shorthand for <span class="math inline">\(L_s(p_i, \os)\)</span>, the source term of at <span class="math inline">\(p_i\)</span> toward <span class="math inline">\(\os\)</span>.
</figcaption>
</figure>
</div>
<p>The way to think of this is that in order to calculate any given radiance <span class="math inline">\(L(p, \os)\)</span>, we need to integrate all the changes along the direction <span class="math inline">\(\os\)</span> up until <span class="math inline">\(p\)</span>. Where do we start the integration? We can start anywhere. <a href="#fig-vre" class="quarto-xref">Figure&nbsp;<span>13.1</span></a> (a) visualizes the integration process. Let’s say we want to start from a point <span class="math inline">\(p_0\)</span>, whose initial radiance toward <span class="math inline">\(\os\)</span> is <span class="math inline">\(L_0(p_0, \os)\)</span>. Let <span class="math inline">\(p = p_0 + s\os\)</span>, where <span class="math inline">\(\os\)</span> is a unit vector and <span class="math inline">\(s\)</span> is the distance between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>. An arbitrary point <span class="math inline">\(p'\)</span> between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> would then be <span class="math inline">\(p' = p_0 + s' \os\)</span><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<p>Now we need to integrate from <span class="math inline">\(p_0\)</span> to <span class="math inline">\(p\)</span> by running <span class="math inline">\(s'\)</span> from 0 to <span class="math inline">\(s\)</span>. Observe that the RTE is a form of a <em>non-homogeneous</em> linear differential equation, whose solution is firmly established in calculus. Without going through the derivations, its solution is:</p>
<p><span id="eq-vre"><span class="math display">\[
    L(p, \os) = T(p_0 \rightarrow p)L_0(p_0, \os) + \int_{0}^{s} T(p' \rightarrow p) L_s(p', \os)\d s',
\tag{13.8}\]</span></span></p>
<p>where <span class="math inline">\(T(p_0 \rightarrow p)\)</span> is the transmittance between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> along <span class="math inline">\(\os\)</span>, and <span class="math inline">\(T(p' \rightarrow p)\)</span> is the transmittance between <span class="math inline">\(p'\)</span> and <span class="math inline">\(p\)</span> along <span class="math inline">\(\os\)</span>. Recall the definition of transmittance in <a href="rendering-sss.html#eq-transmittance" class="quarto-xref">Equation&nbsp;<span>12.15</span></a>: it is the remaining fraction of the radiance after attenuation by the medium after traveling the distance between two points. In our case here:</p>
<p><span class="math display">\[
\begin{aligned}
    T(p' \rightarrow p) = \frac{L(p+s\os, \os)}{L(p+s'\os, \os)} = e^{-\int_{s'}^s \sigma_t(p+t\omega, \omega) \d t}, \\
    T(p_0 \rightarrow p) = \frac{L(p+s\os, \os)}{L(p, \os)} = e^{-\int_{0}^s \sigma_t(p+t\omega, \omega) \d t},
\end{aligned}
\]</span></p>
<p>The integral equation <a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>13.8</span></a> in the graphics literature is called the <strong>volume rendering equation</strong> (VRE) or the <strong>volumetric light transport equation</strong> — the counterpart of the surface LTE (<a href="rendering-re.html#sec-chpt-mat-ss-re" class="quarto-xref"><span>Section 10.3</span></a>). Looking at the visualization in <a href="#fig-vre" class="quarto-xref">Figure&nbsp;<span>13.1</span></a> (a), the VRE has an intuitive interpretation: the radiance at <span class="math inline">\(p\)</span> along <span class="math inline">\(\os\)</span> is the the contribution of <span class="math inline">\(p_0\)</span> plus and contribution of every single point between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>.</p>
<ul>
<li>The contribution of <span class="math inline">\(p_0\)</span> is given by its initial radiance <span class="math inline">\(L_0\)</span> weakened by the transmittance between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>;</li>
<li>Why would a point <span class="math inline">\(p'\)</span> between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> make any contribution? It is because of the source term (<a href="#eq-source_term_em" class="quarto-xref">Equation&nbsp;<span>13.4</span></a>): <span class="math inline">\(p'\)</span> might emit lights, and some of the in-scattered photons at <span class="math inline">\(p'\)</span> will be scattered toward <span class="math inline">\(\os\)</span>. The contribution of <span class="math inline">\(p'\)</span> is thus given by the source term <span class="math inline">\(L_s\)</span> weakened by the transmittance between <span class="math inline">\(p'\)</span> and <span class="math inline">\(p\)</span>.</li>
</ul>
<p>The form of the VRE might appear to suggest that it is enough to accumulate along only the <em>direct</em> path between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>, which is surprising given that there are infinitely many scattering paths between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> (due to multiple scattering). For instance, it appears that we consider only the outgoing radiance toward <span class="math inline">\(\os\)</span> from <span class="math inline">\(p_0\)</span>, but <span class="math inline">\(p_0\)</span> might have outgoing radiances over other directions, which might eventually contribute to <span class="math inline">\(L(p, \os)\)</span> through multiple scattering. Are we ignoring them?</p>
<p>The answer is that the VRE <em>implicitly</em> accounts for all the potential paths between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> because of the <span class="math inline">\(L_s\)</span> term, which expands to <a href="#eq-source_term_em" class="quarto-xref">Equation&nbsp;<span>13.4</span></a>. That is, every time we accumulate the contribution of a point between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span>, we have to consider the in-scattering from all the directions at that point. Another way to interpret this is to observe that the radiance term <span class="math inline">\(L\)</span> appears on both sides of the equation. Therefore, the VRE must be solved recursively by evaluating it everywhere in space.</p>
<p>Does this remind you of the rendering equation (<a href="rendering-re.html#eq-re" class="quarto-xref">Equation&nbsp;<span>10.18</span></a>)? Indeed, the VRE can be thought of as the volumetric counterpart of the rendering equation. Similarly, we can use Monte Carlo integration to estimate it, just like how the rendering equation is dealt with — with an extra complication: the VRE has two integrals: the outer integral runs from <span class="math inline">\(p_0\)</span> to <span class="math inline">\(p\)</span> and, for any intermediate point <span class="math inline">\(p'\)</span>, there is an inner integral that runs from <span class="math inline">\(p'\)</span> to <span class="math inline">\(p\)</span> to evaluate the transmittance <span class="math inline">\(T(p' \rightarrow p)\)</span>. Therefore, we have to sample both integrands.</p>
<p>Similar to the situation of the rendering equation, sampling recursively would exponentially increase the number of rays to be tracked. Put it another way, since there are infinitely many paths from which a ray gains its energy due to multiple scattering, we have to integrate infinitely many paths. Again, a common solution is path tracing, for which <span class="citation" data-cites="pharr2023physically">Pharr, Jakob, and Humphreys (<a href="references.html#ref-pharr2023physically" role="doc-biblioref">2023, chap. 14</a>)</span> is a great reference.</p>
<p>A simplification that is commonly used is to assume that there is only single scattering directly from the light source. In this way, the <span class="math inline">\(L_s\)</span> term does not have to integrate infinitely many incident rays over the sphere but only a fixed amount of rays emitted from the light source <em>non-recursively</em>. This strategy is sometimes called <strong>local illumination</strong> in volume rendering, as opposed to <strong>global illumination</strong>, where one needs to consider all the possible paths of light transport. The distinction is similar to that in modeling surface scattering (<a href="rendering-re.html#sec-chpt-mat-ss-re" class="quarto-xref"><span>Section 10.3</span></a>).</p>
</section>
<section id="sec-chpt-mat-vs-rte-vis" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-vis"><span class="header-section-number">13.3</span> Discrete VRE and Scientific Volume Visualization</h2>
<p>Sometimes the VRE takes the following discrete form:</p>
<p><span id="eq-vre_1a"><span class="math display">\[
    L = \sum_{i=0}^{N-1}\big(L_i\D s\prod_{j=i+1}^{N-1}t_j\big).
\tag{13.9}\]</span></span></p>
<p><a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>13.9</span></a> is the discrete version of <a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>13.8</span></a>: the former turns the two integrals in the latter (both the outer integral and the inner one carried by <span class="math inline">\(T(\cdot)\)</span>) to discrete summations using the Riemann sum over <span class="math inline">\(N\)</span> discrete points along the ray between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> at an interval of <span class="math inline">\(\D s = \frac{s}{N}\)</span>.</p>
<p>The notations are slightly different; <a href="#fig-vre" class="quarto-xref">Figure&nbsp;<span>13.1</span></a> (b) visualizes how this discrete VRE is expressed with the new notations.</p>
<ul>
<li><span class="math inline">\(L\)</span> is <span class="math inline">\(L(p, \os)\)</span>, the quantity to be calculated;</li>
<li><span class="math inline">\(L_i\)</span> is a shorthand for <span class="math inline">\(L_s(p_i, \os)\)</span>, i.e., the source term (<a href="#eq-source_term_em" class="quarto-xref">Equation&nbsp;<span>13.4</span></a>) for the <span class="math inline">\(i^{th}\)</span> point between <span class="math inline">\(p_0\)</span> and <span class="math inline">\(p\)</span> toward <span class="math inline">\(\os\)</span>; by definition, <span class="math inline">\(p_0\)</span> is the <span class="math inline">\(0^{th}\)</span> point (so <span class="math inline">\(L_0\)</span> is the initial radiance <span class="math inline">\(L_0(p_0, \os)\)</span> in <a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>13.8</span></a>) and <span class="math inline">\(p\)</span> is the <span class="math inline">\(N^{th}\)</span> point;</li>
<li><span class="math inline">\(t_i\)</span> (or more explicitly <span class="math inline">\(t(p_{i} \rightarrow p_{i+1})\)</span>) represents the total transmittance between the <span class="math inline">\(i^{th}\)</span> and the <span class="math inline">\((i+1)^{th}\)</span> point and is given by <span class="math inline">\(e^{-\sigma_t(p_i, \os) \D s}\)</span> (notice the integral in continuous transmittance <a href="rendering-sss.html#eq-transmittance" class="quarto-xref">Equation&nbsp;<span>12.15</span></a> is gone, because we assume the transmittance between two adjacent points is a constant in the Reimann sum);</li>
<li><span class="math inline">\(\alpha_i\)</span> is the <strong>opacity</strong> between the <span class="math inline">\(i^{th}\)</span> and the <span class="math inline">\((i+1)^{th}\)</span> point, which is defined as the residual of the transmittance between the two points: <span class="math inline">\(1-t_i\)</span>.</li>
</ul>
<p>See <span class="citation" data-cites="max1995optical">Max (<a href="references.html#ref-max1995optical" role="doc-biblioref">1995</a>, Sect. 4)</span> or <span class="citation" data-cites="kaufman2003volume">Kaufman and Mueller (<a href="references.html#ref-kaufman2003volume" role="doc-biblioref">2003</a>, Sect. 6.1)</span> for a relatively straightforward derivation of <a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>13.9</span></a>, but hopefully this form of the VRE is equally intuitive to interpret from <a href="#fig-vre" class="quarto-xref">Figure&nbsp;<span>13.1</span></a> (b). It is nothing more than accumulating the contribution of each point<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> along the ray, but now we also need to accumulate the attenuation along the way just because of how opacity is defined by convention (per step), hence the product of a sequence of the opacity residuals.</p>
<p>We can also re-express <a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>13.9</span></a> using opacity rather than transmittance: <span id="eq-vre_1b"><span class="math display">\[
\begin{aligned}
    L &amp;= \sum_{i=0}^{N-1}\big(L_i\D s\prod_{j=i+1}^{N-1}(1-\alpha_j)\big) \\
    &amp;= L_{N-1} \D s + L_{N-2} \D s(1-\alpha_{N-1}) + L_{N-3} \D s(1-\alpha_{N-1})(1-\alpha_{N-2}) +~\cdots~  \\
    &amp;~~~+ L_1\D s\prod_{j=2}^{N-1}(1-\alpha_j)+ L_0\D s\prod_{j=1}^{N-1}(1-\alpha_j).
\end{aligned}
\tag{13.10}\]</span></span></p>
<p>The discrete VRE is usually used in the scientific visualization literature, where people are interested in visualizing data obtained from, e.g., computer tomography (CT) scans or magnetic resonance imaging (MRI). There, it is the relative color that people usually care about, not the physical quantity such as the radiance, so people sometimes lump <span class="math inline">\(L_i\D s\)</span> together as <span class="math inline">\(C_i\)</span> and call it the “color” of the <span class="math inline">\(i^{th}\)</span> point. The VRE is then written as:</p>
<p><span id="eq-vre_2"><span class="math display">\[
    C = \sum_{i=0}^{N-1}\big(C_i\prod_{j=i+1}^{N-1}(1-\alpha_j)\big).
\tag{13.11}\]</span></span></p>
<p>The <span class="math inline">\(C\)</span> terms are defined in a three-dimensional RGB space, and <a href="#eq-vre_2" class="quarto-xref">Equation&nbsp;<span>13.11</span></a> is evaluated for the three channels separately, similar to how <a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>13.9</span></a> and <a href="#eq-vre" class="quarto-xref">Equation&nbsp;<span>13.8</span></a> are meant to be evaluated for each wavelength independently. Since color is a linear projection from the spectral radiance, the so-calculated <span class="math inline">\(C\)</span> (all three channels) is indeed proportional to the true color, although in visualization one usually does not care about the true colors anyway (see <a href="#sec-chpt-mat-vs-rte-vis-vis" class="quarto-xref"><span>Section 13.3.3</span></a>).</p>
<p><a href="#eq-vre_2" class="quarto-xref">Equation&nbsp;<span>13.11</span></a> is also called the <em>back-to-front</em> compositing formula in volume rendering, since it starts from <span class="math inline">\(p_0\)</span>, the farthest point on the ray to <span class="math inline">\(p\)</span>. We can easily turn the order around to start from <span class="math inline">\(p\)</span> and end at <span class="math inline">\(p_0\)</span> in a <em>front-to-back</em> fashion (<span class="math inline">\(C_{N-1}\)</span> now corresponds to <span class="math inline">\(p_0\)</span>):</p>
<p><span id="eq-vre2_front"><span class="math display">\[
    C = \sum_{i=0}^{N-1}\big(C_i\prod_{j=0}^{i-1}t_j\big).
\tag{13.12}\]</span></span></p>
<p>While theoretically equivalent, the latter is better in practice because it allows us to opportunistically terminate the integration early when, for instance, the accumulated opacity is high enough (transmittance is low enough), at which point integrating further makes little numerical contribution to the result.</p>
<section id="another-discrete-form-of-vre" class="level3" data-number="13.3.1">
<h3 data-number="13.3.1" class="anchored" data-anchor-id="another-discrete-form-of-vre"><span class="header-section-number">13.3.1</span> Another Discrete Form of VRE</h3>
<p>A perhaps more common way to express the discrete VRE is to approximate the transmittance <span class="math inline">\(t\)</span> using the first two terms of its Taylor series expansion and further assume that the medium has a low albedo, i.e., <span class="math inline">\(\sigma_t \approx \sigma_a\)</span> and <span class="math inline">\(\sigma_s \approx 0\)</span> (that is, the medium emits and absorbs <em>only</em>); we have:</p>
<p><span class="math display">\[
\begin{aligned}
    &amp; 1 - \alpha_i = t_i = t(p_{i} \rightarrow p_{i+1}) = e^{-\sigma_t(p_i, \os) \D s} = 1 - \sigma_t(p_i, \os) \D s + \frac{(\sigma_t(p_i, \os) \D s)^2}{2} - \cdots \\
    \approx &amp; 1 - \sigma_t(p_i, \os) \D s \\
    \approx &amp; 1 - \sigma_a(p_i, \os) \D s.
\end{aligned}
\]</span></p>
<p>Therefore:</p>
<p><span id="eq-vre_alpha_approx"><span class="math display">\[
\alpha_i \approx \sigma_a(p_i, \os) \D s.
\tag{13.13}\]</span></span></p>
<p>Now, observe that the <span class="math inline">\(L_i\)</span> term in <a href="#eq-vre_1a" class="quarto-xref">Equation&nbsp;<span>13.9</span></a> is the source term in <a href="#eq-source_term_em" class="quarto-xref">Equation&nbsp;<span>13.4</span></a>, which under the low albedo assumption has only the emission term, so:</p>
<p><span id="eq-vre_3b"><span class="math display">\[
\begin{aligned}
    L &amp;= \sum_{i=0}^{N-1}\big(L_i\D s\prod_{j=i+1}^{N-1}(1-\alpha_j)\big) \\
    &amp;=  \sum_{i=0}^{N-1}\big(\sigma_a(p_i, \os) L_e(p_i, \os)\D s\prod_{j=i+1}^{N-1}(1-\alpha_j)\big).
\end{aligned}
\tag{13.14}\]</span></span></p>
<p>Now plug in <a href="#eq-vre_alpha_approx" class="quarto-xref">Equation&nbsp;<span>13.13</span></a>, we have:</p>
<p><span id="eq-vre_3c"><span class="math display">\[
    L =  \sum_{i=0}^{N-1}\big(L_e(p_i, \os)\alpha_i\prod_{j=i+1}^{N-1}(1-\alpha_j)\big).
\tag{13.15}\]</span></span></p>
<p>If we let <span class="math inline">\(C_i = L_e(p_i, \os)\)</span>, the discrete VRE is then expressed as <span class="citation" data-cites="levoy1988display">(<a href="references.html#ref-levoy1988display" role="doc-biblioref">Levoy 1988</a>)</span>:</p>
<p><span id="eq-vre_4"><span class="math display">\[
    C = \sum_{i=0}^{N-1}\big(C_i\alpha_i\prod_{j=i+1}^{N-1}(1-\alpha_j)\big).
\tag{13.16}\]</span></span></p>
<p>This can be interpreted as a form of <strong>alpha blending</strong> <span class="citation" data-cites="smith1995alpha">(<a href="references.html#ref-smith1995alpha" role="doc-biblioref">Smith 1995</a>)</span>, a typical trick in graphics to render transparent materials. It makes sense for our discrete VRE to reduce to alpha blending: our derivation assumes that the volume does not scatter lights, so translucent materials become transparent.</p>
<p>Again, <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>13.16</span></a> is the back-to-front equation, and the front-to-back counterpart looks like:</p>
<p><span id="eq-vre4_front"><span class="math display">\[
    C = \sum_{i=0}^{N-1}\big(C_i\alpha_i\prod_{j=0}^{i-1}t_j\big).
\tag{13.17}\]</span></span></p>
<p>If you compare the two discrete forms in <a href="#eq-vre_2" class="quarto-xref">Equation&nbsp;<span>13.11</span></a> and <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>13.16</span></a>, it would appear that the two are not mutually consistent! Of course we know why: 1) <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>13.16</span></a> applies two further approximations (low albedo and Taylor series expansion) <em>and</em> 2) the two <span class="math inline">\(C\)</span> terms in the two equations refer to different physical quantities (compare <a href="#eq-vre_1b" class="quarto-xref">Equation&nbsp;<span>13.10</span></a> with <a href="#eq-vre_3c" class="quarto-xref">Equation&nbsp;<span>13.15</span></a>).</p>
</section>
<section id="sec-chpt-mat-vs-rte-vis-compare" class="level3" data-number="13.3.2">
<h3 data-number="13.3.2" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-vis-compare"><span class="header-section-number">13.3.2</span> The Second Form is More Flexible</h3>
<p>What is the benefit of this new discrete form, comparing <a href="#eq-vre2_front" class="quarto-xref">Equation&nbsp;<span>13.12</span></a> and <a href="#eq-vre4_front" class="quarto-xref">Equation&nbsp;<span>13.17</span></a>? Both equations can be interpreted as a form of weighted sum, where <span class="math inline">\(C_i\)</span> is weighted by a weight <span class="math inline">\(w_i\)</span>, which is <span class="math inline">\(\prod_{j=0}^{i-1}t_j\)</span> in the first case and <span class="math inline">\(\alpha_i\prod_{j=0}^{i-1}t_j\)</span> in the second case. The most obvious difference is that the weights in the first case are correlated but less so in the second case. The weights are strictly decreasing as <span class="math inline">\(i\)</span> increases in the first case, since <span class="math inline">\(t_i &lt; 1\)</span>.</p>
<p>In the second case, the weights are technically independent. One way to understand this is to observe, in the second case, that <span class="math inline">\(w_0 = \alpha_0\)</span> and <span class="math inline">\(w_{i+1} = w_i \frac{\alpha_{i+1}(1-\alpha_i)}{\alpha_i}\)</span>, so there is generally a unique assignment of the <span class="math inline">\(\alpha\)</span> values for a given weight combination. This “flexibility” will come in handy when we can manually assign (<a href="#sec-chpt-mat-vs-rte-vis-vis" class="quarto-xref"><span>Section 13.3.3</span></a>) or learn the weights (<a href="#sec-chpt-mat-vs-rte-nr" class="quarto-xref"><span>Section 13.4</span></a>). Note, however, that if we impose the constraint that <span class="math inline">\(\alpha\in[0, 1]\)</span>, we are effectively constraining the weights too.</p>
</section>
<section id="sec-chpt-mat-vs-rte-vis-vis" class="level3" data-number="13.3.3">
<h3 data-number="13.3.3" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-vis-vis"><span class="header-section-number">13.3.3</span> Visualization is Not (Necessarily) Physically-Based Rendering!</h3>
<p>These discrete VRE forms might give you the false impression that we have avoided the need to integrate infinitely many paths, because, computationally, the evaluation of the VRE comes down to a <em>single-path</em> summation along the ray trajectory. Not really. Calculating the <span class="math inline">\(C_i\)</span> terms in the new formulations still requires recursion if the results are meant to be physically accurate. Of course we can sidestep this by, e.g., applying the local-illumination approximation, as mentioned before, to avoid recursion.</p>
<p>Scientific visualization offers another opportunity: we can simply <em>assign</em> values to the <span class="math inline">\(C\)</span>s and even the <span class="math inline">\(\alpha\)</span>s without regard to physics. The goal of visualization is to discover/highlight interesting objects and structures while de-emphasizing things that are irrelevant. So the actual colors are not as important, which gives us great latitude to determine VRE parameters.</p>
<div id="fig-render_vs_vis" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-render_vs_vis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/render_vs_vis_new.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-render_vs_vis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.2: Comparing volume rendering for visualization and rendering. (a): two examples of scientific visualization (of CT data) using volume rendering; from <span class="citation" data-cites="ctscan">Sjschen (<a href="references.html#ref-ctscan" role="doc-biblioref">2025</a>)</span> and <span class="citation" data-cites="ctscanmouse">MathiasRav (<a href="references.html#ref-ctscanmouse" role="doc-biblioref">2009</a>)</span>. (b): photorealistic volume rendering (a scene from Disney’s Moana, 2016); from <span class="citation" data-cites="eelt_rendering">Gnash (<a href="references.html#ref-eelt_rendering" role="doc-biblioref">2017</a>)</span>.
</figcaption>
</figure>
</div>
<p><a href="#fig-render_vs_vis" class="quarto-xref">Figure&nbsp;<span>13.2</span></a> compares volume-rendered images for scientific visualization (a) and for photorealistic rendering (b). In the case of visualization, the data were from CT scans. In both scans, the outer surface is not transparent but is rendered so just because we are interested in seeing the inner structures that are otherwise occluded. The user makes an executive call to assign a very low transparency to the bones in the knee model 0 but a very high transparency value to the skin and other tissues: this is not physically accurate but a good choice for this particular visualization. Photorealistic rendering, in contrast, has to be physically based and does not usually have this flexibility. See figures in <span class="citation" data-cites="wrenninge2011production">Wrenninge and Bin Zafar (<a href="references.html#ref-wrenninge2011production" role="doc-biblioref">2011</a>)</span> and <span class="citation" data-cites="fong2017production">Fong et al. (<a href="references.html#ref-fong2017production" role="doc-biblioref">2017</a>)</span> for more examples.</p>
<p>There is volume rendering software that would allow the users to make such an assignment depending on what the user wants to highlight and visualize. With certain constraints and heuristics, one can also procedurally assign the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(C\)</span> values from the raw measurement data, usually a density field (see below) acquired from whatever measurement device is used (e.g., CT scanners or MRI machines), using what is called the <em>transfer functions</em> in the literature<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. Making an assignment usually is tied to a <em>classification</em> problem: voxels/points of different classes should have different assignments.</p>
</section>
<section id="density-fields" class="level3" data-number="13.3.4">
<h3 data-number="13.3.4" class="anchored" data-anchor-id="density-fields"><span class="header-section-number">13.3.4</span> Density Fields</h3>
<p>Physically speaking, the medium in RTE/VRE is parameterized by its absorption and scattering coefficients, which are a product of cross section and concentration, which is sometimes also called the density. In physically-based volume rendering, this is indeed how the density is used from the very beginning <span class="citation" data-cites="kajiya1984ray blinn1982light">(<a href="references.html#ref-kajiya1984ray" role="doc-biblioref">Kajiya and Von Herzen 1984</a>; <a href="references.html#ref-blinn1982light" role="doc-biblioref">Blinn 1982</a>)</span>.</p>
<p>In visualization where being physically accurate or photorealistic is unimportant, the notion of an attenuation coefficient<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> loses its physical meaning; it is just a number that controls how the brightness of a point weakens. People simply call the attenuation coefficient the density <span class="citation" data-cites="kaufman2003volume">(<a href="references.html#ref-kaufman2003volume" role="doc-biblioref">Kaufman and Mueller 2003</a>)</span>, presumably because, intuitively, if the particle density is high the color should be dimmer. If you want to be pedantic, you might say that the attenuation coefficient depends not only on the density/concentration but also on the cross section (<a href="rendering-sss.html#eq-abs_2" class="quarto-xref">Equation&nbsp;<span>12.2</span></a>), so how can we do that? Remember in visualization one gets to make an executive call and <em>assign</em> the density value (and thus control <span class="math inline">\(\alpha\)</span>), so it does not really matter if the value itself means the physical quantity of density/concentration. This is apparent in early work that uses volume rendering for scientific visualization <span class="citation" data-cites="sabella1988rendering williams1992volume">(<a href="references.html#ref-sabella1988rendering" role="doc-biblioref">Sabella 1988</a>; <a href="references.html#ref-williams1992volume" role="doc-biblioref">Williams and Max 1992</a>)</span>, where attenuation coefficients are nowhere to be found.</p>
<p>For this reason, the raw volume data obtained from raw measurement device for scientific (medical) visualization are most often called the density field, even though what is being measured is almost certainly not the density field but a field of optical properties that are related to, but certainly do not equate, density. For instance, the raw data you get from a CT scanner is actually a grid of attenuation coefficients <span class="citation" data-cites="bharath2009introductory">(<a href="references.html#ref-bharath2009introductory" role="doc-biblioref">Bharath 2009, chap. 3</a>)</span>.</p>
</section>
</section>
<section id="sec-chpt-mat-vs-rte-nr" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-nr"><span class="header-section-number">13.4</span> Discrete VRE in (Neural) Radiance-Field Rendering</h2>
<p>There is another field where the discrete VRE (especially our second form <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>13.16</span></a>) is becoming incredibly popular: (neural) radiance-field rendering. The two most representative examples are NeRF <span class="citation" data-cites="mildenhall2021nerf">(<a href="references.html#ref-mildenhall2021nerf" role="doc-biblioref">Mildenhall et al. 2021</a>)</span> and 3D Gaussian Splatting (3DGS) <span class="citation" data-cites="kerbl20233d">(<a href="references.html#ref-kerbl20233d" role="doc-biblioref">Kerbl et al. 2023</a>)</span>. They are fundamentally image-based rendering or light-field rendering (<a href="rendering-lightfield.html#sec-chpt-mat-basics-radiometry-lf" class="quarto-xref"><span>Section 9.2</span></a>), where they sample the light field of the scene by taking a set of images at different camera poses and learn to reconstruct the underlying light field, from which they can then re-sample a new camera pose and, thus, render the corresponding image as if it was taken at that new camera pose. This is re-branded in the modern era as “novel view synthesis”.</p>
<p>We will assume that you have read the two papers above so that we can focus on interpreting these radiance-field methods within the fundamental framework of physically-based rendering. Such a re-interpretation would allow us to better understand where these methods come from, how they have introduced new tweaks to physically-based rendering, and what their limitations might be.</p>
<p>The first thing to notice is that NeRF and 3DGS, being essentially a sampling and reconstruction method, use the discrete form of the VRE (mostly <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>13.16</span></a>) as the reconstruction function. This means they assume that the radiance is calculated by a single-path summation along the ray trajectory without the need for path tracing and solving the actual RTE/VRE. The reason they can reduce infinite paths to a single-path evaluation is very similar to that in scientific visualization, except now instead of assigning the “color” values <span class="math inline">\(C\)</span> and opacity values <span class="math inline">\(\alpha\)</span> (or equivalently the density field as discussed above), they train a neural network to directly learn these values.</p>
<section id="sec-chpt-mat-vs-rte-nr-why" class="level3" data-number="13.4.1">
<h3 data-number="13.4.1" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-nr-why"><span class="header-section-number">13.4.1</span> VRE for Surface Rendering?</h3>
<p>It is interesting to observe that both NeRF and 3DGS (and the vast majority of their later developments) use the discrete VRE form in <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>13.16</span></a> as their forward model and can evidently do a very good job at rendering opaque surfaces. Is this surprising? Isn’t <a href="#eq-vre_4" class="quarto-xref">Equation&nbsp;<span>13.16</span></a> designed to render transparent materials/volumes (alpha blending)?</p>
<p>For opaque surfaces, the “ground truth” is the surface rendering equation (<a href="rendering-re.html#sec-chpt-mat-ss-re" class="quarto-xref"><span>Section 10.3</span></a>), which can be seen as a form of weighted sum, where the BRDF <span class="math inline">\(f_r(p, \os, \oi)\)</span> weighs the incident light irradiance <span class="math inline">\(L(p, \oi) \cos\theta_i \text{d}\oi\)</span>. In theory, the weights are independent of each other: the value of <span class="math inline">\(f_r(p, \os, \oi)\)</span> at different <span class="math inline">\(\oi\)</span> can technically be completely uncorrelated. But in reality they are most likely somewhat correlated for real materials: the appearance of a material does not change dramatically when the incident light direction changes slightly. For volumes/translucent materials, the “ground truth” is the VRE, which you could also say is a weighted sum, although the weights are constrained if the <span class="math inline">\(\alpha\)</span> values are constrained (e.g., between 0 and 1), which is the case in NeRF and 3DGS training (<a href="#sec-chpt-mat-vs-rte-vis-compare" class="quarto-xref"><span>Section 13.3.2</span></a>).</p>
<p>So effectively, when rendering opaque surfaces, we are using a form of (theoretically) constrained weighted sum to approximate another (practically) constrained weighted sum, and we hope that we can learn the approximation from a large amount of offline samples. The learned parameters (color and opacity of each point) should not be interpreted literally in the physical sense. One advantage of this parameterization is that it <em>could</em> be used to render volumes or translucent materials if needed, where the ground truth <em>is</em> the VRE, in which case the learned parameters might be more amenable to physical interpretations.</p>
</section>
<section id="volume-graphics-vs.-point-based-graphics" class="level3" data-number="13.4.2">
<h3 data-number="13.4.2" class="anchored" data-anchor-id="volume-graphics-vs.-point-based-graphics"><span class="header-section-number">13.4.2</span> Volume Graphics vs.&nbsp;Point-Based Graphics</h3>
<p>Related to volume graphics, there is also a subtly different branch of graphics called <strong>point-based graphics</strong> (PBG) <span class="citation" data-cites="levoy1985use gross2011point">(<a href="references.html#ref-levoy1985use" role="doc-biblioref">Levoy and Whitted 1985</a>; <a href="references.html#ref-gross2011point" role="doc-biblioref">Gross and Pfister 2011</a>)</span>. The boundary is somewhat blurred, but given the way the two terms are usually used, we can observe a few similarities and distinctions. Both volume graphics and PBG use discrete points as the rendering primitives (as opposed to continuous surfaces such as a mesh), although the input points in volume graphics are usually placed on uniform grids <span class="citation" data-cites="engel2004real">(<a href="references.html#ref-engel2004real" role="doc-biblioref">Engel et al. 2006, chap. 1.5.2</a>)</span> whereas points in PBG can be spatially arbitrary.</p>
<p>Traditionally, PBG is almost exclusively used for photorealistic rendering of surfaces. In fact, the points used in PBG are usually acquired as samples on continuous surfaces <span class="citation" data-cites="gross2011point">(<a href="references.html#ref-gross2011point" role="doc-biblioref">Gross and Pfister 2011, chap. 3</a>)</span>. PBG usually uses object-order rendering through splatting, although ray casting is used too, but RTE/VRE is not involved in the rendering process <span class="citation" data-cites="gross2011point">(<a href="references.html#ref-gross2011point" role="doc-biblioref">Gross and Pfister 2011, chap. 6</a>)</span>.</p>
<p>In contrast, the use of volume graphics is much broader. Volume rendering can be used for photorealistic rendering of participating media and translucent surfaces (by solving the RTE/VRE), or it can be used for non-photorealistic data visualization (by evaluating the single-path, discrete VRE), at which point whether the object to be rendered is called a participating medium, a translucent surface, or anything else is irrelevant, because visualization does not care much about being physically accurate.</p>
<p>3DGS is a somewhat interesting case. It is largely a form of PBG because the rendering primitives are unaligned surface samples, and its splatting technique (which we will discuss shortly) resembles that developed in the PBG literature <span class="citation" data-cites="gross2011point">(<a href="references.html#ref-gross2011point" role="doc-biblioref">Gross and Pfister 2011, chap. 6.1</a>)</span>. However, 3DGS does use the discrete VRE as the forward model. Again, as discussed just above, VRE is just a way for 3DGS to parameterize its forward mode, so the comparison with traditional volume graphics and PBG should not be taken literally.</p>
</section>
<section id="sec-chpt-mat-vs-rte-nr-splatting" class="level3" data-number="13.4.3">
<h3 data-number="13.4.3" class="anchored" data-anchor-id="sec-chpt-mat-vs-rte-nr-splatting"><span class="header-section-number">13.4.3</span> Splatting is Signal Filtering</h3>
<p>Splatting, initially proposed by <span class="citation" data-cites="westover1990footprint">Westover (<a href="references.html#ref-westover1990footprint" role="doc-biblioref">1990</a>)</span> for visualizing volume data, is a common rendering technique used in PBG and 3DGS-family models. We discuss what splatting is, why it works, and how it is used in NeRF and 3DGS. We start by asking: how can we render continuous surfaces from discrete points? If we directly project the points to the sensor plane, we obviously will get holes, as shown in <a href="#fig-splatting" class="quarto-xref">Figure&nbsp;<span>13.3</span></a> (a). This is, of course, not an issue if the rendering primitives are meshes (or procedurally-generated surfaces).</p>
<div id="fig-splatting" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-splatting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/splatting_new.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-splatting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.3: (a): directly projecting discrete points to the image plane would create holes in the rendered image. (b): in splatting, each point is associated with a splat or a footprint function, which can distribute the color of the point to a spatial region on the image plane. (c): splatting essentially allows signal interpolation, which amounts to first reconstructing the underlying signal from the samples (with potential anti-aliasing filtering) followed by re-sampling at new, desired positions.
</figcaption>
</figure>
</div>
<p>The key is to realize that “meshless” does not mean surfaceless: the fact that we do not have a mesh as the rendering primitives does not mean the surface does not exist. Recall that the points used by PBG are actually samples on the surface. To render an image pixel is essentially to estimate the color of a surface point that projects to the pixel (ignoring supersampling for now). From a signal processing perspective, this is a classic problem of signal filtering: reconstruction and resampling.</p>
<p>That is, ideally what we need to do is to reconstruct the underlying signal, i.e., the color distribution of the continuous surface<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> (combined with an anti-aliasing pre-filter<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>) and then resample the reconstructed/filtered signal at positions corresponding to pixels in an image. This is shown in <a href="#fig-splatting" class="quarto-xref">Figure&nbsp;<span>13.3</span></a> (c). %This amounts to applying a single composite filter <span class="math inline">\(F\)</span> at new sampling positions, and The name of the game is to design proper filters. The issue of signal sampling, reconstruction, and resampling is absolutely fundamental to all forms of photorealistic rendering and not limited to PBG; <span class="citation" data-cites="pharr2023physically">Pharr, Jakob, and Humphreys (<a href="references.html#ref-pharr2023physically" role="doc-biblioref">2023, chap. 8</a>)</span> and <span class="citation" data-cites="glassner1995principles">Glassner (<a href="references.html#ref-glassner1995principles" role="doc-biblioref">1995</a>, Unit II)</span> are great references.</p>
<p>Another way to think of this is that the color of a surface point is very likely related to its nearby points that have been sampled as part of the rendering input, so one straightforward thing to do is to interpolate from those samples to calculate colors of new surface points. Signal interpolation is essentially signal filtering/convolution.</p>
<p>There is one catch. In classic signal sampling theories (think of the Nyquist-Shannon sampling theorem), samples are uniformly taken and, as a result, we can use a single reconstruction filter. But in PBG the surface samples are non-uniformly taken, so a single reconstruction filter would not work. Instead, we need a different filter for each point. The filter in the PBG parlance is called a <em>splat</em>, or a <em>footprint function</em>; it is associated with each point (surface sample) and essentially distributes the point color to a local region, enabling signal interpolation. This is shown in <a href="#fig-splatting" class="quarto-xref">Figure&nbsp;<span>13.3</span></a> (b). The exact forms of the footprint functions would determine the exact forms of the signal filters. Gaussian filters are particularly common, and Gaussian splatting is a splatting method that uses Gaussian filters <span class="citation" data-cites="greene1986creating heckbert1989fundamentals zwicker2001surface">(<a href="references.html#ref-greene1986creating" role="doc-biblioref">Greene and Heckbert 1986</a>; <a href="references.html#ref-heckbert1989fundamentals" role="doc-biblioref">Heckbert 1989</a>; <a href="references.html#ref-zwicker2001surface" role="doc-biblioref">Zwicker et al. 2001b</a>)</span>.</p>
<p>From a 3D modeling perspective, instead of having a continuous mesh, the scene is now represented by a set of discrete points, each of which is represented by a 2D Gaussian distribution, which is called a surface element or a surfel <span class="citation" data-cites="pfister2000surfels">(<a href="references.html#ref-pfister2000surfels" role="doc-biblioref">Pfister et al. 2000</a>)</span>. Each surfel is then projected to the screen space to generate a splat as the corresponding reconstruction kernel of that surface point; the reconstruction kernel, after projection, is another Gaussian filter (which can be cascaded with an anti-aliasing pre-filter). The color of each screen space point is then calculated by summing over all the splats (each of which is, of course, scaled by the color of the sample), essentially taking a weighted sum of the colors of the neighboring surface samples (see <span class="citation" data-cites="zwicker2001surface">Zwicker et al. (<a href="references.html#ref-zwicker2001surface" role="doc-biblioref">2001b, fig. 3</a>)</span> for a visualization) or, in signal processing parlance, resampling the reconstructed signal with the reconstruction kernels.</p>
<p>This rendering process is traditionally called surface splatting <span class="citation" data-cites="zwicker2001surface">(<a href="references.html#ref-zwicker2001surface" role="doc-biblioref">Zwicker et al. 2001b</a>)</span>. <span class="citation" data-cites="yifan2019differentiable">Yifan et al. (<a href="references.html#ref-yifan2019differentiable" role="doc-biblioref">2019</a>)</span> is an early attempt to learn the surfels through a differential surface splatting process. Surface splatting is a reasonable rendering model in PBG: the “ground truth” in rendering surfaces is the rendering equation, which can also be interpreted as a weighted sum.</p>
<p>One can also apply the same splatting idea to volume rendering. In this case, each point in the scene is represented by a 3D Gaussian distribution, which is projected to a 2D splat in the screen space. The color of a pixel is then calculated through, critically, alpha blending the corresponding splats, not weighted sum. This is called volume splatting <span class="citation" data-cites="zwicker2001ewa">(<a href="references.html#ref-zwicker2001ewa" role="doc-biblioref">Zwicker et al. 2001a</a>)</span>. 3DGS can be seen as a differential variant of traditional volume splatting, even though it is also very effective in rendering opaque surfaces (and we have discussed the reason on <a href="#sec-chpt-mat-vs-rte-nr-why" class="quarto-xref"><span>Section 13.4.1</span></a>).</p>
</section>
</section>
<section id="sec-chpt-mat-vs-sca-bssrdf" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="sec-chpt-mat-vs-sca-bssrdf"><span class="header-section-number">13.5</span> Integrating Surface Scattering with Volume Scattering</h2>
<p>The rendering equation governs the surface scattering or light transport in space, and the RTE/VRE governs the volume/subsurface scattering or light transport in a medium. Both processes can be involved in a real-life scene. For instance, the appearance of a translucent material like a paint or a wax is a combination of both forms of scattering/light transport (<a href="rendering-overview.html#fig-photon_particle_interactions" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>). Another example would be rendering smoke against a wall.</p>
<!-- %https://pbr-book.org/4ed/Light_Transport_II_Volume_Rendering/Volume_Scattering_Integrators -->
<p>Conceptually nothing new needs to be introduced to deal with the two forms of light transport together. Say we have an opaque surface (a wall) located with a volume (smoke) in the scene. If we want to calculate the radiance of a ray leaving a point on the wall, we would evaluate the rendering equation there, and for each incident ray, we might have to evaluate the VRE since that ray might come from the volume. In practice it amounts to extending the path tracing algorithm to account for the fact that a path might go through a volume and bounce off between surface points. See <span class="citation" data-cites="pharr2023physically">Pharr, Jakob, and Humphreys (<a href="references.html#ref-pharr2023physically" role="doc-biblioref">2023, chap. 14.2</a>)</span> and <span class="citation" data-cites="fong2017production">Fong et al. (<a href="references.html#ref-fong2017production" role="doc-biblioref">2017</a>, Sect. 3)</span> for detailed discussions.</p>
<p>Another approach, which is perhaps more common when dealing with translucent materials (whose appearance, of course, depends on both the surface and subsurface scattering), is through a phenomenological model based on the notion of Bidirectional Scattering Surface Reflectance Distribution Function (<strong>BSSRDF</strong>) <span class="citation" data-cites="nicodemus1977geometrical">(<a href="references.html#ref-nicodemus1977geometrical" role="doc-biblioref">Nicodemus et al. 1977</a>)</span>. The BSSRDF is parameterized as <span class="math inline">\(f_s(p_s, \os, p_i, \oi)\)</span>, describing the infinitesimal outgoing radiance at <span class="math inline">\(p_s\)</span> toward <span class="math inline">\(\os\)</span> given the infinitesimal power incident on <span class="math inline">\(p_i\)</span> from the direction <span class="math inline">\(\oi\)</span>:</p>
<p><span id="eq-bssrdf"><span class="math display">\[
    f_s(p_s, \os, p_i, \oi) = \frac{\text{d}L(p_s, \os)}{\text{d}\Phi(p_i, \oi)}.
\tag{13.18}\]</span></span></p>
<p>BSSRDF can be seen as an extension of BRDF in that it considers the possibility that the radiance of a ray leaving <span class="math inline">\(p_s\)</span> could be influenced by a ray incident on another point <span class="math inline">\(p_i\)</span> due to SSS/volume scattering. Given the BSSRDF, the rendering equation can be generalized to:</p>
<p><span id="eq-re_sss"><span class="math display">\[
    L(p_o, \os) = \int^A\int^{\Omega=2\pi} f_s(p_s, \os, p_i, \oi) L(p_i, \oi) \cos\theta_i \doi \d A,
\tag{13.19}\]</span></span></p>
<p>where <span class="math inline">\(L(p_o, \os)\)</span> is the outgoing radiance at <span class="math inline">\(p_o\)</span> toward <span class="math inline">\(\os\)</span>, <span class="math inline">\(L(p_i, \oi)\)</span> is the incident radiance at <span class="math inline">\(p_i\)</span> from <span class="math inline">\(\oi\)</span>, <span class="math inline">\(A\)</span> in the outer integral is the surface area that is under illumination, and <span class="math inline">\(\Omega=2\pi\)</span> means that each surface point receives illumination from the entire hemisphere.</p>
<p>We can again use path tracing and Monte Carlo integration to evaluate <a href="#eq-re_sss" class="quarto-xref">Equation&nbsp;<span>13.19</span></a> if we know the BSSRDF, which can, again, either be analytically derived given certain constraints and assumptions or measured <span class="citation" data-cites="frisvad2020survey">(<a href="references.html#ref-frisvad2020survey" role="doc-biblioref">Frisvad et al. 2020</a>)</span>. To analytically derive it, one has to consider the fact that the transfer of energy from an incident ray to an outgoing ray is the consequence of a cascade of three factors: two surface scattering (refraction) factors, one entering the material surface <span class="math inline">\(p_i\)</span> from <span class="math inline">\(\oi\)</span> and the other leaving the material surface at <span class="math inline">\(p_i\)</span> toward <span class="math inline">\(p_o\)</span>, and a volume scattering factor that accounts for the subsurface scattering between the incident ray at <span class="math inline">\(p_i\)</span> and the exiting ray at <span class="math inline">\(p_o\)</span> <span class="citation" data-cites="pharr2018physically">(<a href="references.html#ref-pharr2018physically" role="doc-biblioref">Pharr, Jakob, and Humphreys 2018, chap. 11.4</a>)</span>. If all three factors have an analytical form, the final BSSRDF has an analytical form too. This is the approach that, for instance, <span class="citation" data-cites="wann2001practical">Jensen et al. (<a href="references.html#ref-wann2001practical" role="doc-biblioref">2001</a>)</span> takes.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-bharath2009introductory" class="csl-entry" role="listitem">
Bharath, Anil. 2009. <em>Introductory Medical Imaging</em>. Morgan &amp; Claypool.
</div>
<div id="ref-blinn1982light" class="csl-entry" role="listitem">
Blinn, James F. 1982. <span>“Light Reflection Functions for Simulation of Clouds and Dusty Surfaces.”</span> <em>Acm SIGGRAPH Computer Graphics</em> 16 (3): 21–29.
</div>
<div id="ref-boas2001imaging" class="csl-entry" role="listitem">
Boas, David A, Dana H Brooks, Eric L Miller, Charles A DiMarzio, Misha Kilmer, Richard J Gaudette, and Quan Zhang. 2001. <span>“Imaging the Body with Diffuse Optical Tomography.”</span> <em>IEEE Signal Processing Magazine</em> 18 (6): 57–75.
</div>
<div id="ref-bohren2006fundamentals" class="csl-entry" role="listitem">
Bohren, Craig F, and Eugene E Clothiaux. 2006. <em>Fundamentals of Atmospheric Radiation: An Introduction with 400 Problems</em>. John Wiley &amp; Sons.
</div>
<div id="ref-chandrasekhar1960radiative" class="csl-entry" role="listitem">
Chandrasekhar, Subrahmanyan. 1960. <em>Radiative Transfer</em>. Courier Corporation.
</div>
<div id="ref-dong2013material" class="csl-entry" role="listitem">
Dong, Yue, Stephen Lin, Baining Guo, et al. 2013. <em>Material Appearance Modeling: A Data-Coherent Approach</em>. Springer.
</div>
<div id="ref-eason1978theory" class="csl-entry" role="listitem">
Eason, G, AR Veitch, RM Nisbet, and FW Turnbull. 1978. <span>“The Theory of the Back-Scattering of Light by Blood.”</span> <em>Journal of Physics D: Applied Physics</em> 11 (10): 1463.
</div>
<div id="ref-engel2004real" class="csl-entry" role="listitem">
Engel, Klaus, Markus Hadwiger, Joe M Kniss, Christof Rezk-Salama, and Daniel Weiskopf. 2006. <em>Real-Time Volume Graphics</em>. A K Peters, Ltd.
</div>
<div id="ref-farrell1992diffusion" class="csl-entry" role="listitem">
Farrell, Thomas J, Michael S Patterson, and Brian Wilson. 1992. <span>“A Diffusion Theory Model of Spatially Resolved, Steady-State Diffuse Reflectance for the Noninvasive Determination of Tissue Optical Properties in Vivo.”</span> <em>Medical Physics</em> 19 (4): 879–88.
</div>
<div id="ref-fong2017production" class="csl-entry" role="listitem">
Fong, Julian, Magnus Wrenninge, Christopher Kulla, and Ralf Habel. 2017. <span>“Production Volume Rendering: Siggraph 2017 Course.”</span> In <em>ACM SIGGRAPH 2017 Courses</em>, 1–97.
</div>
<div id="ref-frisvad2020survey" class="csl-entry" role="listitem">
Frisvad, Jeppe Revall, Soeren A Jensen, Jonas Skovlund Madsen, António Correia, Li Yang, Søren Kimmer Schou Gregersen, Youri Meuret, and P-E Hansen. 2020. <span>“Survey of Models for Acquiring the Optical Properties of Translucent Materials.”</span> In <em>Computer Graphics Forum</em>, 39:729–55. 2. Wiley Online Library.
</div>
<div id="ref-glassner1995principles" class="csl-entry" role="listitem">
Glassner, Andrew S. 1995. <em>Principles of Digital Image Synthesis</em>. Elsevier.
</div>
<div id="ref-eelt_rendering" class="csl-entry" role="listitem">
Gnash. 2017. <span>“<span class="nocase">Rendering of the Extremely Large Telescope from 2009; CC BY-SA 4.0 license</span>.”</span> <a href="https://commons.wikimedia.org/wiki/File:Latest_Rendering_of_the_E-ELT.jpg" class="uri">https://commons.wikimedia.org/wiki/File:Latest_Rendering_of_the_E-ELT.jpg</a>.
</div>
<div id="ref-greene1986creating" class="csl-entry" role="listitem">
Greene, Ned, and Paul S Heckbert. 1986. <span>“Creating Raster Omnimax Images from Multiple Perspective Views Using the Elliptical Weighted Average Filter.”</span> <em>IEEE Computer Graphics and Applications</em> 6 (6): 21–27.
</div>
<div id="ref-gross2011point" class="csl-entry" role="listitem">
Gross, Markus, and Hanspeter Pfister. 2011. <em>Point-Based Graphics</em>. Elsevier.
</div>
<div id="ref-heckbert1989fundamentals" class="csl-entry" role="listitem">
Heckbert, Paul S. 1989. <span>“Fundamentals of Texture Mapping and Image Warping. Master’s Thesis.”</span> <em>University of California, Berkeley</em>.
</div>
<div id="ref-ishimaru1977theory" class="csl-entry" role="listitem">
Ishimaru, Akira. 1977. <span>“Theory and Application of Wave Propagation and Scattering in Random Media.”</span> <em>Proceedings of the IEEE</em> 65 (7): 1030–61.
</div>
<div id="ref-ishimaru1978wave" class="csl-entry" role="listitem">
Ishimaru, Akira et al. 1978. <em>Wave Propagation and Scattering in Random Media</em>. Vol. 2. Academic press New York.
</div>
<div id="ref-wann2001practical" class="csl-entry" role="listitem">
Jensen, Henrik Wann, Stephen R Marschner, Marc Levoy, and Pat Hanrahan. 2001. <span>“A Practical Model for Subsurface Light Transport.”</span> <em>ACM SIGGRAPH Computer Graphics</em>, 511–18.
</div>
<div id="ref-kajiya1984ray" class="csl-entry" role="listitem">
Kajiya, James T, and Brian P Von Herzen. 1984. <span>“Ray Tracing Volume Densities.”</span> <em>ACM SIGGRAPH Computer Graphics</em> 18 (3): 165–74.
</div>
<div id="ref-kaufman2003volume" class="csl-entry" role="listitem">
Kaufman, Arie, and Klaus Mueller. 2003. <span>“Volume Visualization and Volume Graphics.”</span> <em>Technical Report; Stony Brook University</em>.
</div>
<div id="ref-kerbl20233d" class="csl-entry" role="listitem">
Kerbl, Bernhard, Georgios Kopanas, Thomas Leimkühler, and George Drettakis. 2023. <span>“3d Gaussian Splatting for Real-Time Radiance Field Rendering.”</span> <em>ACM Trans. Graph.</em> 42 (4): 139–31.
</div>
<div id="ref-kubelka1948new" class="csl-entry" role="listitem">
Kubelka, Paul. 1948. <span>“New Contributions to the Optics of Intensely Light-Scattering Materials. Part i.”</span> <em>Josa</em> 38 (5): 448–57.
</div>
<div id="ref-kubelka1931article" class="csl-entry" role="listitem">
Kubelka, Paul, and Franz Munk. 1931a. <span>“An Article on Optics of Paint Layers (Translated by Stephen h. Westin).”</span> <em>Z. Tech. Phys</em> 12 (593-601): 259–74.
</div>
<div id="ref-kubelka1931beitrag" class="csl-entry" role="listitem">
———. 1931b. <span>“Ein Beitrag Zur Optik Der Farbanstriche.”</span> <em>Z. Tech. Phys</em> 12:593–601.
</div>
<div id="ref-levoy1988display" class="csl-entry" role="listitem">
Levoy, Marc. 1988. <span>“Display of Surfaces from Volume Data.”</span> <em>IEEE Computer Graphics and Applications</em> 8 (3): 29–37.
</div>
<div id="ref-levoy1985use" class="csl-entry" role="listitem">
Levoy, Marc, and Turner Whitted. 1985. <span>“The Use of Points as a Display Primitive.”</span> <em>Technical Report; University of North Carolina at Chapel Hill</em>.
</div>
<div id="ref-ctscanmouse" class="csl-entry" role="listitem">
MathiasRav. 2009. <span>“<span class="nocase">Volume rendering of a mouse skull (CT) using shear warp algorithm; CC BY-SA 3.0 license</span>.”</span> <a href="https://en.wikipedia.org/wiki/File:VolRenderShearWarp.gif" class="uri">https://en.wikipedia.org/wiki/File:VolRenderShearWarp.gif</a>.
</div>
<div id="ref-max1995optical" class="csl-entry" role="listitem">
Max, Nelson. 1995. <span>“Optical Models for Direct Volume Rendering.”</span> <em>IEEE Transactions on Visualization and Computer Graphics</em> 1 (2): 99–108.
</div>
<div id="ref-mildenhall2021nerf" class="csl-entry" role="listitem">
Mildenhall, Ben, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. 2021. <span>“Nerf: Representing Scenes as Neural Radiance Fields for View Synthesis.”</span> <em>Communications of the ACM</em> 65 (1): 99–106.
</div>
<div id="ref-nicodemus1977geometrical" class="csl-entry" role="listitem">
Nicodemus, FE, JC Richmond, JJ Hsia, IW Ginsberg, and T Limperis. 1977. <em>Geometrical Considerations and Nomenclature for Reflectance</em>. Vol. 160. US Department of Commerce, National Bureau of Standards Washington, DC, USA.
</div>
<div id="ref-pfister2000surfels" class="csl-entry" role="listitem">
Pfister, Hanspeter, Matthias Zwicker, Jeroen Van Baar, and Markus Gross. 2000. <span>“Surfels: Surface Elements as Rendering Primitives.”</span> In <em>Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques</em>, 335–42.
</div>
<div id="ref-pharr2018physically" class="csl-entry" role="listitem">
Pharr, Matt, Wenzel Jakob, and Greg Humphreys. 2018. <em>Physically Based Rendering: From Theory to Implementation</em>. 3rd ed. MIT Press.
</div>
<div id="ref-pharr2023physically" class="csl-entry" role="listitem">
———. 2023. <em>Physically Based Rendering: From Theory to Implementation</em>. 4th ed. MIT Press.
</div>
<div id="ref-sabella1988rendering" class="csl-entry" role="listitem">
Sabella, Paolo. 1988. <span>“A Rendering Algorithm for Visualizing 3D Scalar Fields.”</span> <em>ACM SIGGRAPH Computer Graphics</em> 22 (4): 51–58.
</div>
<div id="ref-schweiger1995finite" class="csl-entry" role="listitem">
Schweiger, Martin, SR Arridge, M Hiraoka, and DT Delpy. 1995. <span>“The Finite Element Method for the Propagation of Light in Scattering Media: Boundary and Source Conditions.”</span> <em>Medical Physics</em> 22 (11): 1779–92.
</div>
<div id="ref-ctscan" class="csl-entry" role="listitem">
Sjschen. 2025. <span>“<span class="nocase">Volume rendered CT scan of a forearm with different color schemes for muscle, fat, bone, and blood; released into the public domain by the copyright holder</span>.”</span> <a href="https://commons.wikimedia.org/wiki/File:CTWristImage.png" class="uri">https://commons.wikimedia.org/wiki/File:CTWristImage.png</a>.
</div>
<div id="ref-smith1995alpha" class="csl-entry" role="listitem">
Smith, Alvy Ray. 1995. <span>“Alpha and the History of Digital Compositing.”</span> Citeseer.
</div>
<div id="ref-stam1995multiple" class="csl-entry" role="listitem">
Stam, Jos. 1995. <span>“Multiple Scattering as a Diffusion Process.”</span> In <em>Rendering Techniques’ 95: Proceedings of the Eurographics Workshop in Dublin, Ireland, June 12–14, 1995 6</em>, 41–50. Springer.
</div>
<div id="ref-westover1990footprint" class="csl-entry" role="listitem">
Westover, Lee. 1990. <span>“Footprint Evaluation for Volume Rendering.”</span> In <em>Proceedings of the 17th Annual Conference on Computer Graphics and Interactive Techniques</em>, 367–76.
</div>
<div id="ref-williams1992volume" class="csl-entry" role="listitem">
Williams, Peter L, and Nelson Max. 1992. <span>“A Volume Density Optical Model.”</span> In <em>Proceedings of the 1992 Workshop on Volume Visualization</em>, 61–68.
</div>
<div id="ref-wrenninge2011production" class="csl-entry" role="listitem">
Wrenninge, Magnus, and Nafees Bin Zafar. 2011. <span>“Production Volume Rendering: Siggraph 2011 Course.”</span> In <em>ACM SIGGRAPH 2011 Courses</em>, 1–71.
</div>
<div id="ref-yifan2019differentiable" class="csl-entry" role="listitem">
Yifan, Wang, Felice Serena, Shihao Wu, Cengiz Öztireli, and Olga Sorkine-Hornung. 2019. <span>“Differentiable Surface Splatting for Point-Based Geometry Processing.”</span> <em>ACM Transactions On Graphics (TOG)</em> 38 (6): 1–14.
</div>
<div id="ref-zwicker2001ewa" class="csl-entry" role="listitem">
Zwicker, Matthias, Hanspeter Pfister, Jeroen Van Baar, and Markus Gross. 2001a. <span>“EWA Volume Splatting.”</span> In <em>Proceedings Visualization, 2001. VIS’01.</em>, 29–538. IEEE.
</div>
<div id="ref-zwicker2001surface" class="csl-entry" role="listitem">
———. 2001b. <span>“Surface Splatting.”</span> In <em>Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques</em>, 371–78.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Subrahmanyan Chandrasekhar won the Nobel Prize in physics in 1983 (not for the RTE).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Technically, even single scattering can lead to augmentation if there is illumination coming from anywhere outside the ray direction.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Some definitions do not include emission in the source term, while in other definitions the source term is what is defined here divided by <span class="math inline">\(\sigma_t\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>A subtlety you might have noticed is that not all the out-scattering of <span class="math inline">\(L(p, \os)\)</span> attenuates the radiance; some of the scattering could be toward <span class="math inline">\(\os\)</span> so should augment the radiance. This is not a concern since our augmentation term <a href="#eq-radiance_add" class="quarto-xref">Equation&nbsp;<span>13.5</span></a> integrates over the entire sphere, so it considers <span class="math inline">\(L(p, \os)\)</span> again as part of in-scattering and accounts for the forward-scattered portion of <span class="math inline">\(L(p, \os)\)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>There are two alternative parameterizations, both of which are common in graphics literature. The first <span class="citation" data-cites="pharr2023physically">(<a href="references.html#ref-pharr2023physically" role="doc-biblioref">Pharr, Jakob, and Humphreys 2023</a>)</span> is to express <span class="math inline">\(p_0 = p + s\os\)</span> (<span class="math inline">\(s\)</span> being positive), but then the initial radiance would have to be expressed as <span class="math inline">\(L(p_0, -\os)\)</span>, since <span class="math inline">\(\os\)</span> now points from <span class="math inline">\(p\)</span> to <span class="math inline">\(p_0\)</span>. The other is to express <span class="math inline">\(p_0 = p - s\os\)</span> (<span class="math inline">\(s\)</span> again being positive) <span class="citation" data-cites="fong2017production">(<a href="references.html#ref-fong2017production" role="doc-biblioref">Fong et al. 2017</a>)</span>; this avoids the need to switch directions but uses a negative sign. It is a matter of taste which one to use, but be alert to the different conventions.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>technically it is the contribution of each small segment between two discrete points because of the Reimann sum.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Some (color) transfer functions could have physical underpinnings, such as applying a single-scattering shading algorithms (i.e., local illumination); see, e.g., <span class="citation" data-cites="levoy1988display">Levoy (<a href="references.html#ref-levoy1988display" role="doc-biblioref">1988</a>, Sect. 3)</span> or <span class="citation" data-cites="max1995optical">Max (<a href="references.html#ref-max1995optical" role="doc-biblioref">1995</a>, Sect. 5)</span>, but the goal there is not to precisely model physics but for better, subjective visualization.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>which is the only coefficient needed and which participates in calculating <span class="math inline">\(\alpha\)</span> (<a href="#eq-vre_2" class="quarto-xref">Equation&nbsp;<span>13.11</span></a>).<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>assuming a diffuse surface so we care to reconstruct the color of each point, not the radiance of each ray.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>The compound filter combining reconstruction and anti-aliasing filters is sometimes also called a resampling filter, because the compound filter is used during resampling to calculate the new sample values.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./rendering-sss.html" class="pagination-link" aria-label="Volume and Subsurface Scattering Processes">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Volume and Subsurface Scattering Processes</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./rendering-nflux.html" class="pagination-link" aria-label="The N-Flux Theory">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">The N-Flux Theory</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>