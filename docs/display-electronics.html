<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>21&nbsp; Backplane and Processing Architecture – Foundations of Visual Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./display-optics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./display.html">Display</a></li><li class="breadcrumb-item"><a href="./display-electronics.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Backplane and Processing Architecture</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Foundations of Visual Computing</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Foundations-of-Visual-Computing.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">An Invitation to Visual Computing</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./hvs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Human Visual System</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">From Light to Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-receptor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Photoreceptors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-color.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Color Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-colorimetry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Colorimetry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-retinalmodel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modeling Retinal Computation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Visual Adaptations and Constancy</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./rendering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rendering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-radiometry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Radiometry and Photometry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-lightfield.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Light Field</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-re.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Rendering Surface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-surface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Modeling Material Surface</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-sss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Volume and Subsurface Scattering Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-rte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Rendering Volume and Subsurface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-nflux.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">The N-Flux Theory</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./imaging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Imaging</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Imaging Optics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-sensor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Image Sensor Architecture</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-noise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-isp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Image Signal Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./display.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Display</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Optical Mechanisms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-electronics.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Backplane and Processing Architecture</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-disp-bp" id="toc-sec-disp-bp" class="nav-link active" data-scroll-target="#sec-disp-bp"><span class="header-section-number">21.1</span> Backplane Architecture</a>
  <ul class="collapse">
  <li><a href="#driving-lcd-vs.-oled" id="toc-driving-lcd-vs.-oled" class="nav-link" data-scroll-target="#driving-lcd-vs.-oled"><span class="header-section-number">21.1.1</span> Driving LCD vs.&nbsp;OLED</a></li>
  <li><a href="#active-matrix-vs.-passive-matrix" id="toc-active-matrix-vs.-passive-matrix" class="nav-link" data-scroll-target="#active-matrix-vs.-passive-matrix"><span class="header-section-number">21.1.2</span> Active Matrix vs.&nbsp;Passive Matrix</a></li>
  </ul></li>
  <li><a href="#sec-disp-sp" id="toc-sec-disp-sp" class="nav-link" data-scroll-target="#sec-disp-sp"><span class="header-section-number">21.2</span> Digital Signal Processing</a>
  <ul class="collapse">
  <li><a href="#sec-disp-sp-func" id="toc-sec-disp-sp-func" class="nav-link" data-scroll-target="#sec-disp-sp-func"><span class="header-section-number">21.2.1</span> EOTF, EETF, OETF, and OOTF</a></li>
  <li><a href="#sec-disp-sp-eetf" id="toc-sec-disp-sp-eetf" class="nav-link" data-scroll-target="#sec-disp-sp-eetf"><span class="header-section-number">21.2.2</span> Ideal EETF</a></li>
  <li><a href="#sec-disp-sp-impl" id="toc-sec-disp-sp-impl" class="nav-link" data-scroll-target="#sec-disp-sp-impl"><span class="header-section-number">21.2.3</span> Practical Considerations</a></li>
  <li><a href="#sec-disp-sp-cm" id="toc-sec-disp-sp-cm" class="nav-link" data-scroll-target="#sec-disp-sp-cm"><span class="header-section-number">21.2.4</span> Color Management</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./display.html">Display</a></li><li class="breadcrumb-item"><a href="./display-electronics.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Backplane and Processing Architecture</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-disp-elec" class="quarto-section-identifier"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Backplane and Processing Architecture</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Now that we understand how displays produce color and control luminance, let’s take a step back and ask: since all we get from an image is array of pixels, how do we actually control the display color and luminance from image pixel values? This requires a combination of display signal processing algorithms that turn digital pixel values to driver signals (<a href="#sec-disp-sp" class="quarto-xref"><span>Section 21.2</span></a>) and a backplane architecture (<a href="#sec-disp-bp" class="quarto-xref"><span>Section 21.1</span></a>) that delivers the driver signals to ultimately control the display pixels.</p>
<section id="sec-disp-bp" class="level2" data-number="21.1">
<h2 data-number="21.1" class="anchored" data-anchor-id="sec-disp-bp"><span class="header-section-number">21.1</span> Backplane Architecture</h2>
<p>The main component of the backplane is the driving circuit, which delivers electrical signals to drive the LEDs/LC cells. The driving circuit differs between LCDs and (O)LED displays, and can use either an active matrix (AM) architecture of a passive matrix (PM) architecture.</p>
<section id="driving-lcd-vs.-oled" class="level3" data-number="21.1.1">
<h3 data-number="21.1.1" class="anchored" data-anchor-id="driving-lcd-vs.-oled"><span class="header-section-number">21.1.1</span> Driving LCD vs.&nbsp;OLED</h3>
<p>As far as driving is concerned, the main difference between an LED and an LC cell is that LED is a current-driven device and an LC cell is a voltage-driven device. An LED emits photons because of the injected current that flows through it. LC cells do not emit photons themselves — the backlight does. The LC cells change their optical properties (the ability to rotate the polarization of incident light) in response to external voltage, and there is very little current that flows through the LC cells.</p>
<p>Therefore, to drive an LC cell, we need to maintain an external voltage. In contrast, to drive an LED, we need to maintain a flow of current, which will cause a voltage potential difference across the LED but that is the by-product of the injected current.</p>
<p><a href="#fig-lcd_oled_pixel" class="quarto-xref">Figure&nbsp;<span>21.1</span></a> compares the driving circuit between an LC cell and an OLED pixel. In the LC case, each pixel has an LC cell, a storage capacitor <span class="math inline">\(C_{storage}\)</span>, and a switching transistor, usually a thin-film transistor (TFT). When <span class="math inline">\(V_{Select}\)</span> is activated, the TFT allows <span class="math inline">\(C_{storage}\)</span> to be charged by <span class="math inline">\(V_{Data}\)</span>. The voltage stored in <span class="math inline">\(C_{storage}\)</span> then drives the LC cell. In PAM, the voltage value is determined by the intended luminance based on the transmittance-vs-voltage curve (<a href="display-optics.html#sec-disp-optics-lum-pam" class="quarto-xref"><span>Section 20.3.1</span></a>). In PWM, the voltage is fixed but duration at which <span class="math inline">\(V_{Select}\)</span> is activated is luminance dependent.</p>
<div id="fig-lcd_oled_pixel" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lcd_oled_pixel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/lcd_oled_pixel.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lcd_oled_pixel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.1: Comparison the driving circuit inside (a) an LCD pixel and (b) an OLED pixel. Both use the active matrix design, where there are in-pixel TFTs and capacitors to store data and control each pixel. Adapted from <span class="citation" data-cites="ma2016active">Ma (<a href="references.html#ref-ma2016active" role="doc-biblioref">2016, fig. 1</a>)</span>.
</figcaption>
</figure>
</div>
<p>The in-pixel driving circuit for an OLED is slightly more complicated because of its current driven nature. As shown in <a href="#fig-lcd_oled_pixel" class="quarto-xref">Figure&nbsp;<span>21.1</span></a> (b), each pixel has two TFTs and a storage capacitor, hence the name 2T1C design. The switching TFT acts similarly to that in the LC case, allowing <span class="math inline">\(C_{storage}\)</span> to be charged. The voltage across <span class="math inline">\(C_{storage}\)</span> is then <span class="math inline">\(V_{DD} - V_{Data}\)</span>.</p>
<p>To deliver a current to the OLED, however, having only the voltage in <span class="math inline">\(C_{storage}\)</span> is not enough; we need another TFT, the driving TFT. The driving TFT (like any transistor) has three terminals: the source terminal is connected to one side of the capacitor and <span class="math inline">\(V_{DD}\)</span>, the gate terminal is connected to the other side of the capacitor, and the drain terminal is connected to the OLED<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. The gate-source voltage of the TFT, <span class="math inline">\(V_{gs}\)</span>, is equivalent to the voltage across <span class="math inline">\(C_{storage}\)</span>. Given <span class="math inline">\(V_{gs}\)</span>, the current that flows through the drain terminal <span class="math inline">\(I_d\)</span>, which is also the current injected to the OLED <span class="math inline">\(I_{OLED}\)</span> (because of Kirchhoff’s first law), is given by <span class="citation" data-cites="ma2016active">(<a href="references.html#ref-ma2016active" role="doc-biblioref">Ma 2016, p. 1829</a>)</span>:</p>
<p><span id="eq-tft_iv"><span class="math display">\[
\begin{aligned}
    I_{OLED} = I_d = k(V_{gs} - V_{th})^2, \\
    V_{gs} = V_{DD} - V_{Data},
\end{aligned}
\tag{21.1}\]</span></span></p>
<p>where <span class="math inline">\(V_{th}\)</span> is the threshold voltage of the TFT and k is a constant that depends on inherent properties of the transistor. <span class="math inline">\(V_{Data}\)</span> is properly set so that the resulting <span class="math inline">\(I_{OLED}\)</span> gives us the desired luminance (according to <a href="display-optics.html#eq-led_lum" class="quarto-xref">Equation&nbsp;<span>20.1</span></a>).</p>
<p>We can see that we do not directly control the voltage across the OLED. As the current <span class="math inline">\(I_d\)</span> flows through the OLED, there is naturally a voltage difference across the OLED (given by <a href="display-optics.html#eq-led_iv" class="quarto-xref">Equation&nbsp;<span>20.2</span></a>), which is also the voltage at the drain terminal (since the other side of the OLED is connected to ground). The only thing we have to make sure of is <span class="math inline">\(V_{ds} \leq V_{gs} - V_{th}\)</span> (where <span class="math inline">\(V_{ds}\)</span> is the voltage across the drain and source terminals) so that the TFT operates in the saturation region where <a href="#eq-tft_iv" class="quarto-xref">Equation&nbsp;<span>21.1</span></a> holds.</p>
<p>Given the driving circuit of individual pixels, it is natural to extend it to drive an array of pixels, shown in <a href="#fig-amoled" class="quarto-xref">Figure&nbsp;<span>21.2</span></a>, which uses OLEDs as an example. The OLED pixels are organized similar to image sensor pixels and memory cells in a memory array. Each time only one row of pixels is activated (through <span class="math inline">\(V_{Select}\)</span>). Each row has a dedicated <span class="math inline">\(V_{Data}\)</span> signal, which delivers the necessary voltage to the corresponding pixel.</p>
<div id="fig-amoled" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-amoled-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/amoled.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-amoled-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.2: An array of active matrix OLED pixels and the driving circuit. Each pixel uses the 2T1C design in <a href="#fig-lcd_oled_pixel" class="quarto-xref">Figure&nbsp;<span>21.1</span></a> (b).
</figcaption>
</figure>
</div>
<p>If a display’s refresh rate is, say, 120 Hz, each row is selected 120 times a second. Each time, a new voltage is effectively programmed into the storage capacitor. Critically, even when a row is not selected, the charges in <span class="math inline">\(C_{storage}\)</span> are still there and can continuously drive the LED. Driving circuit that has in-pixel control and storage uses the so-called “active matrix” addressing scheme. You might have heard of AMOLED, which is essentially OLED displays that use the AM driving circuit.</p>
</section>
<section id="active-matrix-vs.-passive-matrix" class="level3" data-number="21.1.2">
<h3 data-number="21.1.2" class="anchored" data-anchor-id="active-matrix-vs.-passive-matrix"><span class="header-section-number">21.1.2</span> Active Matrix vs.&nbsp;Passive Matrix</h3>
<p>The driving circuit we have seen above uses the active matrix design. In the passive matrix (PM) design, there is no in-pixel TFTs or storage capacitor <span class="citation" data-cites="blankenbach2016direct">(<a href="references.html#ref-blankenbach2016direct" role="doc-biblioref">Blankenbach, Hudak, and Jentsch 2016</a>)</span>. <a href="#fig-pm_vs_am" class="quarto-xref">Figure&nbsp;<span>21.3</span></a> compares the PM and AM design.</p>
<div id="fig-pm_vs_am" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pm_vs_am-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/pm_vs_am.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pm_vs_am-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.3: Comparing the passive matrix (a) and active matrix (b) driving architecture; from <span class="citation" data-cites="ma2016active">(<a href="references.html#ref-ma2016active" role="doc-biblioref">Ma 2016, figs. 4.20, 4.41</a>)</span>. The AM architecture has in-pixel control (TFTs) and storage (capacitor) that are absent in the PM design.
</figcaption>
</figure>
</div>
<p>Like the AM addressing scheme, in PM we still address pixels row by row. For LCDs, once a row is activated, we set the per-column voltage so that we get the proper voltage difference (<span class="math inline">\(V_{row} - V_{col}\)</span>) to drive an LC cell. For OLED displays, we address a row of pixels by connecting the row signal to ground, and the column signal needs to act as a current source so as to deliver a current through the OLED.</p>
<p>Critically, the pixel (whether LCD or OLED) is “off” whenever its row is not selected. Therefore, for the most part of a refresh cycle the pixels are off. As a result, we need to deliver a large voltage or current during the “on” period in order to get a desired luminance level. This increases the power consumption and reduces the device life time.</p>
<!-- Talk about PWM driving scheme. -->
</section>
</section>
<section id="sec-disp-sp" class="level2" data-number="21.2">
<h2 data-number="21.2" class="anchored" data-anchor-id="sec-disp-sp"><span class="header-section-number">21.2</span> Digital Signal Processing</h2>
<p>Ultimately, it is the <span class="math inline">\(V_{Data}\)</span> signals that the display has to set in order to get a desired response on the pixels. How do we go from digital image pixels to <span class="math inline">\(V_{Data}\)</span>?</p>
<section id="sec-disp-sp-func" class="level3" data-number="21.2.1">
<h3 data-number="21.2.1" class="anchored" data-anchor-id="sec-disp-sp-func"><span class="header-section-number">21.2.1</span> EOTF, EETF, OETF, and OOTF</h3>
<p>Assuming AMOLED and using <a href="#eq-tft_iv" class="quarto-xref">Equation&nbsp;<span>21.1</span></a> and and <a href="display-optics.html#eq-led_lum" class="quarto-xref">Equation&nbsp;<span>20.1</span></a>, we know that to achieve a particular optical power <span class="math inline">\(P\)</span>, the following must hold:</p>
<p><span class="math display">\[
    e\frac{P/(h f)}{\eta} = k(V_{DD} - V_{Data} - V_{th})^2,
\]</span></p>
<p>Therefore, the desired <span class="math inline">\(V_{Data}\)</span> is given by<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<p><span class="math display">\[
    V_{Data} = \sqrt{e\frac{P/(h f)}{\eta k}}  - V_{th} + V_{DD}.
\]</span></p>
<p>With a Digital-to-Analog Convertor (DAC), we can convert a digital value to an analog voltage. Using an ideal DAC transfer function, the digital value to be sent to the DAC is then:</p>
<p><span class="math display">\[
\begin{aligned}
    D = \frac{V_{Data} - V_{min}}{\Delta}, \\
    \Delta = \frac{V_{max} - V_{min}}{2^N - 1},
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\([V_{min}, V_{max}]\)</span> is the DAC output range and <span class="math inline">\(N\)</span> is the resolution.</p>
<p>The relationship between the digital value <span class="math inline">\(D\)</span> and the emitted optical power <span class="math inline">\(P\)</span> is usually called the Electro-Optical Transfer Function (<strong>EOTF</strong>). <a href="#fig-eotf" class="quarto-xref">Figure&nbsp;<span>21.4</span></a> shows the EOTFs for four inorganic LEDs. Even from the theoretical analysis we can see that the relationship is non-linear. In practice the EOTF is usually calibrated and stored in a look-up table (LUT) rather than modeled analytically.</p>
<div id="fig-eotf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-eotf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/eotf.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-eotf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.4: An EOTF example from <span class="citation" data-cites="miller2019color">Miller (<a href="references.html#ref-miller2019color" role="doc-biblioref">2019, fig. 7.2</a>)</span> for four inorganic LEDs (R, G, B, and W).
</figcaption>
</figure>
</div>
<p>Can we directly use an image pixel’s digital value for <span class="math inline">\(D\)</span>? Most likely not. For starters, a pixel’s digital value, without gamma, is encoded in a power/luminance-linear space, but EOTF is non-linear. Therefore, we must transform the image pixel value to the actual digital value that can be sent to the display. This transformation can be abstracted as the Electrical-Electrical Transfer Function (<strong>EETF</strong>).</p>
<div id="fig-ootf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ootf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/ootf.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ootf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.5: In an end-to-end workflow, OETF is carried by the imaging system, image processing executes the EETF, and the display performs the EOTF. Together, the mapping in the scene luminnace to the display luminance is the effective OOTF of the system.
</figcaption>
</figure>
</div>
<p><a href="#fig-ootf" class="quarto-xref">Figure&nbsp;<span>21.5</span></a> shows how EOTF and EETF fit in an end-to-end workflow, where we take a picture of the scene and then displays it on a display. The imaging system essentially executes the Optical-Electrical Transfer Function (<strong>OETF</strong>) that turns the optical signal in the scene to image pixel values. The image processing pipeline turns the image pixel values to digital driving values that are sent to the display, carrying out the EETF. The display then turns the drive signal to optical signal through the EOTF. Together, OETF, EETF, and EOTF collectively forms the effective Optical-Optical Transfer Function (<strong>OOTF</strong>) of the system.</p>
<p>In a rendering system, the image pixel values are rendered/simulated rather than captured, but the same principle applies. The rendered pixel values should be proportional to or, ideally, directly encode the absolute luminance information of the rendered scene. When the frame is rendered on the display, there is an underlying OOTF between the intended luminance in the virtual scene and the actual luminance from the display.</p>
<p>Correcting for the non-linear EOTF is part of the EETF, which, however, does more than just that. So what sort of processing is carried by the EETF? In theory, if we know the intended luminance (of each color channel) we can simply invert the EOTF LUT and obtain the digital value that should be sent to the display. So the real question is, from the image pixel values do we know what the intended luminance value is?</p>
<!-- We first need to construct the display's native color space.
This requires us to first offline calibrate the chromaticities of the display primary colors and the white point, and construct a unit color cube where [1, 1, 1] means each channel emits the maximum luminance (e.g., those shown in @fig-eotf) and [0, 0, 0] means each channel emits the minimum luminance, which preferably is 0 but usually is not.

We then need to transform a pixel's color from its encoding space, say sRGB or DCI-P3, to the display native space.
This sounds trivially but has many challenges.
First, let's say we have an image pixel [0.1, 0.2, 0.3] in the linear sRGB space (i.e., without gamma and channel value bounded between 0 and 1).
What does this tell us?
We of course know that the channel ratio, but it tells us nothing about the absolute luminance of each channel.
Effectively we know the relative shape of the sRGB gamut but not its exact size. -->
</section>
<section id="sec-disp-sp-eetf" class="level3" data-number="21.2.2">
<h3 data-number="21.2.2" class="anchored" data-anchor-id="sec-disp-sp-eetf"><span class="header-section-number">21.2.2</span> Ideal EETF</h3>
<p>Let’s first reason about what <em>should</em> happen using physical units and quantities, and then discuss practical issues in implementation. Ideally, when we render an image, the pixel values should encode absolute luminance/radiance information, not just the relative chromaticity. HDR rendering or imaging gives us that, where physical units are tracked.</p>
<p>Given the absolute luminance intended in the image, the goal of any display is to faithfully reproduce the actual luminance range intended in the scene. It would be <em>amazing</em> if a display could do that, but it is hardly possible, both because the peak display luminance might not be large enough to match that of the real world but also because the real world has a much larger dynamic range than that is afforded by the display. The dynamic range of the scene is the ratio between the maximum and minimum luminance in the scene, and the dynamic range of the sensor is the ratio between the maximum and minimum luminance producible by the display. The definitions are concerned with luminance rather than illuminance because we care about the perceived power not the radiant power in the scene.</p>
<p>So the next best question to ask is: how do we map the intended luminance range in the image to the luminance range afforded by the display? This is the problem of <strong>tone mapping</strong> and is effectively the OOTF in <a href="#fig-ootf" class="quarto-xref">Figure&nbsp;<span>21.5</span></a>. Both the OETF of an imaging system and the EOTF of a display participate in the OOTF, and if the product of OETF and EOTF is not the desired OOTF, the residual adjustment needed must be part of the image processing pipeline, i.e., EETF, to reach the desired OOTF.</p>
<p>Tone mapping is the focus of extensive research <span class="citation" data-cites="reinhard2010high mantiuk2015high">(<a href="references.html#ref-reinhard2010high" role="doc-biblioref">Reinhard 2010</a>; <a href="references.html#ref-mantiuk2015high" role="doc-biblioref">Mantiuk et al. 2015</a>)</span>. The key thing is to preserve contrast. When we map a high-dynamic range scene to a low-dynamic range display, we effectively reduce the contrast. Recall that the human visual system has a contrast sensitivity function, which tells us the minimal contrast necessary at each frequency for the pattern to be detectable. So if we are not careful in preserving the contrast we lose details and the display image looks “dull”.</p>
<!-- Let's say we have an image two pixel values [0.1, 0.2, 0.3] and [0.3, 0.5, 0.6], both in linear sRGB space (i.e., without gamma and channel value bounded between 0 and 1).
What do these pixel values tell us?
They tell us 1) the relative values of the three channels in the two pixels and 2) the relative luminance ratio between the two pixels in each channel.
They do not tell us anything about absolute luminance.

There are a few challenges here.
First, the image pixel values are necessarily encoded in a device-independent color space such as sRGB or DCI-P3, whereas the luminance we are talking about is tied to the display's native color space.
Therefore, we must transform colors from the image's encoding space to the display native space. -->
<p>So in the ideal case, we would first perform tone mapping to determine the luminance of each pixel. Tone mapping changes the luminance of a pixel but not its chromaticity. The mapping between the original image pixel value to the desired luminance level is also called the <strong>tone reproduction curve</strong> (TRC) in display parlance. Given the new luminance, we know the exact XYZ value of a pixel (remember Y is the luminance), from which we can convert the tone-mapped pixel to the display native space.</p>
<p>To construct the display native space, we would first offline calibrate the chromaticities of the display primary colors and the white point, and construct a unit color cube where [1, 1, 1] means each channel emits the maximum luminance (e.g., those shown in <a href="#fig-eotf" class="quarto-xref">Figure&nbsp;<span>21.4</span></a>) and [0, 0, 0] means each channel emits the minimum luminance, which preferably is 0 but usually is not. So an image pixel after the transformation might be, say, [0.1, 0.2, 0.8] in the display native space. From a channel value, we can derive its actual luminance (0.1 means 10% of the maximum luminance in the R sub-pixel) and then by inverting the EOTF LUT (<a href="#fig-eotf" class="quarto-xref">Figure&nbsp;<span>21.4</span></a>) we can get the actual digital value that needs to be sent to the display. <!-- Essentially, knowing the absolute luminance of both the display and the image pixels allow us to perform an absolute color space transformation. --></p>
</section>
<section id="sec-disp-sp-impl" class="level3" data-number="21.2.3">
<h3 data-number="21.2.3" class="anchored" data-anchor-id="sec-disp-sp-impl"><span class="header-section-number">21.2.3</span> Practical Considerations</h3>
<p>There are many challenges of implementing this in practice. First, many images do not encode absolute luminance/radiance information. Let’s say we have an image pixel [10, 20, 30] in the sRGB space. What does this tell us? It tells us nothing about the absolute luminance of each channel. Effectively, we know the relative shape of the sRGB gamut but not its exact size. The next best thing is to perhaps take a guess, setting, say, the maximum luminance of each of the three sRGB channels to the maximum luminance of the display.</p>
<p>During the color space transformation, we usually perform an additional transformation so that sRGB white becomes the white point in the display space. This is called <em>chromatic adaptation</em>, which is discussed in <a href="hvs-adaptation.html#sec-chpt-hvs-adaptations-chroma" class="quarto-xref"><span>Section 7.3</span></a>. This is to accommodate the fact that the viewer might be under a different viewing condition than the condition under which the photo was originally edited. The viewing condition could affect the actual appearance of a color, so we must account for this shift in viewing condition through chromatic adaptation.</p>
<p>Second, display might support a color space whose gamut is smaller than that of the image’s encoding space. For instance, the display might support only sRGB while the image is encoded in DCI-P3, so some of the P3 colors might not be accurately reproduced. <!-- When viewing a P3-encoded image on a display whose gamut is smaller, e.g., similar to that of sRGB, the colors might not be accurately reproduced. --> The best thing we can do is to approximate an out-of-gamut color with an in-gamut color to minimize the color error. This is called <strong>gamut mapping</strong>. <span class="citation" data-cites="morovivc2008color">Morovič (<a href="references.html#ref-morovivc2008color" role="doc-biblioref">2008</a>)</span> and <span class="citation" data-cites="glassner1995principles">Glassner (<a href="references.html#ref-glassner1995principles" role="doc-biblioref">1995, chap. 3.6</a>)</span> describe the basic algorithms, with the former being more recent and comprehensive.</p>
<p>The simplest strategy would be to simply clamp out-of-range values, so a color of [12, 200, 300] would become [12, 200, 255]. Clearly, other than being extremely simple to implement, this strategy would introduce large color reproduction errors. International Color Consortium (ICC) has defined four <strong>rendering intents</strong>, each of which corresponds to a gamut mapping algorithm (vaguely worded, and the implementation detail might vary). For instance, the <em>Absolute</em> rendering intent leaves all the in-gamut colors unchanged but maps the out-of-gamut colors to the boundary of the color gamut. The <em>Perceptual</em> rendering intent can be implemented by uniformly projecting all the colors to the white point so that all the colors are in-gamut. You can imagine that while this maintains the relative color appearance between colors (which the Absolute rendering intent fails at), but it would also change in-gamut colors that could have been accurately rendered!</p>
</section>
<section id="sec-disp-sp-cm" class="level3" data-number="21.2.4">
<h3 data-number="21.2.4" class="anchored" data-anchor-id="sec-disp-sp-cm"><span class="header-section-number">21.2.4</span> Color Management</h3>
<!-- An end-to-end workflow might involve multiple output media (e.g., displays, prints), and it is important to correctly translate colors between them to accurately reproduce the color appearance.

Consider a workflow where you edit a photo encoded in the P3 color space, save the photo in a file, and share it with your friend, who will view the image on a computer with in an image viewer software that supports only the sRGB color space.
There are a few issues that need our attention.

First, multiple color spaces are involved here.
The image is initially encoded in the P3 space and then will have to be reinterpreted in the sRGB space.
A color, say, [10, 20, 30] encoded in the P3 color space is not the same color as the sRGB color [10, 20, 30], so we must correctly translate a color encoded in the source color space to the destination color space.
Eventually, the sRGB color values must be transformed to colors in the display's native color space, whose gamut hopefully is no smaller than sRGB.

Second, a potential issue in this transformation is that the P3 color space has a larger gamut than that of sRGB, so there will necessarily be colors in the photon that will never be accurately reproduced on your friend's display --- what do we do with these colors?

Finally, the viewer might be under a different viewing condition than the condition under which the photo was originally edited.
The viewing condition could affect the actual appearance of a color, so we must account for this shift in viewing condition. -->
<p>We can see that to perform EETF, we have to know a lot about the image itself and the display. Taking care of all these is part of <strong>color management</strong>, whose goal is to maintain a consistent color appearance throughout the workflow that might involve wildly different devices. It requires a collaboration between every single piece that touches color in the workflow: the image file must come with a <em>profile</em> that specifies what color space its pixel colors are encoded in and (an estimation of) the viewing condition under which the image was originally edited/viewed, the software that manipulates image content must correctly read and interpret the profile and perform the necessary transformation, potentially through APIs exposed by the Operating System (OS), and the display firmware and drive must communicate with the OS a similar profile of the display itself. <span class="citation" data-cites="giorgianni2009digital">Giorgianni and Madden (<a href="references.html#ref-giorgianni2009digital" role="doc-biblioref">2009</a>)</span> and <span class="citation" data-cites="sharma2018understanding">Sharma (<a href="references.html#ref-sharma2018understanding" role="doc-biblioref">2018</a>)</span> are two excellent references for color management. We will describe the key issues here.</p>
<!-- When opening and viewing an image encoded in, say, sRGB on a display, a few transformations have to happen [@miller2019color, Chap. 7.1].
The display's native color space is most likely not exactly sRGB or any standard color space; we must correctly translate a color encoded in the sRGB space to the display's space.
A color [10, 20, 30] encoded in sRGB is not the same color as [10, 20, 30] in the display's color space.
This transformation is done in two steps. -->
<p>First, the image file ideally has metadata that tells us what color space its pixel colors are encoded in or, better, the transformation matrix from the image’s color space to a device-independent color space, say the CIE XYZ space. The way to describe such information has been standardized by ICC in what is called the <em>ICC profile</em> <span class="citation" data-cites="iccv2">(<a href="references.html#ref-iccv2" role="doc-biblioref">International Color Consortium 2019</a>)</span>. We can embed an ICC profile in common image file formats such as JPEG.</p>
<p>Second, the display itself also has to report its native color space. To do that, modern displays usually come with an ICC profile that describes how to transform from the CIE XYZ space to the display’s native space. Now when the Operating System gets the image file, it would first transform the sRGB colors to the XYZ space using the ICC profile in the image and then transform the colors in the XYZ to the display’s native space using the display profile. You can see that the XYZ space here serves to connect the input color space and the output color space. ICC calls such a space a Profile Connection Space (PCS).</p>
<!-- The transformation from the XYZ space to the display's native space is necessarily linear.
To calculate the transformation matrix, we will first measure the chromaticity values of the display's native primary colors and the white point offline [@balasubramanian2003device].
Then we take the exact the same steps as described in @sec-chpt-hvs-cori-cube-step1: we are essentially creating a color cube for the display ([1, 1, 1] represents the display white point, i.e., when all the sub-pixels emit maximum luminance, etc.). -->
<!-- %``Display profiles are profiles that describe how a computer monitor or projector reproduces colours. Without them applications such as Photoshop would have no idea how the monitor displays colour. If you haven’t calibrated and profiled your monitor then your computer will be using a generic profile that does not reflect how your monitor works. It will be an approximation at best.''
%https://www.permajet.com/blog/what-is-an-icc-profile-why-do-i-need-one/
% miller2019color chap. 7.1 uses a somewhat weird example where he wants to pick 9000K as the adaptation white but the display white point is not 9000K. so after chromatic adaptation the input sRGB white will become [1, 1, 1] in the display native space, i.e., display white point, which, however, is not 9000K. he suggests a compensation method, but in reality the display profile would know its actual white point and supply the correct chromatic adaptation matrix accordingly. -->


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-blankenbach2016direct" class="csl-entry" role="listitem">
Blankenbach, Karlheinz, Andreas Hudak, and Michael Jentsch. 2016. <span>“Direct Drive, Multiplex, and Passive Matrix.”</span> In <em>Handbook of Visual Display Technology</em>, 2nd ed., 621–44. Springer.
</div>
<div id="ref-giorgianni2009digital" class="csl-entry" role="listitem">
Giorgianni, Edward J, and Thomas E Madden. 2009. <em>Digital Color Management: Encoding Solutions</em>. Vol. 13. John Wiley &amp; Sons.
</div>
<div id="ref-glassner1995principles" class="csl-entry" role="listitem">
Glassner, Andrew S. 1995. <em>Principles of Digital Image Synthesis</em>. Elsevier.
</div>
<div id="ref-iccv2" class="csl-entry" role="listitem">
International Color Consortium. 2019. <span>“<span class="nocase">Specification ICC.2:2019 (Profile version 5.0.0 - iccMAX)</span>.”</span> <a href="https://color.org/specification/ICC.2-2019.pdf" class="uri">https://color.org/specification/ICC.2-2019.pdf</a>.
</div>
<div id="ref-ma2016active" class="csl-entry" role="listitem">
Ma, Ruiqing. 2016. <span>“Active Matrix for OLED Displays.”</span> In <em>Handbook of Visual Display Technology</em>, 2nd ed., 1821–41. Springer.
</div>
<div id="ref-mantiuk2015high" class="csl-entry" role="listitem">
Mantiuk, Rafał, Grzegorz Krawczyk, Dorota Zdrojewska, Radosław Mantiuk, Karol Myszkowski, and Hans-Peter Seidel. 2015. <span>“High Dynamic Range Imaging.”</span> In <em>Wiley Encyclopedia of Electrical and Electronics Engineering</em>. Wiley.
</div>
<div id="ref-miller2019color" class="csl-entry" role="listitem">
Miller, Michael E. 2019. <em>Color in Electronic Display Systems</em>. Springer.
</div>
<div id="ref-morovivc2008color" class="csl-entry" role="listitem">
Morovič, Ján. 2008. <em>Color Gamut Mapping</em>. 2nd ed. John Wiley &amp; Sons.
</div>
<div id="ref-reinhard2010high" class="csl-entry" role="listitem">
Reinhard, Erik. 2010. <em>High Dynamic Range Imaging Acquisition, Display, and Image-Based Lighting</em>. 2nd ed. Morgan Kaufmann Publishers.
</div>
<div id="ref-sharma2018understanding" class="csl-entry" role="listitem">
Sharma, Abhay. 2018. <em>Understanding Color Management</em>. John Wiley &amp; Sons.
</div>
<div id="ref-tsujimura2017oled" class="csl-entry" role="listitem">
Tsujimura, Takatoshi. 2017. <em>OLED Display Fundamentals and Applications</em>. 2nd ed. John Wiley &amp; Sons.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Other configurations are possible depending on whether we use an NMOS or a PMOS transistor and whether we use a source-follower circuit or a constant-current circuit <span class="citation" data-cites="tsujimura2017oled">(<a href="references.html#ref-tsujimura2017oled" role="doc-biblioref">Tsujimura 2017</a>, Chpt. 4.4.2)</span>. What we describe here uses PMOS + constant-current circuit.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>given that <span class="math inline">\(V_{gs} \leq V_{th}\)</span> for the TFT to operate in the saturate region.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./display-optics.html" class="pagination-link" aria-label="Optical Mechanisms">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Optical Mechanisms</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="References">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>