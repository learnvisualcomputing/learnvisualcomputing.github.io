<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>20&nbsp; Driving Circuits and Processing Pipeline – Foundations of Visual Computing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./display-optics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./display.html">Display</a></li><li class="breadcrumb-item"><a href="./display-electronics.html"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Driving Circuits and Processing Pipeline</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Foundations of Visual Computing</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Foundations-of-Visual-Computing.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">An Invitation to Visual Computing</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./hvs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Human Visual System</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">From Light to Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-receptor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Photoreceptors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-color.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Color Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-colorimetry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Colorimetry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hvs-adaptation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Visual Adaptations and Constancy</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./rendering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rendering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-radiometry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Radiometry and Photometry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-lightfield.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Light Field</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-re.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Rendering Surface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-surface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Modeling Material Surface</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-sss.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Volume and Subsurface Scattering Processes</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-rte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Rendering Volume and Subsurface Scattering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rendering-nflux.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">The N-Flux Theory</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./imaging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Imaging</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Imaging Optics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-sensor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Image Sensor Architecture</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-noise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./imaging-isp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Image Signal Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./display.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Display</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-optics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Optical Mechanisms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./display-electronics.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Driving Circuits and Processing Pipeline</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-disp-bp" id="toc-sec-disp-bp" class="nav-link active" data-scroll-target="#sec-disp-bp"><span class="header-section-number">20.1</span> Backplane</a>
  <ul class="collapse">
  <li><a href="#lcd-vs.-oled" id="toc-lcd-vs.-oled" class="nav-link" data-scroll-target="#lcd-vs.-oled"><span class="header-section-number">20.1.1</span> LCD vs.&nbsp;OLED</a></li>
  <li><a href="#active-matrix-vs.-passive-matrix" id="toc-active-matrix-vs.-passive-matrix" class="nav-link" data-scroll-target="#active-matrix-vs.-passive-matrix"><span class="header-section-number">20.1.2</span> Active Matrix vs.&nbsp;Passive Matrix</a></li>
  </ul></li>
  <li><a href="#sec-disp-dic" id="toc-sec-disp-dic" class="nav-link" data-scroll-target="#sec-disp-dic"><span class="header-section-number">20.2</span> Driver IC</a></li>
  <li><a href="#sec-disp-tf" id="toc-sec-disp-tf" class="nav-link" data-scroll-target="#sec-disp-tf"><span class="header-section-number">20.3</span> Elelctrical ↔︎ Optical Transfer Functions</a></li>
  <li><a href="#sec-disp-sp" id="toc-sec-disp-sp" class="nav-link" data-scroll-target="#sec-disp-sp"><span class="header-section-number">20.4</span> Display Signal Processing</a>
  <ul class="collapse">
  <li><a href="#sec-disp-sp-tm" id="toc-sec-disp-sp-tm" class="nav-link" data-scroll-target="#sec-disp-sp-tm"><span class="header-section-number">20.4.1</span> Luminance Dynamic Range and Tone Mapping</a></li>
  <li><a href="#sec-disp-sp-eetf" id="toc-sec-disp-sp-eetf" class="nav-link" data-scroll-target="#sec-disp-sp-eetf"><span class="header-section-number">20.4.2</span> Ideal EETF</a></li>
  <li><a href="#sec-disp-sp-impl" id="toc-sec-disp-sp-impl" class="nav-link" data-scroll-target="#sec-disp-sp-impl"><span class="header-section-number">20.4.3</span> Practical Considerations</a></li>
  <li><a href="#sec-disp-sp-cm" id="toc-sec-disp-sp-cm" class="nav-link" data-scroll-target="#sec-disp-sp-cm"><span class="header-section-number">20.4.4</span> Color Management</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./display.html">Display</a></li><li class="breadcrumb-item"><a href="./display-electronics.html"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Driving Circuits and Processing Pipeline</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-disp-elec" class="quarto-section-identifier"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Driving Circuits and Processing Pipeline</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Now that we understand how displays produce color and control luminance, let’s take a step back and ask: since all we get from an image is array of pixels, how do we actually control the display color and luminance from image pixel values? This requires a combination of display signal processing algorithms that turn image pixel values to actual digital values sent to the display and the driving circuits that use the digital values to actually drive the emissive devices.</p>
<p>There are two main components in the driving circuits: 1) the backplane that sits directly at the back of a display panel and that controls the emissive devices (<a href="#sec-disp-bp" class="quarto-xref"><span>Section 20.1</span></a>), and 2) the driver integrated circuit (IC) that delivers the driver signals to the backplane (<a href="#sec-disp-dic" class="quarto-xref"><span>Section 20.2</span></a>). We will then discuss the signal processing pipeline, starting with how it fits in an end-to-end workflow (<a href="#sec-disp-tf" class="quarto-xref"><span>Section 20.3</span></a>), followed by theoretical and practical implementations (<a href="#sec-disp-sp" class="quarto-xref"><span>Section 20.4</span></a>).</p>
<section id="sec-disp-bp" class="level2" data-number="20.1">
<h2 data-number="20.1" class="anchored" data-anchor-id="sec-disp-bp"><span class="header-section-number">20.1</span> Backplane</h2>
<p>Mechanically, a display panel has an emissive layer at the front that contains the optical devices we have seen in the previous chapter and a <em>backplane</em> that sits right behind and delivers electrical signals to the emissive layer. The main component of the backplane is the driving circuit, which delivers electrical signals to drive the LEDs/LC cells. The driving circuit differs between LCDs and (O)LED displays, and can use either an active matrix (AM) architecture of a passive matrix (PM) architecture.</p>
<section id="lcd-vs.-oled" class="level3" data-number="20.1.1">
<h3 data-number="20.1.1" class="anchored" data-anchor-id="lcd-vs.-oled"><span class="header-section-number">20.1.1</span> LCD vs.&nbsp;OLED</h3>
<p>As far as driving is concerned, the main difference between an LED and an LC cell is that LED is a current-driven device and an LC cell is a voltage-driven device. An LED emits photons because of the injected current that flows through it. LC cells do not emit photons themselves — the backlight does. The LC cells change their optical properties (the ability to rotate the polarization of incident light) in response to external voltage, and there is very little current that flows through the LC cells.</p>
<p>Therefore, to drive an LC cell, we need to maintain an external voltage. In contrast, to drive an LED, we need to maintain a flow of current, which will cause a voltage potential difference across the LED but that is the by-product of the injected current.</p>
<p><a href="#fig-lcd_oled_pixel" class="quarto-xref">Figure&nbsp;<span>20.1</span></a> compares the driving circuit between an LC cell and an OLED pixel. In the LC case, each pixel has an LC cell, a storage capacitor <span class="math inline">\(C_{storage}\)</span>, and a switching transistor, usually a thin-film transistor (TFT). When <span class="math inline">\(V_{Select}\)</span> is activated, the TFT allows <span class="math inline">\(C_{storage}\)</span> to be charged by <span class="math inline">\(V_{Data}\)</span>. The voltage stored in <span class="math inline">\(C_{storage}\)</span> then drives the LC cell. In PAM, the voltage value is determined by the intended luminance based on the transmittance-vs-voltage curve (<a href="display-optics.html#sec-disp-optics-lum-pam" class="quarto-xref"><span>Section 19.3.1</span></a>). In PWM, the voltage is fixed but duration at which <span class="math inline">\(V_{Select}\)</span> is activated is luminance dependent.</p>
<div id="fig-lcd_oled_pixel" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lcd_oled_pixel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/lcd_oled_pixel.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lcd_oled_pixel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.1: Comparison the driving circuit inside (a) an LCD pixel and (b) an OLED pixel. Both use the active matrix design, where there are in-pixel TFTs and capacitors to store data and control each pixel. Adapted from <span class="citation" data-cites="ma2016active">Ma (<a href="references.html#ref-ma2016active" role="doc-biblioref">2016, fig. 1</a>)</span>.
</figcaption>
</figure>
</div>
<p>The in-pixel driving circuit for an OLED is slightly more complicated because of its current driven nature. As shown in <a href="#fig-lcd_oled_pixel" class="quarto-xref">Figure&nbsp;<span>20.1</span></a> (b), each pixel has two TFTs and a storage capacitor, hence the name 2T1C design. The switching TFT acts similarly to that in the LC case, allowing <span class="math inline">\(C_{storage}\)</span> to be charged. The voltage across <span class="math inline">\(C_{storage}\)</span> is then <span class="math inline">\(V_{DD} - V_{Data}\)</span>.</p>
<p>To deliver a current to the OLED, however, having only the voltage in <span class="math inline">\(C_{storage}\)</span> is not enough; we need another TFT, the driving TFT. The driving TFT (like any transistor) has three terminals: the source terminal is connected to one side of the capacitor and <span class="math inline">\(V_{DD}\)</span>, the gate terminal is connected to the other side of the capacitor, and the drain terminal is connected to the OLED<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. The gate-source voltage of the TFT, <span class="math inline">\(V_{gs}\)</span>, is equivalent to the voltage across <span class="math inline">\(C_{storage}\)</span>. Given <span class="math inline">\(V_{gs}\)</span>, the current that flows through the drain terminal <span class="math inline">\(I_d\)</span>, which is also the current injected to the OLED <span class="math inline">\(I_{OLED}\)</span> (because of Kirchhoff’s first law), is given by <span class="citation" data-cites="ma2016active">(<a href="references.html#ref-ma2016active" role="doc-biblioref">Ma 2016, p. 1829</a>)</span>:</p>
<p><span id="eq-tft_iv"><span class="math display">\[
\begin{aligned}
    I_{OLED} = I_d = k(V_{gs} - V_{th})^2, \\
    V_{gs} = V_{DD} - V_{Data},
\end{aligned}
\tag{20.1}\]</span></span></p>
<p>where <span class="math inline">\(V_{th}\)</span> is the threshold voltage of the TFT and k is a constant that depends on inherent properties of the transistor. <span class="math inline">\(V_{Data}\)</span> is properly set so that the resulting <span class="math inline">\(I_{OLED}\)</span> gives us the desired luminance (according to <a href="display-optics.html#eq-led_lum" class="quarto-xref">Equation&nbsp;<span>19.1</span></a>).</p>
<p>We can see that we do not directly control the voltage across the OLED. As the current <span class="math inline">\(I_d\)</span> flows through the OLED, there is naturally a voltage difference across the OLED (given by <a href="display-optics.html#eq-led_iv" class="quarto-xref">Equation&nbsp;<span>19.2</span></a>), which is also the voltage at the drain terminal (since the other side of the OLED is connected to ground). The only thing we have to make sure of is <span class="math inline">\(V_{ds} \geq V_{gs} - V_{th}\)</span> (where <span class="math inline">\(V_{ds}\)</span> is the voltage across the drain and source terminals) so that the TFT operates in the saturation region where <a href="#eq-tft_iv" class="quarto-xref">Equation&nbsp;<span>20.1</span></a> holds.</p>
<p>Given the driving circuit of individual pixels, it is natural to extend it to drive an array of pixels, shown in <a href="#fig-amoled" class="quarto-xref">Figure&nbsp;<span>20.2</span></a>, which uses OLEDs as an example. The OLED pixels are organized similar to image sensor pixels and memory cells in a memory array. Each time only one row of pixels is activated (through <span class="math inline">\(V_{Select}\)</span>). Each row has a dedicated <span class="math inline">\(V_{Data}\)</span> signal, which delivers the necessary voltage to the corresponding pixel.</p>
<div id="fig-amoled" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-amoled-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/amoled.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-amoled-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.2: An array of active matrix OLED pixels and the driving circuit. Each pixel uses the 2T1C design in <a href="#fig-lcd_oled_pixel" class="quarto-xref">Figure&nbsp;<span>20.1</span></a> (b).
</figcaption>
</figure>
</div>
<p>If a display’s refresh rate is, say, 120 Hz, each row is selected 120 times a second. Each time, a new voltage is effectively programmed into the storage capacitor. Critically, even when a row is not selected, the charges in <span class="math inline">\(C_{storage}\)</span> are still there and can continuously drive the LED. Driving circuit that has in-pixel control and storage uses the so-called “active matrix” addressing scheme. You might have heard of AMOLED, which is essentially OLED displays that use the AM driving circuit.</p>
</section>
<section id="active-matrix-vs.-passive-matrix" class="level3" data-number="20.1.2">
<h3 data-number="20.1.2" class="anchored" data-anchor-id="active-matrix-vs.-passive-matrix"><span class="header-section-number">20.1.2</span> Active Matrix vs.&nbsp;Passive Matrix</h3>
<p>The driving circuit we have seen above uses the active matrix design. In the passive matrix (PM) design, there is no in-pixel TFTs or storage capacitor <span class="citation" data-cites="blankenbach2016direct">(<a href="references.html#ref-blankenbach2016direct" role="doc-biblioref">Blankenbach, Hudak, and Jentsch 2016</a>)</span>. <a href="#fig-pm_vs_am" class="quarto-xref">Figure&nbsp;<span>20.3</span></a> compares the PM and AM design.</p>
<div id="fig-pm_vs_am" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pm_vs_am-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/pm_vs_am.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pm_vs_am-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.3: Comparing the passive matrix (a) and active matrix (b) driving architecture; from <span class="citation" data-cites="ma2016active">(<a href="references.html#ref-ma2016active" role="doc-biblioref">Ma 2016, figs. 4.20, 4.41</a>)</span>. The AM architecture has in-pixel control (TFTs) and storage (capacitor) that are absent in the PM design.
</figcaption>
</figure>
</div>
<p>Like the AM addressing scheme, in PM we still address pixels row by row. For LCDs, once a row is activated, we set the per-column voltage so that we get the proper voltage difference (<span class="math inline">\(V_{row} - V_{col}\)</span>) to drive an LC cell. For OLED displays, we address a row of pixels by connecting the row signal to ground, and the column signal needs to act as a current source so as to deliver a current through the OLED.</p>
<p>Critically, the pixel (whether LCD or OLED) is “off” whenever its row is not selected. Therefore, for the most part of a refresh cycle the pixels are off. As a result, we need to deliver a large voltage or current during the “on” period in order to get a desired luminance level. This increases the power consumption and reduces the device life time.</p>
<!-- Talk about PWM driving scheme. -->
</section>
</section>
<section id="sec-disp-dic" class="level2" data-number="20.2">
<h2 data-number="20.2" class="anchored" data-anchor-id="sec-disp-dic"><span class="header-section-number">20.2</span> Driver IC</h2>
<p>The backplane itself is more or less just the matrix shown in <a href="#fig-amoled" class="quarto-xref">Figure&nbsp;<span>20.2</span></a>, whose row and column signals (<span class="math inline">\(V_{Select}\)</span> and <span class="math inline">\(V_{Data}\)</span>, or scan and data drivers in <a href="#fig-pm_vs_am" class="quarto-xref">Figure&nbsp;<span>20.3</span></a>) need to be set externally. These driver signals come from an external driver IC. <span class="citation" data-cites="blankenbach2016active">Blankenbach (<a href="references.html#ref-blankenbach2016active" role="doc-biblioref">2016</a>)</span> and <span class="citation" data-cites="cristaldi2009liquid">Cristaldi, Pennisi, and Pulvirenti (<a href="references.html#ref-cristaldi2009liquid" role="doc-biblioref">2009</a>, Chpt. 6)</span> provide general descriptions of LCD driver ICs up until 10 years ago. Today’s driver ICs are more integrated and have more advanced features, but the general functionalities and principles remain.</p>
<div id="fig-display_driver_ic" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-display_driver_ic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/display_driver_ic.svg" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-display_driver_ic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.4: Two driver ICs: (a) Raydium’s RM68090 driving LCDs (<span class="citation" data-cites="rm68090">Raydium (<a href="references.html#ref-rm68090" role="doc-biblioref">2011, p. 13</a>)</span>) and (b) OmniVision’s OD6631 driving AMOLED displays (<span class="citation" data-cites="od6631">OmniVision (<a href="references.html#ref-od6631" role="doc-biblioref">n.d.</a>)</span>).
</figcaption>
</figure>
</div>
<p><a href="#fig-display_driver_ic" class="quarto-xref">Figure&nbsp;<span>20.4</span></a> shows two examples of driver ICs; one is Raydium’s RM68090 meant to drive LCDs and the other is OmniVision’s OD6631 meant to drive AMOLED displays. Perhaps the most important function of a display driver IC is to set the row (gate) and the column (source) driver signals. In the case of RM68090, it interfaces with a display backplane that has 320 rows, each of which has 720 columns<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Therefore, RM68090 has 320 gate driver signals (<code>G[320:1]</code>) and 720 source driver signals (<code>S[720:1]</code>). Only one gate driver signal is ON at a time, since only one row is selected at a time, so the gate driver signals effectively are a 320-stage shifter register. Assuming the display refreshes at a rate of 60 Hz, the shift register must shift at a rate of 60 <span class="math inline">\(\times\)</span> 320 = 19.2 KHz.</p>
<p>OD6631 interfaces with AMOLED displays that use the gate-in-panel (GIP) technology where the shift registers are inside the backplane. The AMOLED can have up to 2800 rows, but the driver IC delivers only 20 gate driver signals (<code>GIP[19:0]</code>) to the panel. This implies that each gate signal controls 140 rows. With a 144 Hz refresh rate, shift register inside the backplane has to operate a rate of 144 <span class="math inline">\(\times\)</span> 2800 = 403.2 KHz, but the gate signals from the driver IC only have to shift at 1/20 of that rate (20.16 KHz).</p>
<p>Another difference between gate and source driver signals is that the former is a binary signal controlling whether a row is selected whereas the latter needs to have many digital levels to control the pixel luminance. Therefore, there are Digital-to-Analog Convertors (DACs) before the source driver signals. Both the gate and source driver signals are generated from level shifters, because the input voltage of the driver IC is usually much lower (e.g., below 3.3 <span class="math inline">\(\text{V}\)</span>) than that of the gate/source drivers; for instance, the gate driver signal in RM68090 is above 10 <span class="math inline">\(\text{V}\)</span> in order to select a row.</p>
<p>For mobile devices like smartphones, the driver IC is typically connected to the Systems-on-a-Chip (SoC), which has a display controller IP block. The display controller uses the DMA engine to pass frame data from the memory to the MIPI Display Serial Interface (DSI) transmitter (Tx) block, which serializes the data (since MIPI DSI is a serial interface) and transmits the data to the MIPI DSI receiver (Rx) on the driver IC — this is how frame data is passed between the host and the driver IC.</p>
<p>The driver IC then needs to unpack the data to extract pixels. For mobile displays usually integrate the <em>timing controller</em> (TCON), whose main main job is to decide which row/column drivers get which pixels at which time. For large displays like TVs, the TCON usually sits inside the display itself and is a separate IC.</p>
<p>Many driver ICs also include a small amount of built-in memory, or a frame buffer, which temporarily stores an entire frame of image data. This offloads the constant data transfer burden from the main processor, allowing it to send a new image to the driver IC only when a change is needed, while the driver handles the continuous task of refreshing the screen.</p>
</section>
<section id="sec-disp-tf" class="level2" data-number="20.3">
<h2 data-number="20.3" class="anchored" data-anchor-id="sec-disp-tf"><span class="header-section-number">20.3</span> Elelctrical ↔︎ Optical Transfer Functions</h2>
<p>Ultimately, it is the <span class="math inline">\(V_{Data}\)</span> signals that the display has to set in order to get a desired response on the pixels. How do we go from digital image pixels to <span class="math inline">\(V_{Data}\)</span>?</p>
<p>Assuming AMOLED and using <a href="#eq-tft_iv" class="quarto-xref">Equation&nbsp;<span>20.1</span></a> and and <a href="display-optics.html#eq-led_lum" class="quarto-xref">Equation&nbsp;<span>19.1</span></a>, we know that to achieve a particular optical power <span class="math inline">\(P\)</span>, the following must hold:</p>
<p><span class="math display">\[
    e\frac{P/(h f)}{\eta} = k(V_{DD} - V_{Data} - V_{th})^2,
\]</span></p>
<p>Therefore, the desired <span class="math inline">\(V_{Data}\)</span> is given by<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>:</p>
<p><span class="math display">\[
    V_{Data} = \sqrt{e\frac{P/(h f)}{\eta k}}  + V_{th} - V_{DD}.
\]</span></p>
<p>With a DAC, we can convert a digital value to an analog voltage. Using an ideal DAC transfer function, the digital value to be sent to the DAC is then:</p>
<p><span class="math display">\[
\begin{aligned}
    D = \frac{V_{Data} - V_{min}}{\Delta}, \\
    \Delta = \frac{V_{max} - V_{min}}{2^N - 1},
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\([V_{min}, V_{max}]\)</span> is the DAC output range and <span class="math inline">\(N\)</span> is the resolution.</p>
<p>The relationship between the digital value <span class="math inline">\(D\)</span> and the emitted optical power <span class="math inline">\(P\)</span> is usually called the Electro-Optical Transfer Function (<strong>EOTF</strong>). <a href="#fig-eotf" class="quarto-xref">Figure&nbsp;<span>20.5</span></a> shows the EOTFs for four inorganic LEDs. Even from the theoretical analysis we can see that the relationship is non-linear. In practice the EOTF is usually calibrated and stored in a look-up table (LUT) rather than modeled analytically.</p>
<div id="fig-eotf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-eotf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/eotf.svg" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-eotf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.5: An EOTF example from <span class="citation" data-cites="miller2019color">Miller (<a href="references.html#ref-miller2019color" role="doc-biblioref">2019, fig. 7.2</a>)</span> for four inorganic LEDs (R, G, B, and W).
</figcaption>
</figure>
</div>
<p>Can we directly use an image pixel’s digital value for <span class="math inline">\(D\)</span>? Most likely not. For starters, a pixel’s digital value, without gamma, is encoded in a power/luminance-linear space, but EOTF is non-linear. Therefore, we must transform the image pixel value to the actual digital value that can be sent to the display. This transformation can be abstracted as the Electro-Electrical Transfer Function (<strong>EETF</strong>).</p>
<div id="fig-ootf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ootf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/ootf.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ootf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.6: In an end-to-end workflow, OETF is carried by the imaging system, image processing executes the EETF, and the display performs the EOTF. Together, the mapping in the scene luminnace to the display luminance is the effective OOTF of the system.
</figcaption>
</figure>
</div>
<p><a href="#fig-ootf" class="quarto-xref">Figure&nbsp;<span>20.6</span></a> shows how EOTF and EETF fit in an end-to-end workflow, where we take a picture of the scene and then displays it on a display. The imaging system essentially executes the Opto-Electrical Transfer Function (<strong>OETF</strong>) that turns the optical signal in the scene to image pixel values. The image processing pipeline turns the image pixel values to digital values that are sent to the display; this pipeline essentially performs the EETF. The display then turns the digital values to optical signal through the EOTF. Together, OETF, EETF, and EOTF collectively forms the effective Opto-Optical Transfer Function (<strong>OOTF</strong>) of the system.</p>
<p>In a rendering system, the image pixel values are rendered/simulated rather than captured, but the same principle applies. The rendered pixel values should be proportional to or, ideally, directly encode the absolute luminance information of the rendered scene. When the frame is rendered on the display, there is an underlying OOTF between the intended luminance in the virtual scene and the actual luminance from the display.</p>
<p>Correcting for the non-linear EOTF is part of the EETF, which, however, does more than just that. So what sort of processing is carried by the EETF?</p>
</section>
<section id="sec-disp-sp" class="level2" data-number="20.4">
<h2 data-number="20.4" class="anchored" data-anchor-id="sec-disp-sp"><span class="header-section-number">20.4</span> Display Signal Processing</h2>
<p>In theory, if we know the <em>intended</em> luminance (of each color channel) we can simply invert the EOTF LUT and obtain the digital value that should be sent to the display. So the real question is, from the image pixel values do we know what the intended luminance value is? Let’s first reason about what <em>should</em> happen using physical units and quantities, and then discuss practical issues in implementation.</p>
<section id="sec-disp-sp-tm" class="level3" data-number="20.4.1">
<h3 data-number="20.4.1" class="anchored" data-anchor-id="sec-disp-sp-tm"><span class="header-section-number">20.4.1</span> Luminance Dynamic Range and Tone Mapping</h3>
<p>Ideally, the goal of any display is to faithfully reproduce the actual luminance range intended in the scene, which, in turn, poses two requirements.</p>
<p>First, the pixel values in an image should encode absolute luminance/radiance information, not just the relative chromaticity. Usual sRGB encoding does not give us that. Physically-based rendering where physical units are tracked does. HDR imaging, where no pixel is saturated, noise floor is low, and the camera color space is carefully calibrated and corrected to a device-independent space like XYZ (we have discussed color correction in <a href="imaging-isp.html" class="quarto-xref"><span>Chapter 18</span></a>), <em>could</em> (but most often does not) also approximately give the absolute luminance information<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. Let’s for now assume that such absolute luminance information is encoded in an image.</p>
<p>The second requirement has to do with dynamic range and needs a careful explanation.</p>
<section id="luminance-dynamic-range" class="level4">
<h4 class="anchored" data-anchor-id="luminance-dynamic-range">Luminance Dynamic Range</h4>
<p>Given the absolute luminance intended in the image, the display should then ideally reproduce the per-pixel luminance. It would be <em>amazing</em> if a display could do that, but it is hardly possible, for a variety of reasons.</p>
<ul>
<li>First, the peak display luminance of a display is usually lower than that of the real world.</li>
<li>Second, the real world has a much larger luminance dynamic range (DR) than that is afforded by the display. The luminance DR of the scene is the ratio between the maximum and minimum luminance in the scene, and the luminance DR of the display is the ratio between the maximum and minimum luminance producible by the display.
<ul>
<li>The definitions are concerned with luminance (a photometric metric) rather than illuminance (a radiometric metric) because we care about the perceived power not the radiant power in the scene.</li>
<li>We use “luminance DR” rather than simply DR to emphasize its difference from the DR of a sensor (<a href="imaging-sensor.html#sec-chpt-imaging-sensor-pixel-dr" class="quarto-xref"><span>Section 16.2.4</span></a>), which is concerned with the ratio of peak measurable luminance in the scene to the noise floor. For simplicity we will use DR when it is clear what it refers to in a given context. Luminance DR is also often referred to as the <strong>contrast ratio</strong> while the sensor DR can be thought of as a form of signal-to-noise ratio <span class="citation" data-cites="mantiuk2015high">(<a href="references.html#ref-mantiuk2015high" role="doc-biblioref">Mantiuk et al. 2015</a>)</span>.</li>
</ul></li>
<li>Third, the luminance levels in a real-world scene are continuous whereas the luminance levels in digital displays are quantized (e.g., 256 levels in an 8-bit encoding), so there are quantization errors.</li>
</ul>
<div id="fig-dynamic_range_comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dynamic_range_comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/dynamic_range_comparison.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dynamic_range_comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.7: Luminance dynamic range comparison between a real-world scene and various output devices. Adapted from <span class="citation" data-cites="lang2007rendering">Lang (<a href="references.html#ref-lang2007rendering" role="doc-biblioref">2007, figs. 3,5</a>)</span>.
</figcaption>
</figure>
</div>
<p>The difference between the scene luminance range and that of various output devices is illustrated in <a href="#fig-dynamic_range_comparison" class="quarto-xref">Figure&nbsp;<span>20.7</span></a>.</p>
<ul>
<li>The DR of a real-world scene usually spans 4-5 log units.</li>
<li>The DR of a typical display is usually limited to about 3 log units, which is slightly higher than prints.</li>
<li>Modern high-dynamic-range (HDR) displays have luminance DRs that might match that of a scene, but the peak luminance still falls far short of that of what a real-world scene can produce<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</li>
</ul>
<p>To enhance display DR, we not only need to be able to produce a high peak luminance but also a very low, ideally 0, luminance when the pixel value is 0. There are many industry standards/certifications for HDR displays, almost all of which include metrics such as minimum peak luminance, maximum black-level luminance, contrast ratio, and bit depth <span class="citation" data-cites="vesahdr12">(<a href="references.html#ref-vesahdr12" role="doc-biblioref">VESA 2024</a>)</span>.</p>
</section>
<section id="tone-mapping" class="level4">
<h4 class="anchored" data-anchor-id="tone-mapping">Tone Mapping</h4>
<p>Given that it is unlikely that a display can fully reproduce the scene luminance range, the next best question to ask is: how do we accurately reproduce the <em>perceptual experience</em> of the intended scene? To achieve this, the knob we have is the mapping of the intended luminance of each pixel in the image to a new luminance that is within the range afforded by the display (assuming of course the chromaticity is maintained throughout this mapping). This is the problem of <strong>tone mapping</strong> and is effectively the OOTF in <a href="#fig-ootf" class="quarto-xref">Figure&nbsp;<span>20.6</span></a>. Both the OETF of an imaging/rendering system and the EOTF of a display participate in the OOTF, and if the product of OETF and EOTF is not the desired OOTF, the residual adjustment needed must be part of the image processing pipeline, i.e., EETF, to reach the desired OOTF.</p>
<p>Tone mapping is usually part of the rendering pipeline or the image signal processing pipeline of a digital camera (rather than the display signal processing pipeline), which we have discussed in <a href="imaging-isp.html" class="quarto-xref"><span>Chapter 18</span></a>. We will refer you to <span class="citation" data-cites="reinhard2010high">Reinhard (<a href="references.html#ref-reinhard2010high" role="doc-biblioref">2010</a>)</span> and <span class="citation" data-cites="mantiuk2015high">Mantiuk et al. (<a href="references.html#ref-mantiuk2015high" role="doc-biblioref">2015</a>)</span> for surveys of tone mapping techniques. The key thing is to <strong>preserve contrast</strong>. Recall that the human visual system has a contrast sensitivity function (<a href="hvs-intro.html#sec-chpt-hvs-percept-retinafunc-contrast" class="quarto-xref"><span>Section 2.4.2</span></a>), which tells us the minimal contrast necessary at each frequency for the pattern to be detectable. When we compress a large DR to a small DR, (local) contrasts would be lost due to quantization errors (insufficient bit depths) and, as a result, the displayed image looks “dull”.</p>
<!-- Let's say we have an image two pixel values [0.1, 0.2, 0.3] and [0.3, 0.5, 0.6], both in linear sRGB space (i.e., without gamma and channel value bounded between 0 and 1).
What do these pixel values tell us?
They tell us 1) the relative values of the three channels in the two pixels and 2) the relative luminance ratio between the two pixels in each channel.
They do not tell us anything about absolute luminance.

There are a few challenges here.
First, the image pixel values are necessarily encoded in a device-independent color space such as sRGB or DCI-P3, whereas the luminance we are talking about is tied to the display's native color space.
Therefore, we must transform colors from the image's encoding space to the display native space. -->
</section>
</section>
<section id="sec-disp-sp-eetf" class="level3" data-number="20.4.2">
<h3 data-number="20.4.2" class="anchored" data-anchor-id="sec-disp-sp-eetf"><span class="header-section-number">20.4.2</span> Ideal EETF</h3>
<p>So in the ideal case, we would first perform tone mapping to determine the luminance of each pixel. Tone mapping changes the luminance of a pixel but not its chromaticity. Given the new luminance, we can give the absolute XYZ value of a pixel by equating Y to the absolute luminance (recall that Y is proportional to luminance as discussed in <a href="hvs-colorimetry.html#sec-chpt-hvs-cori-xyz" class="quarto-xref"><span>Section 5.1</span></a>). We then transform from the XYZ space to the display native space; from there we then invert the EOTF to obtain the actual digital values sent to the display.</p>
<p>Mathematically, this is broken down into a few steps. Let’s assume the original image is encoded in a luminance-linear RGB space with absolute luminance information. We could transform from the RGB space to the XYZ space by: <!-- by setting the Y value of the sRGB white to 1 (as discussed in @sec-chpt-hvs-cori-cube and interactively illustrated in @zhu2022cube).
For an image pixel color in the RGB space, we obtain its color in the XYZ space by: --></p>
<p><span id="eq-eetf_1"><span class="math display">\[
    P_{XYZ} = \text{diag}(Y^s_{max}, Y^s_{max}, Y^s_{max}) \times T_{RGB\_to\_XYZ} \times P_{RGB},
\tag{20.2}\]</span></span></p>
<p>where <span class="math inline">\(P_{XYZ}\)</span> is the pixel color in the XYZ space carrying absolute luminance information, <span class="math inline">\(P_{RGB}\)</span> is the pixel color in the linear, normalized RGB space bounded by 0 and 1, <span class="math inline">\(T_{RGB\_to\_XYZ}\)</span> is the transformation matrix from the linear, normalized RGB space to the XYZ space such that <span class="math inline">\(Y\)</span> of the RGB white (i.e., <span class="math inline">\([1, 1, 1]\)</span> in the RGB space) is set to 1, and <span class="math inline">\(Y^s_{max}\)</span> is the luminance of RGB white.</p>
<p>What a tone-mapping operator (TMO) <span class="math inline">\(f_{lum}\)</span> does effectively is to simply re-adjust the Y value of each pixel <span class="math inline">\(P_{XYZ}\)</span> to the corresponding absolute luminance level, and then scale the X and Z values proportionally to maintain the chromaticity:</p>
<p><span id="eq-eetf_2"><span class="math display">\[
    \hat{P}_{XYZ} = f_{lum}(P_{XYZ}) = T_{lum} \times P_{XYZ}
\tag{20.3}\]</span></span></p>
<p>where <span class="math inline">\(\hat{P}_{XYZ}\)</span> is a tone-mapped XYZ value of the pixel and carries absolute luminance information, and the subscript in <span class="math inline">\(f_{lum}\)</span> indicates that this particular TMO operates on absolute luminance. Effectively, the TMO scales each tristimulus value of <span class="math inline">\(P_{XYZ}\)</span>, which we represent using a scaling matrix <span class="math inline">\(T_{lum}\)</span>. If <span class="math inline">\(T_{lum}\)</span> depends only on the XYZ values of <span class="math inline">\(P_{XYZ}\)</span>, the TMO is a global operator. In contrast, local TMOs can apply different transformations to pixels that have the same XYZ values but appear at different spatial locations.</p>
<p>Now that we are in the XYZ space, the next step is to transform the image pixel colors to the display native color space, for which we need another transformation between the display native space and the XYZ space. To construct the display native color space, we would first offline measure the chromaticities of the display primary colors and the white point, which gives us another canonical transformation matrix <span class="math inline">\(T_{disp\_to\_XYZ}\)</span> where a luminance-linear, normalized display white point [1, 1, 1] is mapped to an XYZ value where <span class="math inline">\(Y\)</span> is 1.</p>
<p>To use this transformation matrix, we need to first scale each absolute <span class="math inline">\(\hat{P}_{XYZ}\)</span> value by <span class="math inline">\(Y^d_{max}\)</span>, the maximum luminance of display white (e.g., those shown in <a href="#fig-eotf" class="quarto-xref">Figure&nbsp;<span>20.5</span></a>):</p>
<p><span id="eq-eetf_3"><span class="math display">\[
    P_{disp} = T^{-1}_{disp\_to\_XYZ} \times \text{diag}^{-1}(Y^d_{max}, Y^d_{max}, Y^d_{max}) \times \hat{P}_{XYZ},
\tag{20.4}\]</span></span></p>
<p>where <span class="math inline">\(P_{disp} \in [0, 1]^3\)</span> is a pixel color in the normalized display native space.</p>
<p>As an example, let’s say <span class="math inline">\(P_{disp} = [0.1, 0.2, 0.8]\)</span>. What this means is that the R channel of the image pixel requires 10% of the maximum luminance in the R sub-pixel. By inverting the EOTF LUT (<a href="#fig-eotf" class="quarto-xref">Figure&nbsp;<span>20.5</span></a>), we can then get the actual digital value that needs to be sent to the display. This inversion compensates the non-linear EOTF of the display.</p>
<p>Putting <a href="#eq-eetf_1" class="quarto-xref">Equation&nbsp;<span>20.2</span></a> to <a href="#eq-eetf_3" class="quarto-xref">Equation&nbsp;<span>20.4</span></a> together, we have:</p>
<p><span id="eq-eetf_4"><span class="math display">\[
    P_{disp} = \underbrace{T^{-1}_{disp\_to\_XYZ} \times \text{diag}^{-1}(Y^d_{max}, Y^d_{max}, Y^d_{max}) \times T_{lum} \times \text{diag}(Y^s_{max}, Y^s_{max}, Y^s_{max}) \times T_{RGB\_to\_XYZ}}_{f_{norm}(\cdot)} \times P_{RGB},
\tag{20.5}\]</span></span></p>
<p>where the entire transformation can be seen as a TMO <span class="math inline">\(f_{norm}(\cdot)\)</span> that operates between normalized RGB and normalized display native spaces.</p>
</section>
<section id="sec-disp-sp-impl" class="level3" data-number="20.4.3">
<h3 data-number="20.4.3" class="anchored" data-anchor-id="sec-disp-sp-impl"><span class="header-section-number">20.4.3</span> Practical Considerations</h3>
<p>There are many challenges of implementing the ideal EETF in practice.</p>
<section id="practical-tone-mapping" class="level4">
<h4 class="anchored" data-anchor-id="practical-tone-mapping">Practical Tone Mapping</h4>
<p>Many images do not encode absolute luminance/radiance information. An image pixel [10, 20, 30] in the sRGB space tells us nothing about the absolute luminance of each channel. Even if an image is captured through an HDR imaging workflow and encoded in an HDR format, e.g., OpenEXR <span class="citation" data-cites="openxer">(<a href="references.html#ref-openxer" role="doc-biblioref">ILM 2025</a>)</span>, which has a very high bit depth (even allows for floating point numbers!), the absolute luminance information is usually still not encoded. Worse, we do not always know the target display dynamic range (which is ultimatelly what matters since that is where the image will be displayed!), when, for instance, tone mapping is done in an camera image signal processing pipeline that is agnostic to the viewing display.</p>
<p>Absent absolute luminance information, the TMO <span class="math inline">\(f_{norm}(\cdot)\)</span> in <a href="#eq-eetf_4" class="quarto-xref">Equation&nbsp;<span>20.5</span></a> has to operate in normalized, luminance-linear spaces. Some guesswork and empirical heuristics are involved. Many software tools allow us to play with the EETF in such a setting, such as the famous Curves tool in Photoshop and Lightroom. <a href="#fig-tone_mapping_examples" class="quarto-xref">Figure&nbsp;<span>20.8</span></a> shows three such examples in Lightroom, each of which has a tonal adjustment curve that maps an input pixel value in the normalized, luminance-linear input range (x-axis) to an output pixel value in the same range and color space (y-axis)<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. The actual number of input digital levels depends on the input image encoding, which in this case is 10 bits (from Google’s HDR+ dataset) and the number of output digital levels depends on the display itself.</p>
<div id="fig-tone_mapping_examples" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tone_mapping_examples-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figs/tone_mapping_examples.svg" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tone_mapping_examples-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;20.8: Three tone mapping examples, each with a corresponding tonal adjustment curve, I set using Lightroom on an iPhone 12 Pro. The original image is a 10-bit (demosaicked and color corrected) image captured by a Google Pixel phone, obtained from the HDR+ Burst Photography Dataset <span class="citation" data-cites="hasinoff2016burst">(<a href="references.html#ref-hasinoff2016burst" role="doc-biblioref">Hasinoff et al. 2016</a>)</span>.
</figcaption>
</figure>
</div>
<p>With a simple linear mapping in the first example, the image looks quite dark and dull. This is because most of the input pixel values are quite low (judging from the color histogram at the top), so essentially most of the pixels are mapped to low output digital values. We can raise the brightness by raising the tonal curve, as done in the second example. That curve essentially increases the contrast ratio of the low-to-mid luminance pixels and compress the contrast ratio of the mid-to-high luminance pixels.</p>
<p>In my last example, I have raised the tonal curve so much that many input digital levels are mapped to the same, maximum output digital levels, as if those pixels were “saturated” during imaging. What this does is to give the low-to-mid luminance pixels an even larger contrast ratio, so the details look more vivid. Perhaps surprisingly, this intentional saturation does not actually lead to visible “over-exposure” in the final image. Why? Look at the color histogram at the top of the third example: only a small fraction pixels are actually saturated, even though a relative wide range of pixel pixel values are mappped to saturation.</p>
<p>Not knowing the absolute (input and output) luminance levels is fine here since: 1) the input digital levels are luminance-linear so we <em>are</em> still mainipulating the relative luminance information, and 2) the absolute output luminance information is directly seen on the display, so we can judge for ourselves whether we like it or not.</p>
<p>The tonal adjustment curve is also a place for creative expression even if we are not concerned with tone mapping <em>per se</em>. Readers familiar with the Curve tool in Photoshop must be familiar with the notion of an “S-curve” or an “inverse S-curve” (if not, see <a href="https://www.lightroompresets.com/blogs/pretty-presets-blog/how-to-use-photoshop-curves">these</a> <a href="https://www.cambridgeincolour.com/tutorials/photoshop-curves.htm">articles</a>). The former essentially increases the contrast ratio between the highlights and shadows in an image and the latter does the opposite. These adjustments are usually made in photo editing/image processing software that does not map between different dynamic ranges but allows us to apply an creative and artistic look to an image.</p>
</section>
<section id="gamut-mapping" class="level4">
<h4 class="anchored" data-anchor-id="gamut-mapping">Gamut Mapping</h4>
<p>A display might support a color space whose gamut is smaller than that of the image’s encoding space. For instance, the display might support only sRGB while the image is encoded in DCI-P3, so some of the P3 colors might not be accurately reproduced. That is, <span class="math inline">\(P_{disp}\)</span> in <a href="#eq-eetf_3" class="quarto-xref">Equation&nbsp;<span>20.4</span></a> might be outside the [0, 1] bound. The best thing we can do is to approximate an out-of-gamut color with an in-gamut color to minimize the color error. This is called <strong>gamut mapping</strong>. <span class="citation" data-cites="morovivc2008color">Morovič (<a href="references.html#ref-morovivc2008color" role="doc-biblioref">2008</a>)</span> and <span class="citation" data-cites="glassner1995principles">Glassner (<a href="references.html#ref-glassner1995principles" role="doc-biblioref">1995, chap. 3.6</a>)</span> describe the basic algorithms, with the former being more recent and comprehensive.</p>
<p>The simplest strategy would be to simply clamp out-of-range values, so a color of [12, 200, 300] would become [12, 200, 255]. Clearly, other than being extremely simple to implement, this strategy would introduce large color reproduction errors. International Color Consortium (ICC) has defined four <strong>rendering intents</strong>, each of which corresponds to a gamut mapping algorithm (vaguely worded, and the implementation detail might vary).</p>
<p>For instance, the <em>Absolute</em> rendering intent leaves all the in-gamut colors unchanged but maps the out-of-gamut colors to the boundary of the color gamut. The <em>Perceptual</em> rendering intent can be implemented by uniformly projecting all the colors to the white point so that all the colors are in-gamut. You can imagine that while this maintains the relative color appearance between colors (which the Absolute rendering intent fails at), but it would also change in-gamut colors that could have been accurately rendered!</p>
</section>
</section>
<section id="sec-disp-sp-cm" class="level3" data-number="20.4.4">
<h3 data-number="20.4.4" class="anchored" data-anchor-id="sec-disp-sp-cm"><span class="header-section-number">20.4.4</span> Color Management</h3>
<p>Performing EETF in an end-to-end workflow benefits from princpled <strong>color management</strong>, which is concerned with maintaining a consistent color appearance throughout the workflow that might involve wildly different capturing devices (e.g., cameras, scanners) and output devices (e.g., displays, printers).</p>
<p>Color management requires a collaboration between every single piece that touches color in the workflow: the image file must come with a <em>profile</em> that specifies what color space its pixel colors are encoded in and (an estimation of) the viewing condition under which the image was originally edited/viewed, the software that manipulates image content must correctly read and interpret the profile and perform the necessary transformation, potentially through APIs exposed by the Operating System (OS), and the display firmware and drive must communicate with the OS a similar profile of the display itself. <span class="citation" data-cites="giorgianni2009digital">Giorgianni and Madden (<a href="references.html#ref-giorgianni2009digital" role="doc-biblioref">2009</a>)</span> and <span class="citation" data-cites="sharma2018understanding">Sharma (<a href="references.html#ref-sharma2018understanding" role="doc-biblioref">2018</a>)</span> are two excellent references for color management.</p>
<p>First, the image file should ideally have metadata that tells us what color space its pixel colors are encoded in or, better, the transformation matrix from the image’s color space to a device-independent color space, say the CIE XYZ space. The way to describe such information has been standardized by ICC in what is called the <em>ICC profile</em> <span class="citation" data-cites="iccv2 sharma2018understanding">(<a href="references.html#ref-iccv2" role="doc-biblioref">International Color Consortium 2019</a>; <a href="references.html#ref-sharma2018understanding" role="doc-biblioref">Sharma 2018</a>, Chpt, 5)</span>. We can embed an ICC profile in common image file formats such as JPEG.</p>
<p>Second, the display itself also has to report its native color space. To do that, modern displays usually come with an ICC profile that describes how to transform from the CIE XYZ space to the display’s native space. Now when the Operating System gets the image file, it would first transform the, say, sRGB colors to the XYZ space using the ICC profile in the image and then transform the colors in the XYZ to the display’s native space using the display ICC profile. You can see that the XYZ space here serves to connect the input color space and the output color space. ICC calls such a space a Profile Connection Space (PCS).</p>
<p>During the color space transformation, we usually perform an additional transformation so that sRGB white becomes the white point in the display space. This is called <em>chromatic adaptation</em>, which is discussed in <a href="hvs-adaptation.html#sec-chpt-hvs-adaptations-chroma" class="quarto-xref"><span>Section 6.3</span></a>. This is to accommodate the fact that the viewer might be under a different viewing condition than the condition under which the photo was originally edited. The viewing condition could affect the actual appearance of a color, so we must account for this shift in viewing condition through chromatic adaptation.</p>
<!-- Talk about the following here; emphasize that the display EOTF is most likely not sRGB, but showing it to app developers give them the impression that it's sRGB so that they can encode their pixel values according.  Internally there is another translation that uses the device's actual EOTF.

If you want the true TRC of your specific panel:
Measure it with a colorimeter (e.g., X-Rite i1Display, Datacolor Spyder, or better a spectroradiometer).
Generate a LUT-based ICC profile with DisplayCAL. That will encode the actual EOTF of your MacBook at the brightness setting you tested.

The mapping between the original image pixel value (normalized to [0, 1]) to the relative luminance level (normalized to [0, 1]) is also called the **tone reproduction curve** or tone response curve (TRC), essentially a normalized form of EOTF.

![Two TRC examples: one of my LG dislay (left) and the other of my MacBook LCD (right).](figs/trc_examples){#fig-trc_examples width="100%"}

Very confusingly, sometimes TRC is also used to mean the (normalized) OETF, especially in the imaging context, so be careful what it actually means. -->
<!-- %``Display profiles are profiles that describe how a computer monitor or projector reproduces colours. Without them applications such as Photoshop would have no idea how the monitor displays colour. If you haven’t calibrated and profiled your monitor then your computer will be using a generic profile that does not reflect how your monitor works. It will be an approximation at best.''
%https://www.permajet.com/blog/what-is-an-icc-profile-why-do-i-need-one/
% miller2019color chap. 7.1 uses a somewhat weird example where he wants to pick 9000K as the adaptation white but the display white point is not 9000K. so after chromatic adaptation the input sRGB white will become [1, 1, 1] in the display native space, i.e., display white point, which, however, is not 9000K. he suggests a compensation method, but in reality the display profile would know its actual white point and supply the correct chromatic adaptation matrix accordingly. -->


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-blankenbach2016active" class="csl-entry" role="listitem">
Blankenbach, Karlheinz. 2016. <span>“Active Matrix Driving.”</span> In <em>Handbook of Visual Display Technology</em>, 2nd ed., 645–64. Springer.
</div>
<div id="ref-blankenbach2016direct" class="csl-entry" role="listitem">
Blankenbach, Karlheinz, Andreas Hudak, and Michael Jentsch. 2016. <span>“Direct Drive, Multiplex, and Passive Matrix.”</span> In <em>Handbook of Visual Display Technology</em>, 2nd ed., 621–44. Springer.
</div>
<div id="ref-cristaldi2009liquid" class="csl-entry" role="listitem">
Cristaldi, David JR, Salvatore Pennisi, and Francesco Pulvirenti. 2009. <em>Liquid Crystal Display Drivers: Techniques and Circuits</em>. Vol. 2. Springer.
</div>
<div id="ref-giorgianni2009digital" class="csl-entry" role="listitem">
Giorgianni, Edward J, and Thomas E Madden. 2009. <em>Digital Color Management: Encoding Solutions</em>. Vol. 13. John Wiley &amp; Sons.
</div>
<div id="ref-glassner1995principles" class="csl-entry" role="listitem">
Glassner, Andrew S. 1995. <em>Principles of Digital Image Synthesis</em>. Elsevier.
</div>
<div id="ref-hasinoff2016burst" class="csl-entry" role="listitem">
Hasinoff, Samuel W, Dillon Sharlet, Ryan Geiss, Andrew Adams, Jonathan T Barron, Florian Kainz, Jiawen Chen, and Marc Levoy. 2016. <span>“Burst Photography for High Dynamic Range and Low-Light Imaging on Mobile Cameras.”</span> <em>ACM Transactions on Graphics (ToG)</em> 35 (6): 1–12.
</div>
<div id="ref-openxer" class="csl-entry" role="listitem">
ILM. 2025. <span>“<span class="nocase">OpenEXR Specification, v 3.4.0</span>.”</span> <a href="https://openexr.com/en/latest/" class="uri">https://openexr.com/en/latest/</a>.
</div>
<div id="ref-iccv2" class="csl-entry" role="listitem">
International Color Consortium. 2019. <span>“<span class="nocase">Specification ICC.2:2019 (Profile version 5.0.0 - iccMAX)</span>.”</span> <a href="https://color.org/specification/ICC.2-2019.pdf" class="uri">https://color.org/specification/ICC.2-2019.pdf</a>.
</div>
<div id="ref-lang2007rendering" class="csl-entry" role="listitem">
Lang, Karl. 2007. <span>“Rendering the Print: The Art of Photography.”</span> <em>Adobe System Technical Paper</em>.
</div>
<div id="ref-ma2016active" class="csl-entry" role="listitem">
Ma, Ruiqing. 2016. <span>“Active Matrix for OLED Displays.”</span> In <em>Handbook of Visual Display Technology</em>, 2nd ed., 1821–41. Springer.
</div>
<div id="ref-mantiuk2015high" class="csl-entry" role="listitem">
Mantiuk, Rafał, Grzegorz Krawczyk, Dorota Zdrojewska, Radosław Mantiuk, Karol Myszkowski, and Hans-Peter Seidel. 2015. <span>“High Dynamic Range Imaging.”</span> In <em>Wiley Encyclopedia of Electrical and Electronics Engineering</em>. Wiley.
</div>
<div id="ref-miller2019color" class="csl-entry" role="listitem">
Miller, Michael E. 2019. <em>Color in Electronic Display Systems</em>. Springer.
</div>
<div id="ref-morovivc2008color" class="csl-entry" role="listitem">
Morovič, Ján. 2008. <em>Color Gamut Mapping</em>. 2nd ed. John Wiley &amp; Sons.
</div>
<div id="ref-od6631" class="csl-entry" role="listitem">
OmniVision. n.d. <span>“<span>OD6631 AMOLED Driver Brief</span>.”</span>
</div>
<div id="ref-rm68090" class="csl-entry" role="listitem">
Raydium. 2011. <span>“<span class="nocase">RM68090 Data Sheet: Single Chip Driver with 262K color for 240RGBx320 a-Si TFT LCD</span>.”</span>
</div>
<div id="ref-reinhard2010high" class="csl-entry" role="listitem">
Reinhard, Erik. 2010. <em>High Dynamic Range Imaging Acquisition, Display, and Image-Based Lighting</em>. 2nd ed. Morgan Kaufmann Publishers.
</div>
<div id="ref-sharma2018understanding" class="csl-entry" role="listitem">
Sharma, Abhay. 2018. <em>Understanding Color Management</em>. John Wiley &amp; Sons.
</div>
<div id="ref-tsujimura2017oled" class="csl-entry" role="listitem">
Tsujimura, Takatoshi. 2017. <em>OLED Display Fundamentals and Applications</em>. 2nd ed. John Wiley &amp; Sons.
</div>
<div id="ref-vesahdr12" class="csl-entry" role="listitem">
VESA. 2024. <em>VESA High-Performance Monitor and Display Compliance Test Specification</em>. Video Electronics Standards Association.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Other configurations are possible depending on whether we use an NMOS or a PMOS transistor and whether we use a source-follower circuit or a constant-current circuit <span class="citation" data-cites="tsujimura2017oled">(<a href="references.html#ref-tsujimura2017oled" role="doc-biblioref">Tsujimura 2017</a>, Chpt. 4.4.2)</span>. What we describe here uses PMOS + constant-current circuit.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>240 pixel columns and 3 sub-pixels per pixel column, so 720 effective columns<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>given that <span class="math inline">\(V_{gs} &gt; V_{th}\)</span> for the TFT to operate in the saturation region.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>This is because the Y value in an XYZ space is proportional to the luminance, so the device RGB to XYZ transformation matrix can be calibrated to give absolute Y values.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Case in point: you have probably never really felt too uncomfortable staring at a display but starring at white paper under noon sunlight is excruciating.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Two notes. First, exactly in what color space are the inputs and outputs encoded is irrelevant, because all we care about here is luminance re-mapping. Second, the tonal curve here maps RGB values within the same space rather than from the RGB space to the display native space, so it is technically not <span class="math inline">\(f_{norm}(\cdot)\)</span> in <a href="#eq-eetf_4" class="quarto-xref">Equation&nbsp;<span>20.5</span></a> but relates to <span class="math inline">\(f_{norm}(\cdot)\)</span> by a linear transformation from RGB to display native space.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./display-optics.html" class="pagination-link" aria-label="Optical Mechanisms">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Optical Mechanisms</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="References">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/learnvisualcomputing/learnvisualcomputing.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>